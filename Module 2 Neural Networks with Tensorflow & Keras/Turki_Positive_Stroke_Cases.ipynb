{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0g2RQRSltgja"
   },
   "source": [
    "# Full DL Solution\n",
    "---\n",
    "### **Case Study:** Stroke Prediction\n",
    "\n",
    "**Objective:** The goal of this project is to walk you through a case study where you can apply the deep learning concepts that you learned about during the week. By the end of this project, you would have developed a solution that predicts if a person will have a stroke or not.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SSCD88NxJjFo"
   },
   "source": [
    "**Dataset Explanation:** We will be using the stroke dataset. Its features are:\n",
    "\n",
    "\n",
    "* **id:** unique identifier\n",
    "* **gender:** \"Male\", \"Female\" or \"Other\"\n",
    "* **age:** age of the patient\n",
    "* **hypertension:** 0 if the patient doesn't have hypertension, 1 if the patient has hypertension\n",
    "* **heart_disease:** 0 if the patient doesn't have any heart diseases, 1 if the patient has a heart disease\n",
    "* **ever_married:** \"No\" or \"Yes\"\n",
    "* **work_type:** \"children\", \"Govt_jov\", \"Never_worked\", \"Private\" or \"Self-employed\"\n",
    "* **Residence_type:** \"Rural\" or \"Urban\"\n",
    "* **avg_glucose_level:** average glucose level in blood\n",
    "* **bmi:** body mass index\n",
    "* **smoking_status:** \"formerly smoked\", \"never smoked\", \"smokes\" or \"Unknown\"*\n",
    "* **stroke:** 1 if the patient had a stroke or 0 if not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gBvX5nCYt8cT"
   },
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JaPfsfvXK2_0"
   },
   "source": [
    "We start by importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T08:07:41.259744Z",
     "start_time": "2023-11-09T08:07:41.080187Z"
    },
    "id": "oK92M0m-ezbE"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T08:07:42.059713Z",
     "start_time": "2023-11-09T08:07:42.007929Z"
    },
    "id": "mMQuUG7OtfrG"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0-RxAH5auFFy"
   },
   "source": [
    "# Loading the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z_jj2t6zK6zy"
   },
   "source": [
    "We load the dataset from a csv file, and see its first rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T08:07:48.937612Z",
     "start_time": "2023-11-09T08:07:48.722533Z"
    },
    "id": "UQVo1CAJt7s8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9046</td>\n",
       "      <td>Male</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.6</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51676</td>\n",
       "      <td>Female</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>202.21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31112</td>\n",
       "      <td>Male</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.5</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60182</td>\n",
       "      <td>Female</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.4</td>\n",
       "      <td>smokes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1665</td>\n",
       "      <td>Female</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.0</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  gender   age  hypertension  heart_disease ever_married  \\\n",
       "0   9046    Male  67.0             0              1          Yes   \n",
       "1  51676  Female  61.0             0              0          Yes   \n",
       "2  31112    Male  80.0             0              1          Yes   \n",
       "3  60182  Female  49.0             0              0          Yes   \n",
       "4   1665  Female  79.0             1              0          Yes   \n",
       "\n",
       "       work_type Residence_type  avg_glucose_level   bmi   smoking_status  \\\n",
       "0        Private          Urban             228.69  36.6  formerly smoked   \n",
       "1  Self-employed          Rural             202.21   NaN     never smoked   \n",
       "2        Private          Rural             105.92  32.5     never smoked   \n",
       "3        Private          Urban             171.23  34.4           smokes   \n",
       "4  Self-employed          Rural             174.12  24.0     never smoked   \n",
       "\n",
       "   stroke  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'healthcare-dataset-stroke-data.csv'\n",
    "data = pd.read_csv(path)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r6gAyBGtubI7"
   },
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XZ_93CvuLF3j"
   },
   "source": [
    "Now we start the exploratory data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2925yVCdud0a"
   },
   "source": [
    "### Shape of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yZ0hWvVALJy4"
   },
   "source": [
    "First thing we need to know the shape of our data\n",
    "\n",
    "**Question 1:** How many examples and features do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T08:07:55.363960Z",
     "start_time": "2023-11-09T08:07:55.319276Z"
    },
    "id": "8pvWR3PKuQEy"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5110, 12)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yUy4oI5xukRr"
   },
   "source": [
    "### Types of different Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G1q10ievLTTs"
   },
   "source": [
    "**Question 2:** Check the type of each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T08:07:58.249822Z",
     "start_time": "2023-11-09T08:07:58.234161Z"
    },
    "id": "_8snoohouhUP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5110 entries, 0 to 5109\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   id                 5110 non-null   int64  \n",
      " 1   gender             5110 non-null   object \n",
      " 2   age                5110 non-null   float64\n",
      " 3   hypertension       5110 non-null   int64  \n",
      " 4   heart_disease      5110 non-null   int64  \n",
      " 5   ever_married       5110 non-null   object \n",
      " 6   work_type          5110 non-null   object \n",
      " 7   Residence_type     5110 non-null   object \n",
      " 8   avg_glucose_level  5110 non-null   float64\n",
      " 9   bmi                4909 non-null   float64\n",
      " 10  smoking_status     5110 non-null   object \n",
      " 11  stroke             5110 non-null   int64  \n",
      "dtypes: float64(3), int64(4), object(5)\n",
      "memory usage: 479.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nkrEh6RYygms"
   },
   "source": [
    "### Dealing with categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v_kBYl7ItLGt"
   },
   "source": [
    "**Question 3:** Use the .value_counts() functions to walk through the categorical variables that we have to see the categories and the counts of each of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T08:08:02.925394Z",
     "start_time": "2023-11-09T08:08:02.899762Z"
    },
    "id": "DlSfSQ35ykgc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smoking_status\n",
       "never smoked       1892\n",
       "Unknown            1544\n",
       "formerly smoked     885\n",
       "smokes              789\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['smoking_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T08:08:04.389704Z",
     "start_time": "2023-11-09T08:08:04.249628Z"
    },
    "id": "Yg0xlLNUy7AF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Residence_type\n",
       "Urban    2596\n",
       "Rural    2514\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Residence_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T08:08:05.092673Z",
     "start_time": "2023-11-09T08:08:05.058427Z"
    },
    "id": "T72r_mkrzF9V"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "work_type\n",
       "Private          2925\n",
       "Self-employed     819\n",
       "children          687\n",
       "Govt_job          657\n",
       "Never_worked       22\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['work_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T08:08:05.776389Z",
     "start_time": "2023-11-09T08:08:05.740190Z"
    },
    "id": "Z0kpR57LzQE9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ever_married\n",
       "Yes    3353\n",
       "No     1757\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['ever_married'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T08:08:06.387915Z",
     "start_time": "2023-11-09T08:08:06.359649Z"
    },
    "id": "fQIoAs8y3igG"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hypertension\n",
       "0    4612\n",
       "1     498\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['hypertension'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T08:08:07.022291Z",
     "start_time": "2023-11-09T08:08:06.974112Z"
    },
    "id": "xEhNH46j3p3Y"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "heart_disease\n",
       "0    4834\n",
       "1     276\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['heart_disease'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T08:08:08.167613Z",
     "start_time": "2023-11-09T08:08:08.099700Z"
    },
    "id": "8cI7uJvA3Njv"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stroke\n",
       "0    4861\n",
       "1     249\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data ['stroke'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_jFIiKPvllld"
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JsQQj-wVlkjS"
   },
   "source": [
    "### Dealing with Nulls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wdlRc672lgI4"
   },
   "source": [
    "**Question 4:** The bmi column contains nulls. Fill it with the appropriate measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T08:08:15.657413Z",
     "start_time": "2023-11-09T08:08:15.627276Z"
    },
    "id": "7UDrnGK6lYiE"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                   0\n",
       "gender               0\n",
       "age                  0\n",
       "hypertension         0\n",
       "heart_disease        0\n",
       "ever_married         0\n",
       "work_type            0\n",
       "Residence_type       0\n",
       "avg_glucose_level    0\n",
       "bmi                  0\n",
       "smoking_status       0\n",
       "stroke               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['bmi'].fillna(value=data['bmi'].mean(), inplace=True)\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "21da4C_Bzd-u"
   },
   "source": [
    "#### Encoding Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UaNk4gWCLqe4"
   },
   "source": [
    "**Question 5:** Here you have to encode those categorical variables to be able to use them to train your DL model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T08:08:19.881993Z",
     "start_time": "2023-11-09T08:08:19.832458Z"
    },
    "id": "6nJtOvxdzi_G"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "data['smoking_status'] = encoder.fit_transform(data['smoking_status'])\n",
    "data['Residence_type'] = encoder.fit_transform(data['Residence_type'])\n",
    "data['work_type'] = encoder.fit_transform(data['work_type'])\n",
    "data['ever_married'] = encoder.fit_transform(data['ever_married'])\n",
    "data['gender'] = encoder.fit_transform(data['gender'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d1GOfAgt4M-Q"
   },
   "source": [
    "### Normalizing Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EPpkMCXELwty"
   },
   "source": [
    "**Question 6:** Normalize the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T08:08:27.051492Z",
     "start_time": "2023-11-09T08:08:26.977038Z"
    },
    "id": "BtI_XA-m33Bx"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5110.000000</td>\n",
       "      <td>5110.000000</td>\n",
       "      <td>5110.000000</td>\n",
       "      <td>5110.000000</td>\n",
       "      <td>5110.000000</td>\n",
       "      <td>5110.000000</td>\n",
       "      <td>5110.000000</td>\n",
       "      <td>5110.000000</td>\n",
       "      <td>5110.000000</td>\n",
       "      <td>5110.000000</td>\n",
       "      <td>5110.000000</td>\n",
       "      <td>5110.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.500656</td>\n",
       "      <td>0.207143</td>\n",
       "      <td>0.527154</td>\n",
       "      <td>0.097456</td>\n",
       "      <td>0.054012</td>\n",
       "      <td>0.656164</td>\n",
       "      <td>0.541928</td>\n",
       "      <td>0.508023</td>\n",
       "      <td>0.390622</td>\n",
       "      <td>0.296037</td>\n",
       "      <td>0.458969</td>\n",
       "      <td>0.048728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.290125</td>\n",
       "      <td>0.246522</td>\n",
       "      <td>0.275764</td>\n",
       "      <td>0.296607</td>\n",
       "      <td>0.226063</td>\n",
       "      <td>0.475034</td>\n",
       "      <td>0.272573</td>\n",
       "      <td>0.499985</td>\n",
       "      <td>0.166643</td>\n",
       "      <td>0.078873</td>\n",
       "      <td>0.357178</td>\n",
       "      <td>0.215320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000919</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000976</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.202841</td>\n",
       "      <td>0.105533</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.243231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.304878</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.284261</td>\n",
       "      <td>0.243852</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.506334</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.548780</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.338136</td>\n",
       "      <td>0.290984</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.749685</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.743902</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.419850</td>\n",
       "      <td>0.336066</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id       gender          age  hypertension  heart_disease  \\\n",
       "count  5110.000000  5110.000000  5110.000000   5110.000000    5110.000000   \n",
       "mean      0.500656     0.207143     0.527154      0.097456       0.054012   \n",
       "std       0.290125     0.246522     0.275764      0.296607       0.226063   \n",
       "min       0.000919     0.000000     0.000976      0.000000       0.000000   \n",
       "25%       0.243231     0.000000     0.304878      0.000000       0.000000   \n",
       "50%       0.506334     0.000000     0.548780      0.000000       0.000000   \n",
       "75%       0.749685     0.500000     0.743902      0.000000       0.000000   \n",
       "max       1.000000     1.000000     1.000000      1.000000       1.000000   \n",
       "\n",
       "       ever_married    work_type  Residence_type  avg_glucose_level  \\\n",
       "count   5110.000000  5110.000000     5110.000000        5110.000000   \n",
       "mean       0.656164     0.541928        0.508023           0.390622   \n",
       "std        0.475034     0.272573        0.499985           0.166643   \n",
       "min        0.000000     0.000000        0.000000           0.202841   \n",
       "25%        0.000000     0.500000        0.000000           0.284261   \n",
       "50%        1.000000     0.500000        1.000000           0.338136   \n",
       "75%        1.000000     0.750000        1.000000           0.419850   \n",
       "max        1.000000     1.000000        1.000000           1.000000   \n",
       "\n",
       "               bmi  smoking_status       stroke  \n",
       "count  5110.000000     5110.000000  5110.000000  \n",
       "mean      0.296037        0.458969     0.048728  \n",
       "std       0.078873        0.357178     0.215320  \n",
       "min       0.105533        0.000000     0.000000  \n",
       "25%       0.243852        0.000000     0.000000  \n",
       "50%       0.290984        0.666667     0.000000  \n",
       "75%       0.336066        0.666667     0.000000  \n",
       "max       1.000000        1.000000     1.000000  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.divide(data.max(axis=0))\n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KICuY0lg5nUD"
   },
   "source": [
    "### Removing Unnecessary Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ua71U2YxL5Ls"
   },
   "source": [
    "**Question 7:** From the features that you have, remove the feature(s) that is(are) irrelevant to your predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T08:08:31.074725Z",
     "start_time": "2023-11-09T08:08:31.039504Z"
    },
    "id": "8AHNqYbh5sE7"
   },
   "outputs": [],
   "source": [
    "data = data.drop('id', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5k-KoLpH5C9R"
   },
   "source": [
    "# Building the DL Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uI2VtlafMBeN"
   },
   "source": [
    "**Question 8:** Now it's time to build the actual model, and observe a summary of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T08:08:34.704717Z",
     "start_time": "2023-11-09T08:08:34.493248Z"
    },
    "id": "AZvKqqT65E0W"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_90 (Dense)            (None, 32)                352       \n",
      "                                                                 \n",
      " dense_91 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_92 (Dense)            (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_93 (Dense)            (None, 4)                 36        \n",
      "                                                                 \n",
      " dense_94 (Dense)            (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_95 (Dense)            (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,065\n",
      "Trainable params: 1,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(32, input_dim=10, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(2, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AD57fE2n7QP4"
   },
   "source": [
    "### Compiling the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "seGmh1x1-qH9"
   },
   "source": [
    "**Question 9:**  Now we compile the model. Here we want to measure the accuracy as well as the precision and recall to know better about the performance of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T08:08:37.711043Z",
     "start_time": "2023-11-09T08:08:37.682475Z"
    },
    "id": "woSsSTEm61_U"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy', metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U5zevRH57X8v"
   },
   "source": [
    "### Fitting the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UhaEU26KMUWK"
   },
   "source": [
    "**Question 10:** Split the data and train the model\n",
    "\n",
    "We take the first columns as features and the last column as a label, then we split our dataset between training (70%) and testing (30%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T08:08:41.495280Z",
     "start_time": "2023-11-09T08:08:41.439038Z"
    },
    "id": "rsVOVfn47MLn"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = data.iloc[:,:-1]\n",
    "y = data.iloc[:, -1]\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.3, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LVvxbyPyezb3"
   },
   "source": [
    "we fit the model on 80% training data, and validate on the rest. Later we will do the final test on the test data. The training happens for 15 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T08:08:57.370121Z",
     "start_time": "2023-11-09T08:08:44.274856Z"
    },
    "id": "KrlvFubpqBeS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "112/112 [==============================] - 3s 6ms/step - loss: 0.4277 - accuracy: 0.9514 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: 0.2214 - val_accuracy: 0.9511 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 2/25\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.2075 - accuracy: 0.9514 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: 0.2002 - val_accuracy: 0.9511 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 3/25\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.1928 - accuracy: 0.9514 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: 0.1863 - val_accuracy: 0.9511 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 4/25\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.1835 - accuracy: 0.9514 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: 0.1806 - val_accuracy: 0.9511 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 5/25\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.1773 - accuracy: 0.9514 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: 0.1735 - val_accuracy: 0.9511 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 6/25\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.1728 - accuracy: 0.9514 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: 0.1657 - val_accuracy: 0.9511 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 7/25\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.1701 - accuracy: 0.9514 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: 0.1634 - val_accuracy: 0.9511 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 8/25\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.1656 - accuracy: 0.9514 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: 0.1595 - val_accuracy: 0.9511 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 9/25\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.1636 - accuracy: 0.9514 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: 0.1596 - val_accuracy: 0.9511 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 10/25\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.1632 - accuracy: 0.9514 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: 0.1582 - val_accuracy: 0.9511 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 11/25\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.1612 - accuracy: 0.9514 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: 0.1583 - val_accuracy: 0.9511 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 12/25\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.1596 - accuracy: 0.9514 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: 0.1551 - val_accuracy: 0.9511 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 13/25\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.1596 - accuracy: 0.9514 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: 0.1595 - val_accuracy: 0.9511 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 14/25\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.1604 - accuracy: 0.9514 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: 0.1570 - val_accuracy: 0.9511 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 15/25\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.1608 - accuracy: 0.9514 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: 0.1553 - val_accuracy: 0.9511 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 16/25\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.1579 - accuracy: 0.9514 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: 0.1538 - val_accuracy: 0.9511 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 17/25\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.1581 - accuracy: 0.9514 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: 0.1559 - val_accuracy: 0.9511 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 18/25\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.1582 - accuracy: 0.9514 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: 0.1554 - val_accuracy: 0.9511 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 19/25\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.1567 - accuracy: 0.9514 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: 0.1534 - val_accuracy: 0.9511 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 20/25\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.1565 - accuracy: 0.9514 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: 0.1530 - val_accuracy: 0.9511 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 21/25\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.1569 - accuracy: 0.9514 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: 0.1534 - val_accuracy: 0.9511 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 22/25\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.1574 - accuracy: 0.9514 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: 0.1533 - val_accuracy: 0.9511 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 23/25\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.1564 - accuracy: 0.9514 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: 0.1546 - val_accuracy: 0.9511 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 24/25\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.1562 - accuracy: 0.9514 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: 0.1532 - val_accuracy: 0.9511 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 25/25\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.1554 - accuracy: 0.9514 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: 0.1560 - val_accuracy: 0.9511 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "voqUo00lAqCZ"
   },
   "source": [
    "# Improving DL Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Op2Frp44uSiX"
   },
   "source": [
    "**Question 11:** Suggest ways to improve your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IImSYWQGBSz6"
   },
   "source": [
    "### Checking For Data Imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZHxCONODMkNN"
   },
   "source": [
    "We check for imbalance because we have a poor recall and precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T08:09:03.757862Z",
     "start_time": "2023-11-09T08:09:03.367210Z"
    },
    "id": "1bF6G8c58SOE"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['stroke'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gzZBB5GMCOld"
   },
   "source": [
    "We have a huge imbalance in the data, this is why we fix it with oversamppling and undersampling.\n",
    "\n",
    "We will oversample this time using the SMOTE() function instead of random oversampling, and this is because SMOTE will generate new data based on the data that we have, so we avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T08:09:05.415424Z",
     "start_time": "2023-11-09T08:09:05.100558Z"
    },
    "id": "US4xON4LBX8I"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4861.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "        4861.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "over = SMOTE()\n",
    "x_new, y_new = over.fit_resample(x, y)\n",
    "\n",
    "plt.hist([y_new])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OmfeUhi1ezb9"
   },
   "source": [
    "Split the balanced dataset between 90% (training and validation), 10% testing\n",
    "Then divide the 90% between 80% training and 20% validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T08:09:06.902712Z",
     "start_time": "2023-11-09T08:09:06.825129Z"
    },
    "id": "IxnYFoPZezb-"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "x_train_val, x_test, y_train_val, y_test = train_test_split(x_new, y_new, test_size=0.1, stratify=y_new)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_val, y_train_val, test_size=0.2, stratify=y_train_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dgyxF74oezcA"
   },
   "source": [
    "Now we will train the model on the balanced data, and tune it on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T08:09:31.057917Z",
     "start_time": "2023-11-09T08:09:10.447577Z"
    },
    "id": "26YTispLEm9N"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.5579 - accuracy: 0.7155 - precision_14: 0.7825 - recall_14: 0.5971 - val_loss: 0.5013 - val_accuracy: 0.7949 - val_precision_14: 0.7739 - val_recall_14: 0.8331\n",
      "Epoch 2/25\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.4976 - accuracy: 0.7850 - precision_14: 0.7521 - recall_14: 0.8503 - val_loss: 0.4785 - val_accuracy: 0.7966 - val_precision_14: 0.8014 - val_recall_14: 0.7886\n",
      "Epoch 3/25\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.4760 - accuracy: 0.7925 - precision_14: 0.7577 - recall_14: 0.8603 - val_loss: 0.4573 - val_accuracy: 0.8017 - val_precision_14: 0.7640 - val_recall_14: 0.8731\n",
      "Epoch 4/25\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.4632 - accuracy: 0.7935 - precision_14: 0.7543 - recall_14: 0.8709 - val_loss: 0.4491 - val_accuracy: 0.8074 - val_precision_14: 0.7862 - val_recall_14: 0.8446\n",
      "Epoch 5/25\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.4553 - accuracy: 0.7923 - precision_14: 0.7533 - recall_14: 0.8691 - val_loss: 0.4439 - val_accuracy: 0.8063 - val_precision_14: 0.7548 - val_recall_14: 0.9074\n",
      "Epoch 6/25\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.4468 - accuracy: 0.7970 - precision_14: 0.7572 - recall_14: 0.8743 - val_loss: 0.4343 - val_accuracy: 0.8120 - val_precision_14: 0.7758 - val_recall_14: 0.8777\n",
      "Epoch 7/25\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.4406 - accuracy: 0.7981 - precision_14: 0.7572 - recall_14: 0.8777 - val_loss: 0.4421 - val_accuracy: 0.8080 - val_precision_14: 0.8018 - val_recall_14: 0.8183\n",
      "Epoch 8/25\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.4360 - accuracy: 0.7995 - precision_14: 0.7608 - recall_14: 0.8740 - val_loss: 0.4263 - val_accuracy: 0.8120 - val_precision_14: 0.7698 - val_recall_14: 0.8903\n",
      "Epoch 9/25\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.4321 - accuracy: 0.7994 - precision_14: 0.7589 - recall_14: 0.8777 - val_loss: 0.4251 - val_accuracy: 0.8160 - val_precision_14: 0.7796 - val_recall_14: 0.8811\n",
      "Epoch 10/25\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.4290 - accuracy: 0.8023 - precision_14: 0.7579 - recall_14: 0.8883 - val_loss: 0.4315 - val_accuracy: 0.8091 - val_precision_14: 0.8016 - val_recall_14: 0.8217\n",
      "Epoch 11/25\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.4260 - accuracy: 0.7994 - precision_14: 0.7584 - recall_14: 0.8789 - val_loss: 0.4193 - val_accuracy: 0.8126 - val_precision_14: 0.7674 - val_recall_14: 0.8971\n",
      "Epoch 12/25\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.4227 - accuracy: 0.8021 - precision_14: 0.7589 - recall_14: 0.8857 - val_loss: 0.4180 - val_accuracy: 0.8114 - val_precision_14: 0.7593 - val_recall_14: 0.9120\n",
      "Epoch 13/25\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.4200 - accuracy: 0.8000 - precision_14: 0.7570 - recall_14: 0.8837 - val_loss: 0.4149 - val_accuracy: 0.8126 - val_precision_14: 0.7612 - val_recall_14: 0.9109\n",
      "Epoch 14/25\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.4160 - accuracy: 0.8027 - precision_14: 0.7613 - recall_14: 0.8820 - val_loss: 0.4209 - val_accuracy: 0.8086 - val_precision_14: 0.7974 - val_recall_14: 0.8274\n",
      "Epoch 15/25\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.4141 - accuracy: 0.8011 - precision_14: 0.7590 - recall_14: 0.8826 - val_loss: 0.4152 - val_accuracy: 0.8074 - val_precision_14: 0.7509 - val_recall_14: 0.9200\n",
      "Epoch 16/25\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.4123 - accuracy: 0.8050 - precision_14: 0.7626 - recall_14: 0.8857 - val_loss: 0.4205 - val_accuracy: 0.8080 - val_precision_14: 0.7435 - val_recall_14: 0.9406\n",
      "Epoch 17/25\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.4060 - accuracy: 0.8061 - precision_14: 0.7640 - recall_14: 0.8860 - val_loss: 0.4079 - val_accuracy: 0.8166 - val_precision_14: 0.7648 - val_recall_14: 0.9143\n",
      "Epoch 18/25\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.4049 - accuracy: 0.8051 - precision_14: 0.7642 - recall_14: 0.8826 - val_loss: 0.3997 - val_accuracy: 0.8229 - val_precision_14: 0.7745 - val_recall_14: 0.9109\n",
      "Epoch 19/25\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.4013 - accuracy: 0.8107 - precision_14: 0.7666 - recall_14: 0.8934 - val_loss: 0.4017 - val_accuracy: 0.8240 - val_precision_14: 0.7969 - val_recall_14: 0.8697\n",
      "Epoch 20/25\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.3983 - accuracy: 0.8104 - precision_14: 0.7699 - recall_14: 0.8854 - val_loss: 0.3943 - val_accuracy: 0.8251 - val_precision_14: 0.7707 - val_recall_14: 0.9257\n",
      "Epoch 21/25\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.3955 - accuracy: 0.8120 - precision_14: 0.7710 - recall_14: 0.8877 - val_loss: 0.3941 - val_accuracy: 0.8257 - val_precision_14: 0.7867 - val_recall_14: 0.8937\n",
      "Epoch 22/25\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.3941 - accuracy: 0.8108 - precision_14: 0.7692 - recall_14: 0.8883 - val_loss: 0.3935 - val_accuracy: 0.8200 - val_precision_14: 0.7966 - val_recall_14: 0.8594\n",
      "Epoch 23/25\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.3905 - accuracy: 0.8151 - precision_14: 0.7733 - recall_14: 0.8917 - val_loss: 0.3908 - val_accuracy: 0.8257 - val_precision_14: 0.7873 - val_recall_14: 0.8926\n",
      "Epoch 24/25\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.3873 - accuracy: 0.8127 - precision_14: 0.7717 - recall_14: 0.8883 - val_loss: 0.3892 - val_accuracy: 0.8257 - val_precision_14: 0.8013 - val_recall_14: 0.8663\n",
      "Epoch 25/25\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.3834 - accuracy: 0.8183 - precision_14: 0.7782 - recall_14: 0.8903 - val_loss: 0.3874 - val_accuracy: 0.8234 - val_precision_14: 0.7985 - val_recall_14: 0.8651\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wAhUAu5JezcC"
   },
   "source": [
    "Evaluate your model on the test set that you kept aside at the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T08:09:35.704538Z",
     "start_time": "2023-11-09T08:09:35.379292Z"
    },
    "id": "utTyIgJLezcD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 3ms/step - loss: 0.3806 - accuracy: 0.8294 - precision_14: 0.8077 - recall_14: 0.8642\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.380567342042923, 0.8293936252593994, 0.807692289352417, 0.8641975522041321]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hhfhpIaWGtz2"
   },
   "source": [
    "We see that the performance gets better when our data became balanced.\n",
    "Now we will try improving our model with other techniques that we learned through the week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ngJVLbRKG7U_"
   },
   "source": [
    "### Model Design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sMdcXspCHxIo"
   },
   "source": [
    "We will introduce batch normalization after each layer and then train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T08:09:41.180557Z",
     "start_time": "2023-11-09T08:09:40.841531Z"
    },
    "id": "yK78-g-hHrmq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_96 (Dense)            (None, 32)                352       \n",
      "                                                                 \n",
      " batch_normalization_70 (Bat  (None, 32)               128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_97 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_71 (Bat  (None, 16)               64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_98 (Dense)            (None, 8)                 136       \n",
      "                                                                 \n",
      " batch_normalization_72 (Bat  (None, 8)                32        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_99 (Dense)            (None, 4)                 36        \n",
      "                                                                 \n",
      " batch_normalization_73 (Bat  (None, 4)                16        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_100 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " batch_normalization_74 (Bat  (None, 2)                8         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_101 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,313\n",
      "Trainable params: 1,189\n",
      "Non-trainable params: 124\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(32, input_dim=10, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(2, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T08:10:19.728524Z",
     "start_time": "2023-11-09T08:09:44.147285Z"
    },
    "id": "REDrQVWLJLs5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "219/219 [==============================] - 5s 6ms/step - loss: 0.6192 - accuracy: 0.6721 - precision: 0.6949 - recall: 0.6137 - val_loss: 0.6157 - val_accuracy: 0.6840 - val_precision: 0.7113 - val_recall: 0.6194\n",
      "Epoch 2/25\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.5424 - accuracy: 0.7500 - precision: 0.7557 - recall: 0.7389 - val_loss: 0.4963 - val_accuracy: 0.7886 - val_precision: 0.7622 - val_recall: 0.8389\n",
      "Epoch 3/25\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.4994 - accuracy: 0.7764 - precision: 0.7634 - recall: 0.8011 - val_loss: 0.4583 - val_accuracy: 0.8034 - val_precision: 0.7810 - val_recall: 0.8434\n",
      "Epoch 4/25\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.4794 - accuracy: 0.7841 - precision: 0.7653 - recall: 0.8197 - val_loss: 0.4449 - val_accuracy: 0.8126 - val_precision: 0.7840 - val_recall: 0.8629\n",
      "Epoch 5/25\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.4641 - accuracy: 0.7875 - precision: 0.7662 - recall: 0.8277 - val_loss: 0.4467 - val_accuracy: 0.7880 - val_precision: 0.8007 - val_recall: 0.7669\n",
      "Epoch 6/25\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.4426 - accuracy: 0.8008 - precision: 0.7748 - recall: 0.8483 - val_loss: 0.4068 - val_accuracy: 0.8234 - val_precision: 0.7836 - val_recall: 0.8937\n",
      "Epoch 7/25\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.4456 - accuracy: 0.7947 - precision: 0.7636 - recall: 0.8537 - val_loss: 0.4078 - val_accuracy: 0.8166 - val_precision: 0.7764 - val_recall: 0.8891\n",
      "Epoch 8/25\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.4325 - accuracy: 0.8011 - precision: 0.7698 - recall: 0.8591 - val_loss: 0.4009 - val_accuracy: 0.8229 - val_precision: 0.7862 - val_recall: 0.8869\n",
      "Epoch 9/25\n",
      "219/219 [==============================] - 2s 8ms/step - loss: 0.4341 - accuracy: 0.7995 - precision: 0.7693 - recall: 0.8557 - val_loss: 0.4077 - val_accuracy: 0.8223 - val_precision: 0.7872 - val_recall: 0.8834\n",
      "Epoch 10/25\n",
      "219/219 [==============================] - 2s 7ms/step - loss: 0.4286 - accuracy: 0.8040 - precision: 0.7780 - recall: 0.8509 - val_loss: 0.4065 - val_accuracy: 0.8263 - val_precision: 0.7631 - val_recall: 0.9463\n",
      "Epoch 11/25\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.4217 - accuracy: 0.8098 - precision: 0.7818 - recall: 0.8597 - val_loss: 0.3938 - val_accuracy: 0.8360 - val_precision: 0.7865 - val_recall: 0.9223\n",
      "Epoch 12/25\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.4164 - accuracy: 0.8088 - precision: 0.7806 - recall: 0.8591 - val_loss: 0.4139 - val_accuracy: 0.8149 - val_precision: 0.7662 - val_recall: 0.9063\n",
      "Epoch 13/25\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.4218 - accuracy: 0.8073 - precision: 0.7830 - recall: 0.8503 - val_loss: 0.3901 - val_accuracy: 0.8337 - val_precision: 0.7885 - val_recall: 0.9120\n",
      "Epoch 14/25\n",
      "219/219 [==============================] - 1s 7ms/step - loss: 0.4113 - accuracy: 0.8107 - precision: 0.7825 - recall: 0.8606 - val_loss: 0.3843 - val_accuracy: 0.8400 - val_precision: 0.7960 - val_recall: 0.9143\n",
      "Epoch 15/25\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.4123 - accuracy: 0.8084 - precision: 0.7812 - recall: 0.8569 - val_loss: 0.3920 - val_accuracy: 0.8269 - val_precision: 0.7889 - val_recall: 0.8926\n",
      "Epoch 16/25\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.4023 - accuracy: 0.8138 - precision: 0.7854 - recall: 0.8637 - val_loss: 0.3794 - val_accuracy: 0.8389 - val_precision: 0.7974 - val_recall: 0.9086\n",
      "Epoch 17/25\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.4051 - accuracy: 0.8175 - precision: 0.7907 - recall: 0.8637 - val_loss: 0.3830 - val_accuracy: 0.8423 - val_precision: 0.8110 - val_recall: 0.8926\n",
      "Epoch 18/25\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.4057 - accuracy: 0.8123 - precision: 0.7842 - recall: 0.8617 - val_loss: 0.3921 - val_accuracy: 0.8320 - val_precision: 0.7840 - val_recall: 0.9166\n",
      "Epoch 19/25\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.4002 - accuracy: 0.8193 - precision: 0.7914 - recall: 0.8671 - val_loss: 0.3887 - val_accuracy: 0.8269 - val_precision: 0.7837 - val_recall: 0.9029\n",
      "Epoch 20/25\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.3943 - accuracy: 0.8184 - precision: 0.7893 - recall: 0.8689 - val_loss: 0.3689 - val_accuracy: 0.8366 - val_precision: 0.8298 - val_recall: 0.8469\n",
      "Epoch 21/25\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.3846 - accuracy: 0.8293 - precision: 0.8008 - recall: 0.8766 - val_loss: 0.3635 - val_accuracy: 0.8406 - val_precision: 0.8239 - val_recall: 0.8663\n",
      "Epoch 22/25\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.3894 - accuracy: 0.8217 - precision: 0.7991 - recall: 0.8594 - val_loss: 0.3674 - val_accuracy: 0.8411 - val_precision: 0.7958 - val_recall: 0.9177\n",
      "Epoch 23/25\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.3921 - accuracy: 0.8215 - precision: 0.7930 - recall: 0.8703 - val_loss: 0.3587 - val_accuracy: 0.8491 - val_precision: 0.7935 - val_recall: 0.9440\n",
      "Epoch 24/25\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.3902 - accuracy: 0.8240 - precision: 0.7965 - recall: 0.8703 - val_loss: 0.3572 - val_accuracy: 0.8480 - val_precision: 0.8136 - val_recall: 0.9029\n",
      "Epoch 25/25\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.3876 - accuracy: 0.8193 - precision: 0.7954 - recall: 0.8597 - val_loss: 0.3669 - val_accuracy: 0.8440 - val_precision: 0.7911 - val_recall: 0.9349\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', 'Precision', 'Recall'])\n",
    "\n",
    "history2 = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T08:10:23.528899Z",
     "start_time": "2023-11-09T08:10:23.248547Z"
    },
    "id": "eenpPyr_ezcH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 3ms/step - loss: 0.3565 - accuracy: 0.8417 - precision: 0.7833 - recall: 0.9444\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.35648778080940247,\n",
       " 0.8417266011238098,\n",
       " 0.7832764387130737,\n",
       " 0.9444444179534912]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hhkSEThVKEdm"
   },
   "source": [
    "We see that we are achieving better metrics with batch normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use Hyperparameter Tuning to see if it gets better accuracy. However, it's not part of the assessment but just for learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T08:10:41.901126Z",
     "start_time": "2023-11-09T08:10:41.881184Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "#create a fn that create the model when called\n",
    "def create_model():\n",
    "\n",
    "  model = Sequential()\n",
    "\n",
    "  model.add(Dense(32, input_dim=10, activation='relu'))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Dense(16, activation='relu'))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Dense(8, activation='relu'))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Dense(4, activation='relu'))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Dense(2, activation='relu'))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Dense(1, activation='sigmoid'))\n",
    "  model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "  return model \n",
    "\n",
    "model_wrapper = KerasClassifier(build_fn=create_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T08:19:19.769122Z",
     "start_time": "2023-11-09T08:10:42.957742Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Epoch 1/50\n",
      "94/94 [==============================] - 4s 3ms/step - loss: 0.7024 - accuracy: 0.6237 - precision_15: 0.6348 - recall_15: 0.5718\n",
      "Epoch 2/50\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.5855 - accuracy: 0.7143 - precision_15: 0.7052 - recall_15: 0.7305\n",
      "Epoch 3/50\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.5426 - accuracy: 0.7495 - precision_15: 0.7334 - recall_15: 0.7792\n",
      "Epoch 4/50\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.5127 - accuracy: 0.7658 - precision_15: 0.7486 - recall_15: 0.7960\n",
      "Epoch 5/50\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.4904 - accuracy: 0.7814 - precision_15: 0.7591 - recall_15: 0.8206\n",
      "Epoch 6/50\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.4813 - accuracy: 0.7823 - precision_15: 0.7556 - recall_15: 0.8305\n",
      "Epoch 7/50\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.4669 - accuracy: 0.7883 - precision_15: 0.7569 - recall_15: 0.8456\n",
      "Epoch 8/50\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.4538 - accuracy: 0.7981 - precision_15: 0.7678 - recall_15: 0.8512\n",
      "Epoch 9/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4509 - accuracy: 0.7988 - precision_15: 0.7632 - recall_15: 0.8629\n",
      "Epoch 10/50\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.4393 - accuracy: 0.8003 - precision_15: 0.7677 - recall_15: 0.8577\n",
      "Epoch 11/50\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.4355 - accuracy: 0.7998 - precision_15: 0.7685 - recall_15: 0.8547\n",
      "Epoch 12/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4299 - accuracy: 0.8005 - precision_15: 0.7686 - recall_15: 0.8564\n",
      "Epoch 13/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4337 - accuracy: 0.8033 - precision_15: 0.7746 - recall_15: 0.8521\n",
      "Epoch 14/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4231 - accuracy: 0.8095 - precision_15: 0.7789 - recall_15: 0.8611\n",
      "Epoch 15/50\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.4128 - accuracy: 0.8065 - precision_15: 0.7763 - recall_15: 0.8577\n",
      "Epoch 16/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4210 - accuracy: 0.8093 - precision_15: 0.7775 - recall_15: 0.8633\n",
      "Epoch 17/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4121 - accuracy: 0.8123 - precision_15: 0.7860 - recall_15: 0.8551\n",
      "Epoch 18/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4094 - accuracy: 0.8071 - precision_15: 0.7768 - recall_15: 0.8586\n",
      "Epoch 19/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4097 - accuracy: 0.8123 - precision_15: 0.7785 - recall_15: 0.8698\n",
      "Epoch 20/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4098 - accuracy: 0.8084 - precision_15: 0.7791 - recall_15: 0.8577\n",
      "Epoch 21/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4030 - accuracy: 0.8174 - precision_15: 0.7903 - recall_15: 0.8611\n",
      "Epoch 22/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4129 - accuracy: 0.8125 - precision_15: 0.7861 - recall_15: 0.8555\n",
      "Epoch 23/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4047 - accuracy: 0.8200 - precision_15: 0.7894 - recall_15: 0.8698\n",
      "Epoch 24/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3982 - accuracy: 0.8187 - precision_15: 0.7910 - recall_15: 0.8633\n",
      "Epoch 25/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3998 - accuracy: 0.8123 - precision_15: 0.7844 - recall_15: 0.8581\n",
      "Epoch 26/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3936 - accuracy: 0.8200 - precision_15: 0.7933 - recall_15: 0.8624\n",
      "Epoch 27/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3973 - accuracy: 0.8213 - precision_15: 0.7915 - recall_15: 0.8693\n",
      "Epoch 28/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3852 - accuracy: 0.8296 - precision_15: 0.7956 - recall_15: 0.8844\n",
      "Epoch 29/50\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3958 - accuracy: 0.8189 - precision_15: 0.7925 - recall_15: 0.8611\n",
      "Epoch 30/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3954 - accuracy: 0.8210 - precision_15: 0.7917 - recall_15: 0.8685\n",
      "Epoch 31/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3857 - accuracy: 0.8264 - precision_15: 0.7983 - recall_15: 0.8706\n",
      "Epoch 32/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3857 - accuracy: 0.8223 - precision_15: 0.7942 - recall_15: 0.8672\n",
      "Epoch 33/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3797 - accuracy: 0.8285 - precision_15: 0.8003 - recall_15: 0.8728\n",
      "Epoch 34/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3886 - accuracy: 0.8270 - precision_15: 0.7928 - recall_15: 0.8827\n",
      "Epoch 35/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3885 - accuracy: 0.8258 - precision_15: 0.8005 - recall_15: 0.8650\n",
      "Epoch 36/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3835 - accuracy: 0.8243 - precision_15: 0.7911 - recall_15: 0.8784\n",
      "Epoch 37/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3811 - accuracy: 0.8275 - precision_15: 0.8014 - recall_15: 0.8680\n",
      "Epoch 38/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3799 - accuracy: 0.8273 - precision_15: 0.8008 - recall_15: 0.8685\n",
      "Epoch 39/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3719 - accuracy: 0.8333 - precision_15: 0.8032 - recall_15: 0.8801\n",
      "Epoch 40/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3756 - accuracy: 0.8333 - precision_15: 0.8037 - recall_15: 0.8793\n",
      "Epoch 41/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3779 - accuracy: 0.8307 - precision_15: 0.8057 - recall_15: 0.8689\n",
      "Epoch 42/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3752 - accuracy: 0.8307 - precision_15: 0.8047 - recall_15: 0.8706\n",
      "Epoch 43/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3737 - accuracy: 0.8358 - precision_15: 0.8110 - recall_15: 0.8732\n",
      "Epoch 44/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3703 - accuracy: 0.8356 - precision_15: 0.8062 - recall_15: 0.8810\n",
      "Epoch 45/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3715 - accuracy: 0.8367 - precision_15: 0.8042 - recall_15: 0.8875\n",
      "Epoch 46/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3762 - accuracy: 0.8348 - precision_15: 0.8042 - recall_15: 0.8823\n",
      "Epoch 47/50\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3653 - accuracy: 0.8414 - precision_15: 0.8152 - recall_15: 0.8806\n",
      "Epoch 48/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3700 - accuracy: 0.8333 - precision_15: 0.8030 - recall_15: 0.8806\n",
      "Epoch 49/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3618 - accuracy: 0.8375 - precision_15: 0.8123 - recall_15: 0.8754\n",
      "Epoch 50/50\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3625 - accuracy: 0.8380 - precision_15: 0.8083 - recall_15: 0.8836\n",
      "47/47 [==============================] - 1s 2ms/step - loss: 0.3790 - accuracy: 0.8435 - precision_15: 0.7996 - recall_15: 0.9221\n",
      "[CV 1/3] END ..........batch_size=50, epochs=50;, score=0.844 total time=  23.4s\n",
      "Epoch 1/50\n",
      "94/94 [==============================] - 5s 4ms/step - loss: 0.6694 - accuracy: 0.6022 - precision_16: 0.5795 - recall_16: 0.7757\n",
      "Epoch 2/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5850 - accuracy: 0.7100 - precision_16: 0.6597 - recall_16: 0.8804\n",
      "Epoch 3/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5360 - accuracy: 0.7508 - precision_16: 0.6960 - recall_16: 0.8999\n",
      "Epoch 4/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4975 - accuracy: 0.7752 - precision_16: 0.7281 - recall_16: 0.8859\n",
      "Epoch 5/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4726 - accuracy: 0.7889 - precision_16: 0.7449 - recall_16: 0.8855\n",
      "Epoch 6/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4617 - accuracy: 0.7921 - precision_16: 0.7495 - recall_16: 0.8842\n",
      "Epoch 7/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4550 - accuracy: 0.7921 - precision_16: 0.7489 - recall_16: 0.8855\n",
      "Epoch 8/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4426 - accuracy: 0.8063 - precision_16: 0.7649 - recall_16: 0.8902\n",
      "Epoch 9/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4358 - accuracy: 0.8020 - precision_16: 0.7644 - recall_16: 0.8791\n",
      "Epoch 10/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.8118 - precision_16: 0.7727 - recall_16: 0.8893\n",
      "Epoch 11/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4305 - accuracy: 0.8084 - precision_16: 0.7677 - recall_16: 0.8902\n",
      "Epoch 12/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4244 - accuracy: 0.8090 - precision_16: 0.7670 - recall_16: 0.8936\n",
      "Epoch 13/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4218 - accuracy: 0.8144 - precision_16: 0.7792 - recall_16: 0.8830\n",
      "Epoch 14/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4097 - accuracy: 0.8202 - precision_16: 0.7757 - recall_16: 0.9063\n",
      "Epoch 15/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4087 - accuracy: 0.8120 - precision_16: 0.7731 - recall_16: 0.8889\n",
      "Epoch 16/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4067 - accuracy: 0.8187 - precision_16: 0.7798 - recall_16: 0.8936\n",
      "Epoch 17/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4075 - accuracy: 0.8140 - precision_16: 0.7751 - recall_16: 0.8902\n",
      "Epoch 18/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4068 - accuracy: 0.8178 - precision_16: 0.7807 - recall_16: 0.8893\n",
      "Epoch 19/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4031 - accuracy: 0.8193 - precision_16: 0.7828 - recall_16: 0.8893\n",
      "Epoch 20/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3948 - accuracy: 0.8283 - precision_16: 0.7961 - recall_16: 0.8876\n",
      "Epoch 21/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3921 - accuracy: 0.8268 - precision_16: 0.7922 - recall_16: 0.8910\n",
      "Epoch 22/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3913 - accuracy: 0.8320 - precision_16: 0.7956 - recall_16: 0.8982\n",
      "Epoch 23/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3939 - accuracy: 0.8202 - precision_16: 0.7880 - recall_16: 0.8813\n",
      "Epoch 24/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3812 - accuracy: 0.8307 - precision_16: 0.7919 - recall_16: 0.9020\n",
      "Epoch 25/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3888 - accuracy: 0.8268 - precision_16: 0.7925 - recall_16: 0.8906\n",
      "Epoch 26/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3790 - accuracy: 0.8279 - precision_16: 0.7909 - recall_16: 0.8965\n",
      "Epoch 27/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3778 - accuracy: 0.8341 - precision_16: 0.8002 - recall_16: 0.8953\n",
      "Epoch 28/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3851 - accuracy: 0.8275 - precision_16: 0.7974 - recall_16: 0.8830\n",
      "Epoch 29/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3786 - accuracy: 0.8322 - precision_16: 0.7931 - recall_16: 0.9037\n",
      "Epoch 30/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3756 - accuracy: 0.8320 - precision_16: 0.8004 - recall_16: 0.8893\n",
      "Epoch 31/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3790 - accuracy: 0.8352 - precision_16: 0.8062 - recall_16: 0.8872\n",
      "Epoch 32/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3648 - accuracy: 0.8433 - precision_16: 0.8104 - recall_16: 0.9008\n",
      "Epoch 33/50\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3703 - accuracy: 0.8378 - precision_16: 0.8090 - recall_16: 0.8889\n",
      "Epoch 34/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3599 - accuracy: 0.8440 - precision_16: 0.8069 - recall_16: 0.9088\n",
      "Epoch 35/50\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3622 - accuracy: 0.8420 - precision_16: 0.8114 - recall_16: 0.8957\n",
      "Epoch 36/50\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3664 - accuracy: 0.8429 - precision_16: 0.8095 - recall_16: 0.9012\n",
      "Epoch 37/50\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3538 - accuracy: 0.8487 - precision_16: 0.8177 - recall_16: 0.9016\n",
      "Epoch 38/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3566 - accuracy: 0.8472 - precision_16: 0.8150 - recall_16: 0.9025\n",
      "Epoch 39/50\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3636 - accuracy: 0.8378 - precision_16: 0.8073 - recall_16: 0.8919\n",
      "Epoch 40/50\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.3554 - accuracy: 0.8513 - precision_16: 0.8205 - recall_16: 0.9033\n",
      "Epoch 41/50\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3630 - accuracy: 0.8425 - precision_16: 0.8040 - recall_16: 0.9101\n",
      "Epoch 42/50\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3551 - accuracy: 0.8427 - precision_16: 0.8085 - recall_16: 0.9025\n",
      "Epoch 43/50\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.3456 - accuracy: 0.8504 - precision_16: 0.8192 - recall_16: 0.9033\n",
      "Epoch 44/50\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.3583 - accuracy: 0.8450 - precision_16: 0.8158 - recall_16: 0.8957\n",
      "Epoch 45/50\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3454 - accuracy: 0.8515 - precision_16: 0.8193 - recall_16: 0.9059\n",
      "Epoch 46/50\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3489 - accuracy: 0.8487 - precision_16: 0.8182 - recall_16: 0.9008\n",
      "Epoch 47/50\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3444 - accuracy: 0.8487 - precision_16: 0.8172 - recall_16: 0.9025\n",
      "Epoch 48/50\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.3436 - accuracy: 0.8483 - precision_16: 0.8180 - recall_16: 0.8999\n",
      "Epoch 49/50\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.3495 - accuracy: 0.8506 - precision_16: 0.8203 - recall_16: 0.9020\n",
      "Epoch 50/50\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.3422 - accuracy: 0.8562 - precision_16: 0.8208 - recall_16: 0.9152\n",
      "47/47 [==============================] - 1s 3ms/step - loss: 0.3352 - accuracy: 0.8556 - precision_16: 0.8172 - recall_16: 0.9081\n",
      "[CV 2/3] END ..........batch_size=50, epochs=50;, score=0.856 total time=  27.7s\n",
      "Epoch 1/50\n",
      "94/94 [==============================] - 6s 4ms/step - loss: 0.6306 - accuracy: 0.6717 - precision_17: 0.6475 - recall_17: 0.7473\n",
      "Epoch 2/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5320 - accuracy: 0.7372 - precision_17: 0.7019 - recall_17: 0.8209\n",
      "Epoch 3/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5046 - accuracy: 0.7638 - precision_17: 0.7284 - recall_17: 0.8381\n",
      "Epoch 4/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4852 - accuracy: 0.7748 - precision_17: 0.7337 - recall_17: 0.8597\n",
      "Epoch 5/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4749 - accuracy: 0.7790 - precision_17: 0.7421 - recall_17: 0.8523\n",
      "Epoch 6/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4673 - accuracy: 0.7885 - precision_17: 0.7557 - recall_17: 0.8498\n",
      "Epoch 7/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4640 - accuracy: 0.7801 - precision_17: 0.7446 - recall_17: 0.8498\n",
      "Epoch 8/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.7846 - precision_17: 0.7504 - recall_17: 0.8502\n",
      "Epoch 9/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4553 - accuracy: 0.7885 - precision_17: 0.7523 - recall_17: 0.8575\n",
      "Epoch 10/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4456 - accuracy: 0.7936 - precision_17: 0.7502 - recall_17: 0.8777\n",
      "Epoch 11/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4444 - accuracy: 0.7913 - precision_17: 0.7503 - recall_17: 0.8704\n",
      "Epoch 12/50\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.4326 - accuracy: 0.7983 - precision_17: 0.7621 - recall_17: 0.8648\n",
      "Epoch 13/50\n",
      "94/94 [==============================] - 1s 8ms/step - loss: 0.4317 - accuracy: 0.8007 - precision_17: 0.7631 - recall_17: 0.8696\n",
      "Epoch 14/50\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.4313 - accuracy: 0.7955 - precision_17: 0.7574 - recall_17: 0.8670\n",
      "Epoch 15/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.7951 - precision_17: 0.7563 - recall_17: 0.8683\n",
      "Epoch 16/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4271 - accuracy: 0.8018 - precision_17: 0.7612 - recall_17: 0.8769\n",
      "Epoch 17/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4199 - accuracy: 0.8039 - precision_17: 0.7645 - recall_17: 0.8760\n",
      "Epoch 18/50\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.4144 - accuracy: 0.8073 - precision_17: 0.7695 - recall_17: 0.8752\n",
      "Epoch 19/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4200 - accuracy: 0.8090 - precision_17: 0.7745 - recall_17: 0.8696\n",
      "Epoch 20/50\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.4096 - accuracy: 0.8099 - precision_17: 0.7673 - recall_17: 0.8872\n",
      "Epoch 21/50\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.4099 - accuracy: 0.8114 - precision_17: 0.7705 - recall_17: 0.8846\n",
      "Epoch 22/50\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.4090 - accuracy: 0.8095 - precision_17: 0.7706 - recall_17: 0.8790\n",
      "Epoch 23/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4135 - accuracy: 0.8103 - precision_17: 0.7701 - recall_17: 0.8825\n",
      "Epoch 24/50\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.4057 - accuracy: 0.8180 - precision_17: 0.7773 - recall_17: 0.8894\n",
      "Epoch 25/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4007 - accuracy: 0.8189 - precision_17: 0.7782 - recall_17: 0.8898\n",
      "Epoch 26/50\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.4022 - accuracy: 0.8187 - precision_17: 0.7835 - recall_17: 0.8786\n",
      "Epoch 27/50\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.4052 - accuracy: 0.8170 - precision_17: 0.7817 - recall_17: 0.8773\n",
      "Epoch 28/50\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3951 - accuracy: 0.8208 - precision_17: 0.7824 - recall_17: 0.8868\n",
      "Epoch 29/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3934 - accuracy: 0.8178 - precision_17: 0.7784 - recall_17: 0.8864\n",
      "Epoch 30/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3964 - accuracy: 0.8204 - precision_17: 0.7850 - recall_17: 0.8803\n",
      "Epoch 31/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3876 - accuracy: 0.8234 - precision_17: 0.7864 - recall_17: 0.8859\n",
      "Epoch 32/50\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3913 - accuracy: 0.8174 - precision_17: 0.7819 - recall_17: 0.8782\n",
      "Epoch 33/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3888 - accuracy: 0.8172 - precision_17: 0.7774 - recall_17: 0.8868\n",
      "Epoch 34/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3891 - accuracy: 0.8243 - precision_17: 0.7818 - recall_17: 0.8975\n",
      "Epoch 35/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3811 - accuracy: 0.8277 - precision_17: 0.7920 - recall_17: 0.8868\n",
      "Epoch 36/50\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3780 - accuracy: 0.8305 - precision_17: 0.7908 - recall_17: 0.8967\n",
      "Epoch 37/50\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3855 - accuracy: 0.8255 - precision_17: 0.7868 - recall_17: 0.8911\n",
      "Epoch 38/50\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.3819 - accuracy: 0.8225 - precision_17: 0.7828 - recall_17: 0.8907\n",
      "Epoch 39/50\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3734 - accuracy: 0.8309 - precision_17: 0.7921 - recall_17: 0.8954\n",
      "Epoch 40/50\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3810 - accuracy: 0.8266 - precision_17: 0.7889 - recall_17: 0.8898\n",
      "Epoch 41/50\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3847 - accuracy: 0.8206 - precision_17: 0.7878 - recall_17: 0.8756\n",
      "Epoch 42/50\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3807 - accuracy: 0.8243 - precision_17: 0.7867 - recall_17: 0.8876\n",
      "Epoch 43/50\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3800 - accuracy: 0.8251 - precision_17: 0.7886 - recall_17: 0.8864\n",
      "Epoch 44/50\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.3765 - accuracy: 0.8275 - precision_17: 0.7931 - recall_17: 0.8842\n",
      "Epoch 45/50\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3766 - accuracy: 0.8283 - precision_17: 0.7934 - recall_17: 0.8859\n",
      "Epoch 46/50\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3773 - accuracy: 0.8320 - precision_17: 0.7940 - recall_17: 0.8945\n",
      "Epoch 47/50\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.3711 - accuracy: 0.8333 - precision_17: 0.8014 - recall_17: 0.8842\n",
      "Epoch 48/50\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3757 - accuracy: 0.8339 - precision_17: 0.7966 - recall_17: 0.8950\n",
      "Epoch 49/50\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3739 - accuracy: 0.8339 - precision_17: 0.7995 - recall_17: 0.8894\n",
      "Epoch 50/50\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.3687 - accuracy: 0.8326 - precision_17: 0.7961 - recall_17: 0.8924\n",
      "47/47 [==============================] - 1s 4ms/step - loss: 0.3750 - accuracy: 0.8341 - precision_17: 0.7883 - recall_17: 0.9176\n",
      "[CV 3/3] END ..........batch_size=50, epochs=50;, score=0.834 total time=  29.7s\n",
      "Epoch 1/100\n",
      "94/94 [==============================] - 7s 4ms/step - loss: 0.6516 - accuracy: 0.6474 - precision_18: 0.6068 - recall_18: 0.8254\n",
      "Epoch 2/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5772 - accuracy: 0.7510 - precision_18: 0.6956 - recall_18: 0.8870\n",
      "Epoch 3/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5310 - accuracy: 0.7733 - precision_18: 0.7290 - recall_18: 0.8655\n",
      "Epoch 4/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5042 - accuracy: 0.7745 - precision_18: 0.7339 - recall_18: 0.8573\n",
      "Epoch 5/100\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.4805 - accuracy: 0.7846 - precision_18: 0.7451 - recall_18: 0.8611\n",
      "Epoch 6/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4641 - accuracy: 0.7891 - precision_18: 0.7499 - recall_18: 0.8637\n",
      "Epoch 7/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4542 - accuracy: 0.7863 - precision_18: 0.7476 - recall_18: 0.8607\n",
      "Epoch 8/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.7938 - precision_18: 0.7529 - recall_18: 0.8711\n",
      "Epoch 9/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4418 - accuracy: 0.7936 - precision_18: 0.7536 - recall_18: 0.8689\n",
      "Epoch 10/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4284 - accuracy: 0.8011 - precision_18: 0.7596 - recall_18: 0.8775\n",
      "Epoch 11/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4198 - accuracy: 0.8086 - precision_18: 0.7645 - recall_18: 0.8887\n",
      "Epoch 12/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4159 - accuracy: 0.8043 - precision_18: 0.7619 - recall_18: 0.8818\n",
      "Epoch 13/100\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.4114 - accuracy: 0.8090 - precision_18: 0.7644 - recall_18: 0.8900\n",
      "Epoch 14/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4034 - accuracy: 0.8088 - precision_18: 0.7693 - recall_18: 0.8788\n",
      "Epoch 15/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4063 - accuracy: 0.8084 - precision_18: 0.7688 - recall_18: 0.8788\n",
      "Epoch 16/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4009 - accuracy: 0.8125 - precision_18: 0.7682 - recall_18: 0.8918\n",
      "Epoch 17/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.4004 - accuracy: 0.8155 - precision_18: 0.7700 - recall_18: 0.8965\n",
      "Epoch 18/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3928 - accuracy: 0.8153 - precision_18: 0.7697 - recall_18: 0.8965\n",
      "Epoch 19/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3896 - accuracy: 0.8195 - precision_18: 0.7792 - recall_18: 0.8887\n",
      "Epoch 20/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3812 - accuracy: 0.8208 - precision_18: 0.7739 - recall_18: 0.9034\n",
      "Epoch 21/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3848 - accuracy: 0.8198 - precision_18: 0.7768 - recall_18: 0.8944\n",
      "Epoch 22/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3819 - accuracy: 0.8193 - precision_18: 0.7756 - recall_18: 0.8956\n",
      "Epoch 23/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3818 - accuracy: 0.8234 - precision_18: 0.7790 - recall_18: 0.9000\n",
      "Epoch 24/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3791 - accuracy: 0.8234 - precision_18: 0.7770 - recall_18: 0.9043\n",
      "Epoch 25/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3739 - accuracy: 0.8258 - precision_18: 0.7820 - recall_18: 0.9004\n",
      "Epoch 26/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3746 - accuracy: 0.8258 - precision_18: 0.7808 - recall_18: 0.9030\n",
      "Epoch 27/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3750 - accuracy: 0.8266 - precision_18: 0.7828 - recall_18: 0.9013\n",
      "Epoch 28/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3696 - accuracy: 0.8290 - precision_18: 0.7826 - recall_18: 0.9082\n",
      "Epoch 29/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3725 - accuracy: 0.8309 - precision_18: 0.7904 - recall_18: 0.8978\n",
      "Epoch 30/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3654 - accuracy: 0.8270 - precision_18: 0.7842 - recall_18: 0.8995\n",
      "Epoch 31/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3654 - accuracy: 0.8322 - precision_18: 0.7844 - recall_18: 0.9133\n",
      "Epoch 32/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3616 - accuracy: 0.8309 - precision_18: 0.7859 - recall_18: 0.9069\n",
      "Epoch 33/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3558 - accuracy: 0.8324 - precision_18: 0.7908 - recall_18: 0.9013\n",
      "Epoch 34/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3649 - accuracy: 0.8294 - precision_18: 0.7828 - recall_18: 0.9090\n",
      "Epoch 35/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3654 - accuracy: 0.8288 - precision_18: 0.7846 - recall_18: 0.9034\n",
      "Epoch 36/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3558 - accuracy: 0.8324 - precision_18: 0.7932 - recall_18: 0.8965\n",
      "Epoch 37/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3563 - accuracy: 0.8408 - precision_18: 0.7932 - recall_18: 0.9194\n",
      "Epoch 38/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3575 - accuracy: 0.8358 - precision_18: 0.7972 - recall_18: 0.8982\n",
      "Epoch 39/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3485 - accuracy: 0.8390 - precision_18: 0.7954 - recall_18: 0.9103\n",
      "Epoch 40/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3517 - accuracy: 0.8378 - precision_18: 0.7976 - recall_18: 0.9025\n",
      "Epoch 41/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3524 - accuracy: 0.8393 - precision_18: 0.7953 - recall_18: 0.9112\n",
      "Epoch 42/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3421 - accuracy: 0.8427 - precision_18: 0.8012 - recall_18: 0.9090\n",
      "Epoch 43/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3460 - accuracy: 0.8446 - precision_18: 0.8030 - recall_18: 0.9107\n",
      "Epoch 44/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3410 - accuracy: 0.8478 - precision_18: 0.8030 - recall_18: 0.9194\n",
      "Epoch 45/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3500 - accuracy: 0.8382 - precision_18: 0.7967 - recall_18: 0.9056\n",
      "Epoch 46/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3478 - accuracy: 0.8455 - precision_18: 0.8029 - recall_18: 0.9133\n",
      "Epoch 47/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3347 - accuracy: 0.8418 - precision_18: 0.8011 - recall_18: 0.9069\n",
      "Epoch 48/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3420 - accuracy: 0.8457 - precision_18: 0.8041 - recall_18: 0.9116\n",
      "Epoch 49/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3468 - accuracy: 0.8390 - precision_18: 0.7995 - recall_18: 0.9025\n",
      "Epoch 50/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3357 - accuracy: 0.8461 - precision_18: 0.8057 - recall_18: 0.9099\n",
      "Epoch 51/100\n",
      "94/94 [==============================] - 1s 5ms/step - loss: 0.3412 - accuracy: 0.8453 - precision_18: 0.8026 - recall_18: 0.9133\n",
      "Epoch 52/100\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.3381 - accuracy: 0.8446 - precision_18: 0.8035 - recall_18: 0.9099\n",
      "Epoch 53/100\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.3342 - accuracy: 0.8478 - precision_18: 0.8030 - recall_18: 0.9194\n",
      "Epoch 54/100\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.3350 - accuracy: 0.8495 - precision_18: 0.8087 - recall_18: 0.9133\n",
      "Epoch 55/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3316 - accuracy: 0.8444 - precision_18: 0.8037 - recall_18: 0.9090\n",
      "Epoch 56/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3305 - accuracy: 0.8517 - precision_18: 0.8087 - recall_18: 0.9189\n",
      "Epoch 57/100\n",
      "94/94 [==============================] - 1s 5ms/step - loss: 0.3313 - accuracy: 0.8530 - precision_18: 0.8113 - recall_18: 0.9176\n",
      "Epoch 58/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3303 - accuracy: 0.8526 - precision_18: 0.8169 - recall_18: 0.9064\n",
      "Epoch 59/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3294 - accuracy: 0.8517 - precision_18: 0.8076 - recall_18: 0.9211\n",
      "Epoch 60/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3416 - accuracy: 0.8508 - precision_18: 0.8075 - recall_18: 0.9189\n",
      "Epoch 61/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3255 - accuracy: 0.8579 - precision_18: 0.8160 - recall_18: 0.9219\n",
      "Epoch 62/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3306 - accuracy: 0.8526 - precision_18: 0.8116 - recall_18: 0.9159\n",
      "Epoch 63/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3277 - accuracy: 0.8573 - precision_18: 0.8170 - recall_18: 0.9185\n",
      "Epoch 64/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3254 - accuracy: 0.8526 - precision_18: 0.8131 - recall_18: 0.9133\n",
      "Epoch 65/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3231 - accuracy: 0.8588 - precision_18: 0.8183 - recall_18: 0.9202\n",
      "Epoch 66/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3294 - accuracy: 0.8474 - precision_18: 0.8040 - recall_18: 0.9163\n",
      "Epoch 67/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3222 - accuracy: 0.8532 - precision_18: 0.8090 - recall_18: 0.9224\n",
      "Epoch 68/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3151 - accuracy: 0.8607 - precision_18: 0.8231 - recall_18: 0.9168\n",
      "Epoch 69/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3166 - accuracy: 0.8553 - precision_18: 0.8121 - recall_18: 0.9224\n",
      "Epoch 70/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3179 - accuracy: 0.8547 - precision_18: 0.8142 - recall_18: 0.9168\n",
      "Epoch 71/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3194 - accuracy: 0.8558 - precision_18: 0.8141 - recall_18: 0.9198\n",
      "Epoch 72/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3263 - accuracy: 0.8560 - precision_18: 0.8099 - recall_18: 0.9280\n",
      "Epoch 73/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3162 - accuracy: 0.8588 - precision_18: 0.8158 - recall_18: 0.9245\n",
      "Epoch 74/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3283 - accuracy: 0.8583 - precision_18: 0.8184 - recall_18: 0.9189\n",
      "Epoch 75/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3198 - accuracy: 0.8562 - precision_18: 0.8124 - recall_18: 0.9241\n",
      "Epoch 76/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3209 - accuracy: 0.8515 - precision_18: 0.8134 - recall_18: 0.9099\n",
      "Epoch 77/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3092 - accuracy: 0.8613 - precision_18: 0.8140 - recall_18: 0.9345\n",
      "Epoch 78/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3295 - accuracy: 0.8526 - precision_18: 0.8167 - recall_18: 0.9069\n",
      "Epoch 79/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3158 - accuracy: 0.8583 - precision_18: 0.8191 - recall_18: 0.9176\n",
      "Epoch 80/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3190 - accuracy: 0.8609 - precision_18: 0.8144 - recall_18: 0.9327\n",
      "Epoch 81/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3154 - accuracy: 0.8601 - precision_18: 0.8179 - recall_18: 0.9241\n",
      "Epoch 82/100\n",
      "94/94 [==============================] - 1s 5ms/step - loss: 0.3086 - accuracy: 0.8611 - precision_18: 0.8176 - recall_18: 0.9276\n",
      "Epoch 83/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3186 - accuracy: 0.8523 - precision_18: 0.8176 - recall_18: 0.9047\n",
      "Epoch 84/100\n",
      "94/94 [==============================] - 1s 5ms/step - loss: 0.3159 - accuracy: 0.8598 - precision_18: 0.8169 - recall_18: 0.9254\n",
      "Epoch 85/100\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.3178 - accuracy: 0.8566 - precision_18: 0.8178 - recall_18: 0.9155\n",
      "Epoch 86/100\n",
      "94/94 [==============================] - 1s 5ms/step - loss: 0.3167 - accuracy: 0.8583 - precision_18: 0.8143 - recall_18: 0.9263\n",
      "Epoch 87/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3122 - accuracy: 0.8590 - precision_18: 0.8178 - recall_18: 0.9215\n",
      "Epoch 88/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3121 - accuracy: 0.8628 - precision_18: 0.8228 - recall_18: 0.9228\n",
      "Epoch 89/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3094 - accuracy: 0.8633 - precision_18: 0.8254 - recall_18: 0.9194\n",
      "Epoch 90/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3117 - accuracy: 0.8626 - precision_18: 0.8205 - recall_18: 0.9263\n",
      "Epoch 91/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3094 - accuracy: 0.8613 - precision_18: 0.8233 - recall_18: 0.9181\n",
      "Epoch 92/100\n",
      "94/94 [==============================] - 1s 5ms/step - loss: 0.3116 - accuracy: 0.8616 - precision_18: 0.8219 - recall_18: 0.9211\n",
      "Epoch 93/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3130 - accuracy: 0.8624 - precision_18: 0.8197 - recall_18: 0.9271\n",
      "Epoch 94/100\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.3048 - accuracy: 0.8648 - precision_18: 0.8271 - recall_18: 0.9202\n",
      "Epoch 95/100\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 0.3055 - accuracy: 0.8616 - precision_18: 0.8192 - recall_18: 0.9258\n",
      "Epoch 96/100\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.3108 - accuracy: 0.8663 - precision_18: 0.8281 - recall_18: 0.9224\n",
      "Epoch 97/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3214 - accuracy: 0.8558 - precision_18: 0.8158 - recall_18: 0.9168\n",
      "Epoch 98/100\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.3051 - accuracy: 0.8643 - precision_18: 0.8227 - recall_18: 0.9267\n",
      "Epoch 99/100\n",
      "94/94 [==============================] - 1s 5ms/step - loss: 0.3091 - accuracy: 0.8618 - precision_18: 0.8237 - recall_18: 0.9185\n",
      "Epoch 100/100\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.3110 - accuracy: 0.8633 - precision_18: 0.8202 - recall_18: 0.9284\n",
      "47/47 [==============================] - 2s 6ms/step - loss: 0.3298 - accuracy: 0.8646 - precision_18: 0.8132 - recall_18: 0.9509\n",
      "[CV 1/3] END .........batch_size=50, epochs=100;, score=0.865 total time=  55.1s\n",
      "Epoch 1/100\n",
      "94/94 [==============================] - 7s 5ms/step - loss: 0.6985 - accuracy: 0.5544 - precision_19: 0.5901 - recall_19: 0.3876\n",
      "Epoch 2/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.6293 - accuracy: 0.6339 - precision_19: 0.7167 - recall_19: 0.4559\n",
      "Epoch 3/100\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.5841 - accuracy: 0.6957 - precision_19: 0.7489 - recall_19: 0.5984\n",
      "Epoch 4/100\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.5438 - accuracy: 0.7398 - precision_19: 0.7563 - recall_19: 0.7159\n",
      "Epoch 5/100\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.5212 - accuracy: 0.7555 - precision_19: 0.7526 - recall_19: 0.7689\n",
      "Epoch 6/100\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.5138 - accuracy: 0.7645 - precision_19: 0.7575 - recall_19: 0.7854\n",
      "Epoch 7/100\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.4925 - accuracy: 0.7722 - precision_19: 0.7610 - recall_19: 0.8007\n",
      "Epoch 8/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.4859 - accuracy: 0.7795 - precision_19: 0.7642 - recall_19: 0.8151\n",
      "Epoch 9/100\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.4707 - accuracy: 0.7878 - precision_19: 0.7633 - recall_19: 0.8410\n",
      "Epoch 10/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.4564 - accuracy: 0.7868 - precision_19: 0.7586 - recall_19: 0.8478\n",
      "Epoch 11/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.4419 - accuracy: 0.7930 - precision_19: 0.7605 - recall_19: 0.8617\n",
      "Epoch 12/100\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.4383 - accuracy: 0.7992 - precision_19: 0.7648 - recall_19: 0.8702\n",
      "Epoch 13/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.4248 - accuracy: 0.8013 - precision_19: 0.7631 - recall_19: 0.8800\n",
      "Epoch 14/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.4155 - accuracy: 0.8048 - precision_19: 0.7687 - recall_19: 0.8779\n",
      "Epoch 15/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.4116 - accuracy: 0.8063 - precision_19: 0.7741 - recall_19: 0.8707\n",
      "Epoch 16/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.4138 - accuracy: 0.8084 - precision_19: 0.7723 - recall_19: 0.8804\n",
      "Epoch 17/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3995 - accuracy: 0.8185 - precision_19: 0.7843 - recall_19: 0.8838\n",
      "Epoch 18/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.4038 - accuracy: 0.8172 - precision_19: 0.7851 - recall_19: 0.8787\n",
      "Epoch 19/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3961 - accuracy: 0.8163 - precision_19: 0.7816 - recall_19: 0.8834\n",
      "Epoch 20/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3964 - accuracy: 0.8135 - precision_19: 0.7831 - recall_19: 0.8728\n",
      "Epoch 21/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3916 - accuracy: 0.8170 - precision_19: 0.7846 - recall_19: 0.8791\n",
      "Epoch 22/100\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.3910 - accuracy: 0.8193 - precision_19: 0.7862 - recall_19: 0.8825\n",
      "Epoch 23/100\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.3851 - accuracy: 0.8191 - precision_19: 0.7854 - recall_19: 0.8834\n",
      "Epoch 24/100\n",
      "94/94 [==============================] - 1s 5ms/step - loss: 0.3876 - accuracy: 0.8253 - precision_19: 0.7880 - recall_19: 0.8953\n",
      "Epoch 25/100\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.3806 - accuracy: 0.8225 - precision_19: 0.7874 - recall_19: 0.8889\n",
      "Epoch 26/100\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.3815 - accuracy: 0.8258 - precision_19: 0.7912 - recall_19: 0.8902\n",
      "Epoch 27/100\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.3733 - accuracy: 0.8268 - precision_19: 0.7963 - recall_19: 0.8834\n",
      "Epoch 28/100\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.3788 - accuracy: 0.8213 - precision_19: 0.7880 - recall_19: 0.8842\n",
      "Epoch 29/100\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.3703 - accuracy: 0.8322 - precision_19: 0.7955 - recall_19: 0.8991\n",
      "Epoch 30/100\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.3632 - accuracy: 0.8277 - precision_19: 0.7941 - recall_19: 0.8897\n",
      "Epoch 31/100\n",
      "94/94 [==============================] - 1s 5ms/step - loss: 0.3622 - accuracy: 0.8354 - precision_19: 0.8053 - recall_19: 0.8893\n",
      "Epoch 32/100\n",
      "94/94 [==============================] - 1s 5ms/step - loss: 0.3608 - accuracy: 0.8292 - precision_19: 0.7931 - recall_19: 0.8957\n",
      "Epoch 33/100\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.3646 - accuracy: 0.8309 - precision_19: 0.7957 - recall_19: 0.8953\n",
      "Epoch 34/100\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.3628 - accuracy: 0.8277 - precision_19: 0.7919 - recall_19: 0.8940\n",
      "Epoch 35/100\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.3671 - accuracy: 0.8322 - precision_19: 0.7993 - recall_19: 0.8919\n",
      "Epoch 36/100\n",
      "94/94 [==============================] - 1s 8ms/step - loss: 0.3664 - accuracy: 0.8283 - precision_19: 0.7959 - recall_19: 0.8880\n",
      "Epoch 37/100\n",
      "94/94 [==============================] - 1s 8ms/step - loss: 0.3644 - accuracy: 0.8330 - precision_19: 0.8008 - recall_19: 0.8914\n",
      "Epoch 38/100\n",
      "94/94 [==============================] - 1s 8ms/step - loss: 0.3608 - accuracy: 0.8324 - precision_19: 0.7949 - recall_19: 0.9008\n",
      "Epoch 39/100\n",
      "94/94 [==============================] - 1s 8ms/step - loss: 0.3536 - accuracy: 0.8350 - precision_19: 0.8026 - recall_19: 0.8931\n",
      "Epoch 40/100\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.3538 - accuracy: 0.8384 - precision_19: 0.8033 - recall_19: 0.9008\n",
      "Epoch 41/100\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.3503 - accuracy: 0.8367 - precision_19: 0.8037 - recall_19: 0.8957\n",
      "Epoch 42/100\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.3602 - accuracy: 0.8337 - precision_19: 0.8026 - recall_19: 0.8897\n",
      "Epoch 43/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 0.3610 - accuracy: 0.8358 - precision_19: 0.7986 - recall_19: 0.9029\n",
      "Epoch 44/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 0.3437 - accuracy: 0.8384 - precision_19: 0.8056 - recall_19: 0.8965\n",
      "Epoch 45/100\n",
      "94/94 [==============================] - 1s 8ms/step - loss: 0.3535 - accuracy: 0.8326 - precision_19: 0.8002 - recall_19: 0.8914\n",
      "Epoch 46/100\n",
      "94/94 [==============================] - 1s 14ms/step - loss: 0.3468 - accuracy: 0.8450 - precision_19: 0.8117 - recall_19: 0.9029\n",
      "Epoch 47/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 0.3527 - accuracy: 0.8378 - precision_19: 0.8085 - recall_19: 0.8897\n",
      "Epoch 48/100\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 0.3396 - accuracy: 0.8476 - precision_19: 0.8083 - recall_19: 0.9156\n",
      "Epoch 49/100\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 0.3516 - accuracy: 0.8363 - precision_19: 0.8005 - recall_19: 0.9003\n",
      "Epoch 50/100\n",
      "94/94 [==============================] - 1s 14ms/step - loss: 0.3408 - accuracy: 0.8459 - precision_19: 0.8115 - recall_19: 0.9054\n",
      "Epoch 51/100\n",
      "94/94 [==============================] - 1s 8ms/step - loss: 0.3471 - accuracy: 0.8373 - precision_19: 0.8046 - recall_19: 0.8957\n",
      "Epoch 52/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 0.3389 - accuracy: 0.8459 - precision_19: 0.8136 - recall_19: 0.9016\n",
      "Epoch 53/100\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.3466 - accuracy: 0.8395 - precision_19: 0.8060 - recall_19: 0.8986\n",
      "Epoch 54/100\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.3384 - accuracy: 0.8459 - precision_19: 0.8110 - recall_19: 0.9063\n",
      "Epoch 55/100\n",
      "94/94 [==============================] - 1s 8ms/step - loss: 0.3399 - accuracy: 0.8489 - precision_19: 0.8149 - recall_19: 0.9071\n",
      "Epoch 56/100\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 0.3472 - accuracy: 0.8442 - precision_19: 0.8109 - recall_19: 0.9020\n",
      "Epoch 57/100\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 0.3443 - accuracy: 0.8463 - precision_19: 0.8164 - recall_19: 0.8978\n",
      "Epoch 58/100\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 0.3386 - accuracy: 0.8403 - precision_19: 0.8103 - recall_19: 0.8931\n",
      "Epoch 59/100\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.3402 - accuracy: 0.8461 - precision_19: 0.8078 - recall_19: 0.9126\n",
      "Epoch 60/100\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.3440 - accuracy: 0.8450 - precision_19: 0.8110 - recall_19: 0.9042\n",
      "Epoch 61/100\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.3332 - accuracy: 0.8478 - precision_19: 0.8164 - recall_19: 0.9016\n",
      "Epoch 62/100\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.3325 - accuracy: 0.8549 - precision_19: 0.8204 - recall_19: 0.9126\n",
      "Epoch 63/100\n",
      "94/94 [==============================] - 1s 8ms/step - loss: 0.3320 - accuracy: 0.8526 - precision_19: 0.8199 - recall_19: 0.9075\n",
      "Epoch 64/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 0.3331 - accuracy: 0.8513 - precision_19: 0.8118 - recall_19: 0.9186\n",
      "Epoch 65/100\n",
      "94/94 [==============================] - 1s 8ms/step - loss: 0.3295 - accuracy: 0.8495 - precision_19: 0.8185 - recall_19: 0.9025\n",
      "Epoch 66/100\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.3395 - accuracy: 0.8438 - precision_19: 0.8166 - recall_19: 0.8910\n",
      "Epoch 67/100\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.3263 - accuracy: 0.8547 - precision_19: 0.8189 - recall_19: 0.9148\n",
      "Epoch 68/100\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.3313 - accuracy: 0.8511 - precision_19: 0.8189 - recall_19: 0.9054\n",
      "Epoch 69/100\n",
      "94/94 [==============================] - 1s 8ms/step - loss: 0.3365 - accuracy: 0.8459 - precision_19: 0.8127 - recall_19: 0.9033\n",
      "Epoch 70/100\n",
      "94/94 [==============================] - 1s 8ms/step - loss: 0.3345 - accuracy: 0.8515 - precision_19: 0.8174 - recall_19: 0.9092\n",
      "Epoch 71/100\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.3306 - accuracy: 0.8526 - precision_19: 0.8202 - recall_19: 0.9071\n",
      "Epoch 72/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 0.3335 - accuracy: 0.8461 - precision_19: 0.8125 - recall_19: 0.9042\n",
      "Epoch 73/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 0.3330 - accuracy: 0.8519 - precision_19: 0.8192 - recall_19: 0.9071\n",
      "Epoch 74/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 0.3348 - accuracy: 0.8545 - precision_19: 0.8191 - recall_19: 0.9139\n",
      "Epoch 75/100\n",
      "94/94 [==============================] - 1s 8ms/step - loss: 0.3287 - accuracy: 0.8543 - precision_19: 0.8222 - recall_19: 0.9080\n",
      "Epoch 76/100\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.3314 - accuracy: 0.8493 - precision_19: 0.8184 - recall_19: 0.9020\n",
      "Epoch 77/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3211 - accuracy: 0.8616 - precision_19: 0.8265 - recall_19: 0.9190\n",
      "Epoch 78/100\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.3321 - accuracy: 0.8498 - precision_19: 0.8215 - recall_19: 0.8978\n",
      "Epoch 79/100\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.3187 - accuracy: 0.8605 - precision_19: 0.8264 - recall_19: 0.9165\n",
      "Epoch 80/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 0.3196 - accuracy: 0.8575 - precision_19: 0.8237 - recall_19: 0.9135\n",
      "Epoch 81/100\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.3197 - accuracy: 0.8549 - precision_19: 0.8185 - recall_19: 0.9160\n",
      "Epoch 82/100\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.3262 - accuracy: 0.8541 - precision_19: 0.8202 - recall_19: 0.9109\n",
      "Epoch 83/100\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.3161 - accuracy: 0.8571 - precision_19: 0.8248 - recall_19: 0.9105\n",
      "Epoch 84/100\n",
      "94/94 [==============================] - 1s 8ms/step - loss: 0.3273 - accuracy: 0.8526 - precision_19: 0.8247 - recall_19: 0.8995\n",
      "Epoch 85/100\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.3158 - accuracy: 0.8609 - precision_19: 0.8273 - recall_19: 0.9160\n",
      "Epoch 86/100\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.3235 - accuracy: 0.8528 - precision_19: 0.8245 - recall_19: 0.9003\n",
      "Epoch 87/100\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.3232 - accuracy: 0.8541 - precision_19: 0.8224 - recall_19: 0.9071\n",
      "Epoch 88/100\n",
      "94/94 [==============================] - 1s 8ms/step - loss: 0.3184 - accuracy: 0.8530 - precision_19: 0.8233 - recall_19: 0.9029\n",
      "Epoch 89/100\n",
      "94/94 [==============================] - 1s 8ms/step - loss: 0.3117 - accuracy: 0.8654 - precision_19: 0.8296 - recall_19: 0.9232\n",
      "Epoch 90/100\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.3201 - accuracy: 0.8575 - precision_19: 0.8262 - recall_19: 0.9092\n",
      "Epoch 91/100\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.3251 - accuracy: 0.8528 - precision_19: 0.8212 - recall_19: 0.9059\n",
      "Epoch 92/100\n",
      "94/94 [==============================] - 2s 16ms/step - loss: 0.3152 - accuracy: 0.8611 - precision_19: 0.8291 - recall_19: 0.9135\n",
      "Epoch 93/100\n",
      "94/94 [==============================] - 1s 15ms/step - loss: 0.3142 - accuracy: 0.8571 - precision_19: 0.8286 - recall_19: 0.9042\n",
      "Epoch 94/100\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 0.3137 - accuracy: 0.8586 - precision_19: 0.8228 - recall_19: 0.9177\n",
      "Epoch 95/100\n",
      "94/94 [==============================] - 1s 8ms/step - loss: 0.3158 - accuracy: 0.8637 - precision_19: 0.8309 - recall_19: 0.9169\n",
      "Epoch 96/100\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.3103 - accuracy: 0.8658 - precision_19: 0.8298 - recall_19: 0.9241\n",
      "Epoch 97/100\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.3138 - accuracy: 0.8601 - precision_19: 0.8268 - recall_19: 0.9148\n",
      "Epoch 98/100\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.3160 - accuracy: 0.8588 - precision_19: 0.8286 - recall_19: 0.9084\n",
      "Epoch 99/100\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.3090 - accuracy: 0.8588 - precision_19: 0.8296 - recall_19: 0.9067\n",
      "Epoch 100/100\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.3130 - accuracy: 0.8628 - precision_19: 0.8342 - recall_19: 0.9092\n",
      "47/47 [==============================] - 2s 9ms/step - loss: 0.3379 - accuracy: 0.8637 - precision_19: 0.8070 - recall_19: 0.9483\n",
      "[CV 2/3] END .........batch_size=50, epochs=100;, score=0.864 total time= 1.3min\n",
      "Epoch 1/100\n",
      "94/94 [==============================] - 13s 8ms/step - loss: 0.7287 - accuracy: 0.5497 - precision_20: 0.5703 - recall_20: 0.3879\n",
      "Epoch 2/100\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.6343 - accuracy: 0.6481 - precision_20: 0.7290 - recall_20: 0.4666\n",
      "Epoch 3/100\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.6043 - accuracy: 0.6871 - precision_20: 0.7579 - recall_20: 0.5458\n",
      "Epoch 4/100\n",
      "94/94 [==============================] - 2s 21ms/step - loss: 0.5765 - accuracy: 0.7203 - precision_20: 0.7885 - recall_20: 0.5988\n",
      "Epoch 5/100\n",
      "94/94 [==============================] - 1s 8ms/step - loss: 0.5471 - accuracy: 0.7490 - precision_20: 0.7807 - recall_20: 0.6896\n",
      "Epoch 6/100\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.5069 - accuracy: 0.7786 - precision_20: 0.7795 - recall_20: 0.7744\n",
      "Epoch 7/100\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.4842 - accuracy: 0.7848 - precision_20: 0.7678 - recall_20: 0.8140\n",
      "Epoch 8/100\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.4591 - accuracy: 0.7975 - precision_20: 0.7736 - recall_20: 0.8386\n",
      "Epoch 9/100\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.4477 - accuracy: 0.7979 - precision_20: 0.7642 - recall_20: 0.8592\n",
      "Epoch 10/100\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.4395 - accuracy: 0.7951 - precision_20: 0.7590 - recall_20: 0.8622\n",
      "Epoch 11/100\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.4285 - accuracy: 0.8018 - precision_20: 0.7688 - recall_20: 0.8605\n",
      "Epoch 12/100\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.4199 - accuracy: 0.8065 - precision_20: 0.7735 - recall_20: 0.8644\n",
      "Epoch 13/100\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.4161 - accuracy: 0.8082 - precision_20: 0.7731 - recall_20: 0.8700\n",
      "Epoch 14/100\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.4118 - accuracy: 0.8116 - precision_20: 0.7743 - recall_20: 0.8773\n",
      "Epoch 15/100\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.4110 - accuracy: 0.8075 - precision_20: 0.7698 - recall_20: 0.8752\n",
      "Epoch 16/100\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.3928 - accuracy: 0.8202 - precision_20: 0.7826 - recall_20: 0.8846\n",
      "Epoch 17/100\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.3989 - accuracy: 0.8153 - precision_20: 0.7813 - recall_20: 0.8734\n",
      "Epoch 18/100\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.4047 - accuracy: 0.8146 - precision_20: 0.7802 - recall_20: 0.8739\n",
      "Epoch 19/100\n",
      "94/94 [==============================] - 1s 8ms/step - loss: 0.3951 - accuracy: 0.8140 - precision_20: 0.7784 - recall_20: 0.8756\n",
      "Epoch 20/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.4020 - accuracy: 0.8191 - precision_20: 0.7841 - recall_20: 0.8786\n",
      "Epoch 21/100\n",
      "94/94 [==============================] - 1s 5ms/step - loss: 0.3852 - accuracy: 0.8215 - precision_20: 0.7906 - recall_20: 0.8726\n",
      "Epoch 22/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.4035 - accuracy: 0.8157 - precision_20: 0.7828 - recall_20: 0.8717\n",
      "Epoch 23/100\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.3963 - accuracy: 0.8208 - precision_20: 0.7841 - recall_20: 0.8833\n",
      "Epoch 24/100\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.3939 - accuracy: 0.8155 - precision_20: 0.7842 - recall_20: 0.8683\n",
      "Epoch 25/100\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.3872 - accuracy: 0.8228 - precision_20: 0.7913 - recall_20: 0.8747\n",
      "Epoch 26/100\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.3766 - accuracy: 0.8288 - precision_20: 0.7902 - recall_20: 0.8932\n",
      "Epoch 27/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3777 - accuracy: 0.8300 - precision_20: 0.7963 - recall_20: 0.8851\n",
      "Epoch 28/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3802 - accuracy: 0.8219 - precision_20: 0.7942 - recall_20: 0.8670\n",
      "Epoch 29/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3770 - accuracy: 0.8236 - precision_20: 0.7894 - recall_20: 0.8808\n",
      "Epoch 30/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3807 - accuracy: 0.8238 - precision_20: 0.7921 - recall_20: 0.8760\n",
      "Epoch 31/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3653 - accuracy: 0.8324 - precision_20: 0.8030 - recall_20: 0.8790\n",
      "Epoch 32/100\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.3648 - accuracy: 0.8403 - precision_20: 0.8044 - recall_20: 0.8975\n",
      "Epoch 33/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3756 - accuracy: 0.8290 - precision_20: 0.7984 - recall_20: 0.8782\n",
      "Epoch 34/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3727 - accuracy: 0.8292 - precision_20: 0.7976 - recall_20: 0.8803\n",
      "Epoch 35/100\n",
      "94/94 [==============================] - 1s 5ms/step - loss: 0.3718 - accuracy: 0.8264 - precision_20: 0.7954 - recall_20: 0.8769\n",
      "Epoch 36/100\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.3676 - accuracy: 0.8356 - precision_20: 0.8092 - recall_20: 0.8765\n",
      "Epoch 37/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3735 - accuracy: 0.8309 - precision_20: 0.8034 - recall_20: 0.8743\n",
      "Epoch 38/100\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.3614 - accuracy: 0.8309 - precision_20: 0.8001 - recall_20: 0.8803\n",
      "Epoch 39/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3679 - accuracy: 0.8358 - precision_20: 0.8052 - recall_20: 0.8842\n",
      "Epoch 40/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3671 - accuracy: 0.8300 - precision_20: 0.7998 - recall_20: 0.8786\n",
      "Epoch 41/100\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.3624 - accuracy: 0.8348 - precision_20: 0.8046 - recall_20: 0.8825\n",
      "Epoch 42/100\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.3467 - accuracy: 0.8444 - precision_20: 0.8142 - recall_20: 0.8907\n",
      "Epoch 43/100\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.3671 - accuracy: 0.8320 - precision_20: 0.8043 - recall_20: 0.8756\n",
      "Epoch 44/100\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 0.3588 - accuracy: 0.8405 - precision_20: 0.8114 - recall_20: 0.8855\n",
      "Epoch 45/100\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 0.3633 - accuracy: 0.8275 - precision_20: 0.7965 - recall_20: 0.8777\n",
      "Epoch 46/100\n",
      "94/94 [==============================] - 1s 5ms/step - loss: 0.3529 - accuracy: 0.8410 - precision_20: 0.8084 - recall_20: 0.8920\n",
      "Epoch 47/100\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.3570 - accuracy: 0.8365 - precision_20: 0.8071 - recall_20: 0.8825\n",
      "Epoch 48/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3532 - accuracy: 0.8356 - precision_20: 0.8075 - recall_20: 0.8795\n",
      "Epoch 49/100\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.3556 - accuracy: 0.8350 - precision_20: 0.7979 - recall_20: 0.8954\n",
      "Epoch 50/100\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.3457 - accuracy: 0.8418 - precision_20: 0.8144 - recall_20: 0.8838\n",
      "Epoch 51/100\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.3417 - accuracy: 0.8457 - precision_20: 0.8159 - recall_20: 0.8911\n",
      "Epoch 52/100\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.3573 - accuracy: 0.8328 - precision_20: 0.8055 - recall_20: 0.8756\n",
      "Epoch 53/100\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.3529 - accuracy: 0.8410 - precision_20: 0.8118 - recall_20: 0.8859\n",
      "Epoch 54/100\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.3467 - accuracy: 0.8450 - precision_20: 0.8145 - recall_20: 0.8920\n",
      "Epoch 55/100\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.3491 - accuracy: 0.8405 - precision_20: 0.8095 - recall_20: 0.8889\n",
      "Epoch 56/100\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.3462 - accuracy: 0.8459 - precision_20: 0.8157 - recall_20: 0.8920\n",
      "Epoch 57/100\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.3523 - accuracy: 0.8345 - precision_20: 0.8052 - recall_20: 0.8808\n",
      "Epoch 58/100\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.3438 - accuracy: 0.8435 - precision_20: 0.8088 - recall_20: 0.8980\n",
      "Epoch 59/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3461 - accuracy: 0.8444 - precision_20: 0.8160 - recall_20: 0.8876\n",
      "Epoch 60/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3414 - accuracy: 0.8429 - precision_20: 0.8091 - recall_20: 0.8958\n",
      "Epoch 61/100\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.3424 - accuracy: 0.8480 - precision_20: 0.8135 - recall_20: 0.9014\n",
      "Epoch 62/100\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.3358 - accuracy: 0.8495 - precision_20: 0.8187 - recall_20: 0.8963\n",
      "Epoch 63/100\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.3403 - accuracy: 0.8457 - precision_20: 0.8197 - recall_20: 0.8846\n",
      "Epoch 64/100\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.3496 - accuracy: 0.8453 - precision_20: 0.8133 - recall_20: 0.8945\n",
      "Epoch 65/100\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.3445 - accuracy: 0.8420 - precision_20: 0.8083 - recall_20: 0.8950\n",
      "Epoch 66/100\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.3354 - accuracy: 0.8472 - precision_20: 0.8184 - recall_20: 0.8907\n",
      "Epoch 67/100\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.3370 - accuracy: 0.8463 - precision_20: 0.8161 - recall_20: 0.8924\n",
      "Epoch 68/100\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.3508 - accuracy: 0.8457 - precision_20: 0.8167 - recall_20: 0.8898\n",
      "Epoch 69/100\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.3381 - accuracy: 0.8431 - precision_20: 0.8118 - recall_20: 0.8915\n",
      "Epoch 70/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 0.3349 - accuracy: 0.8446 - precision_20: 0.8176 - recall_20: 0.8855\n",
      "Epoch 71/100\n",
      "94/94 [==============================] - 1s 8ms/step - loss: 0.3363 - accuracy: 0.8485 - precision_20: 0.8196 - recall_20: 0.8920\n",
      "Epoch 72/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 0.3323 - accuracy: 0.8498 - precision_20: 0.8168 - recall_20: 0.9001\n",
      "Epoch 73/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 0.3382 - accuracy: 0.8478 - precision_20: 0.8159 - recall_20: 0.8967\n",
      "Epoch 74/100\n",
      "94/94 [==============================] - 1s 8ms/step - loss: 0.3320 - accuracy: 0.8495 - precision_20: 0.8155 - recall_20: 0.9019\n",
      "Epoch 75/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 0.3265 - accuracy: 0.8549 - precision_20: 0.8281 - recall_20: 0.8941\n",
      "Epoch 76/100\n",
      "94/94 [==============================] - 1s 8ms/step - loss: 0.3355 - accuracy: 0.8528 - precision_20: 0.8226 - recall_20: 0.8980\n",
      "Epoch 77/100\n",
      "94/94 [==============================] - 1s 8ms/step - loss: 0.3311 - accuracy: 0.8498 - precision_20: 0.8190 - recall_20: 0.8963\n",
      "Epoch 78/100\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.3223 - accuracy: 0.8575 - precision_20: 0.8290 - recall_20: 0.8993\n",
      "Epoch 79/100\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.3286 - accuracy: 0.8493 - precision_20: 0.8157 - recall_20: 0.9010\n",
      "Epoch 80/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 0.3251 - accuracy: 0.8551 - precision_20: 0.8282 - recall_20: 0.8945\n",
      "Epoch 81/100\n",
      "94/94 [==============================] - 1s 8ms/step - loss: 0.3200 - accuracy: 0.8594 - precision_20: 0.8285 - recall_20: 0.9049\n",
      "Epoch 82/100\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.3239 - accuracy: 0.8523 - precision_20: 0.8234 - recall_20: 0.8954\n",
      "Epoch 83/100\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 0.3254 - accuracy: 0.8536 - precision_20: 0.8246 - recall_20: 0.8967\n",
      "Epoch 84/100\n",
      "94/94 [==============================] - 1s 8ms/step - loss: 0.3296 - accuracy: 0.8530 - precision_20: 0.8209 - recall_20: 0.9014\n",
      "Epoch 85/100\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.3175 - accuracy: 0.8609 - precision_20: 0.8272 - recall_20: 0.9109\n",
      "Epoch 86/100\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.3279 - accuracy: 0.8549 - precision_20: 0.8235 - recall_20: 0.9019\n",
      "Epoch 87/100\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.3304 - accuracy: 0.8491 - precision_20: 0.8196 - recall_20: 0.8937\n",
      "Epoch 88/100\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.3280 - accuracy: 0.8568 - precision_20: 0.8244 - recall_20: 0.9053\n",
      "Epoch 89/100\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.3176 - accuracy: 0.8588 - precision_20: 0.8320 - recall_20: 0.8975\n",
      "Epoch 90/100\n",
      "94/94 [==============================] - 1s 8ms/step - loss: 0.3167 - accuracy: 0.8605 - precision_20: 0.8297 - recall_20: 0.9057\n",
      "Epoch 91/100\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.3217 - accuracy: 0.8575 - precision_20: 0.8256 - recall_20: 0.9049\n",
      "Epoch 92/100\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.3169 - accuracy: 0.8643 - precision_20: 0.8359 - recall_20: 0.9053\n",
      "Epoch 93/100\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.3162 - accuracy: 0.8594 - precision_20: 0.8257 - recall_20: 0.9096\n",
      "Epoch 94/100\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.3221 - accuracy: 0.8596 - precision_20: 0.8278 - recall_20: 0.9066\n",
      "Epoch 95/100\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.3105 - accuracy: 0.8661 - precision_20: 0.8311 - recall_20: 0.9173\n",
      "Epoch 96/100\n",
      "94/94 [==============================] - 1s 5ms/step - loss: 0.3132 - accuracy: 0.8641 - precision_20: 0.8374 - recall_20: 0.9023\n",
      "Epoch 97/100\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.3111 - accuracy: 0.8643 - precision_20: 0.8319 - recall_20: 0.9118\n",
      "Epoch 98/100\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.3131 - accuracy: 0.8622 - precision_20: 0.8363 - recall_20: 0.8993\n",
      "Epoch 99/100\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.3195 - accuracy: 0.8547 - precision_20: 0.8265 - recall_20: 0.8963\n",
      "Epoch 100/100\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.3095 - accuracy: 0.8635 - precision_20: 0.8290 - recall_20: 0.9143\n",
      "47/47 [==============================] - 3s 7ms/step - loss: 0.3115 - accuracy: 0.8693 - precision_20: 0.8349 - recall_20: 0.9235\n",
      "[CV 3/3] END .........batch_size=50, epochs=100;, score=0.869 total time= 1.3min\n",
      "Epoch 1/50\n",
      "47/47 [==============================] - 9s 6ms/step - loss: 0.6468 - accuracy: 0.6316 - precision_21: 0.6537 - recall_21: 0.5502\n",
      "Epoch 2/50\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.5688 - accuracy: 0.7332 - precision_21: 0.7562 - recall_21: 0.6835\n",
      "Epoch 3/50\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.5344 - accuracy: 0.7670 - precision_21: 0.7678 - recall_21: 0.7615\n",
      "Epoch 4/50\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5110 - accuracy: 0.7797 - precision_21: 0.7631 - recall_21: 0.8072\n",
      "Epoch 5/50\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.4719 - accuracy: 0.8015 - precision_21: 0.7726 - recall_21: 0.8512\n",
      "Epoch 6/50\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.4586 - accuracy: 0.8020 - precision_21: 0.7688 - recall_21: 0.8603\n",
      "Epoch 7/50\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.4486 - accuracy: 0.8028 - precision_21: 0.7696 - recall_21: 0.8611\n",
      "Epoch 8/50\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.4394 - accuracy: 0.8067 - precision_21: 0.7722 - recall_21: 0.8668\n",
      "Epoch 9/50\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.4341 - accuracy: 0.8088 - precision_21: 0.7745 - recall_21: 0.8680\n",
      "Epoch 10/50\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.4254 - accuracy: 0.8112 - precision_21: 0.7713 - recall_21: 0.8814\n",
      "Epoch 11/50\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.4230 - accuracy: 0.8069 - precision_21: 0.7750 - recall_21: 0.8616\n",
      "Epoch 12/50\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.4023 - accuracy: 0.8180 - precision_21: 0.7782 - recall_21: 0.8866\n",
      "Epoch 13/50\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.4008 - accuracy: 0.8208 - precision_21: 0.7866 - recall_21: 0.8775\n",
      "Epoch 14/50\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.3901 - accuracy: 0.8217 - precision_21: 0.7894 - recall_21: 0.8745\n",
      "Epoch 15/50\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.3975 - accuracy: 0.8191 - precision_21: 0.7880 - recall_21: 0.8702\n",
      "Epoch 16/50\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.3842 - accuracy: 0.8279 - precision_21: 0.7947 - recall_21: 0.8814\n",
      "Epoch 17/50\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.3799 - accuracy: 0.8277 - precision_21: 0.7972 - recall_21: 0.8762\n",
      "Epoch 18/50\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.3788 - accuracy: 0.8279 - precision_21: 0.7991 - recall_21: 0.8732\n",
      "Epoch 19/50\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.3707 - accuracy: 0.8318 - precision_21: 0.7955 - recall_21: 0.8905\n",
      "Epoch 20/50\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.3676 - accuracy: 0.8354 - precision_21: 0.8045 - recall_21: 0.8836\n",
      "Epoch 21/50\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.3681 - accuracy: 0.8330 - precision_21: 0.8029 - recall_21: 0.8801\n",
      "Epoch 22/50\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.3779 - accuracy: 0.8270 - precision_21: 0.7960 - recall_21: 0.8767\n",
      "Epoch 23/50\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.3693 - accuracy: 0.8315 - precision_21: 0.8014 - recall_21: 0.8788\n",
      "Epoch 24/50\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.3564 - accuracy: 0.8399 - precision_21: 0.8061 - recall_21: 0.8926\n",
      "Epoch 25/50\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.3651 - accuracy: 0.8367 - precision_21: 0.8088 - recall_21: 0.8793\n",
      "Epoch 26/50\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.3657 - accuracy: 0.8356 - precision_21: 0.8046 - recall_21: 0.8840\n",
      "Epoch 27/50\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.3571 - accuracy: 0.8393 - precision_21: 0.8102 - recall_21: 0.8836\n",
      "Epoch 28/50\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.3497 - accuracy: 0.8435 - precision_21: 0.8132 - recall_21: 0.8896\n",
      "Epoch 29/50\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.3507 - accuracy: 0.8405 - precision_21: 0.8146 - recall_21: 0.8793\n",
      "Epoch 30/50\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.3555 - accuracy: 0.8393 - precision_21: 0.8085 - recall_21: 0.8866\n",
      "Epoch 31/50\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.3559 - accuracy: 0.8345 - precision_21: 0.8044 - recall_21: 0.8814\n",
      "Epoch 32/50\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.3518 - accuracy: 0.8399 - precision_21: 0.8056 - recall_21: 0.8935\n",
      "Epoch 33/50\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.3403 - accuracy: 0.8435 - precision_21: 0.8137 - recall_21: 0.8887\n",
      "Epoch 34/50\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.3360 - accuracy: 0.8476 - precision_21: 0.8173 - recall_21: 0.8931\n",
      "Epoch 35/50\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.3437 - accuracy: 0.8455 - precision_21: 0.8171 - recall_21: 0.8879\n",
      "Epoch 36/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3490 - accuracy: 0.8405 - precision_21: 0.8080 - recall_21: 0.8909\n",
      "Epoch 37/50\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.3410 - accuracy: 0.8480 - precision_21: 0.8162 - recall_21: 0.8961\n",
      "Epoch 38/50\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.3368 - accuracy: 0.8491 - precision_21: 0.8185 - recall_21: 0.8948\n",
      "Epoch 39/50\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.3394 - accuracy: 0.8483 - precision_21: 0.8236 - recall_21: 0.8840\n",
      "Epoch 40/50\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.3335 - accuracy: 0.8465 - precision_21: 0.8187 - recall_21: 0.8879\n",
      "Epoch 41/50\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.3291 - accuracy: 0.8551 - precision_21: 0.8251 - recall_21: 0.8991\n",
      "Epoch 42/50\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.3372 - accuracy: 0.8485 - precision_21: 0.8211 - recall_21: 0.8887\n",
      "Epoch 43/50\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.3383 - accuracy: 0.8465 - precision_21: 0.8172 - recall_21: 0.8905\n",
      "Epoch 44/50\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.3313 - accuracy: 0.8495 - precision_21: 0.8192 - recall_21: 0.8948\n",
      "Epoch 45/50\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.3378 - accuracy: 0.8468 - precision_21: 0.8128 - recall_21: 0.8987\n",
      "Epoch 46/50\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.3294 - accuracy: 0.8530 - precision_21: 0.8241 - recall_21: 0.8952\n",
      "Epoch 47/50\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.3223 - accuracy: 0.8562 - precision_21: 0.8259 - recall_21: 0.9004\n",
      "Epoch 48/50\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.3327 - accuracy: 0.8480 - precision_21: 0.8157 - recall_21: 0.8969\n",
      "Epoch 49/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3223 - accuracy: 0.8553 - precision_21: 0.8257 - recall_21: 0.8987\n",
      "Epoch 50/50\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.3202 - accuracy: 0.8577 - precision_21: 0.8254 - recall_21: 0.9051\n",
      "24/24 [==============================] - 1s 5ms/step - loss: 0.3750 - accuracy: 0.8388 - precision_21: 0.8103 - recall_21: 0.8899\n",
      "[CV 1/3] END .........batch_size=100, epochs=50;, score=0.839 total time=  27.0s\n",
      "Epoch 1/50\n",
      "47/47 [==============================] - 10s 6ms/step - loss: 0.6912 - accuracy: 0.6044 - precision_22: 0.6411 - recall_22: 0.4932\n",
      "Epoch 2/50\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.5692 - accuracy: 0.7276 - precision_22: 0.7404 - recall_22: 0.7099\n",
      "Epoch 3/50\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.5376 - accuracy: 0.7518 - precision_22: 0.7597 - recall_22: 0.7443\n",
      "Epoch 4/50\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.5278 - accuracy: 0.7555 - precision_22: 0.7586 - recall_22: 0.7570\n",
      "Epoch 5/50\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.5149 - accuracy: 0.7613 - precision_22: 0.7640 - recall_22: 0.7634\n",
      "Epoch 6/50\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.4984 - accuracy: 0.7750 - precision_22: 0.7707 - recall_22: 0.7897\n",
      "Epoch 7/50\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.4785 - accuracy: 0.7814 - precision_22: 0.7731 - recall_22: 0.8032\n",
      "Epoch 8/50\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.4596 - accuracy: 0.7928 - precision_22: 0.7835 - recall_22: 0.8151\n",
      "Epoch 9/50\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.4548 - accuracy: 0.7923 - precision_22: 0.7855 - recall_22: 0.8104\n",
      "Epoch 10/50\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.4398 - accuracy: 0.8033 - precision_22: 0.7948 - recall_22: 0.8232\n",
      "Epoch 11/50\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.4349 - accuracy: 0.8052 - precision_22: 0.7927 - recall_22: 0.8321\n",
      "Epoch 12/50\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.4338 - accuracy: 0.8026 - precision_22: 0.7887 - recall_22: 0.8325\n",
      "Epoch 13/50\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.4178 - accuracy: 0.8118 - precision_22: 0.7925 - recall_22: 0.8503\n",
      "Epoch 14/50\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.4186 - accuracy: 0.8135 - precision_22: 0.7913 - recall_22: 0.8571\n",
      "Epoch 15/50\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.4078 - accuracy: 0.8178 - precision_22: 0.7950 - recall_22: 0.8617\n",
      "Epoch 16/50\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.4021 - accuracy: 0.8228 - precision_22: 0.8053 - recall_22: 0.8562\n",
      "Epoch 17/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3959 - accuracy: 0.8251 - precision_22: 0.8012 - recall_22: 0.8698\n",
      "Epoch 18/50\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.3964 - accuracy: 0.8253 - precision_22: 0.8043 - recall_22: 0.8647\n",
      "Epoch 19/50\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.3948 - accuracy: 0.8253 - precision_22: 0.8029 - recall_22: 0.8673\n",
      "Epoch 20/50\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.3855 - accuracy: 0.8303 - precision_22: 0.8073 - recall_22: 0.8723\n",
      "Epoch 21/50\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.3879 - accuracy: 0.8294 - precision_22: 0.8041 - recall_22: 0.8757\n",
      "Epoch 22/50\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.3912 - accuracy: 0.8245 - precision_22: 0.8026 - recall_22: 0.8656\n",
      "Epoch 23/50\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.3779 - accuracy: 0.8337 - precision_22: 0.8112 - recall_22: 0.8745\n",
      "Epoch 24/50\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.3760 - accuracy: 0.8335 - precision_22: 0.8116 - recall_22: 0.8732\n",
      "Epoch 25/50\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.3773 - accuracy: 0.8352 - precision_22: 0.8088 - recall_22: 0.8825\n",
      "Epoch 26/50\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.3619 - accuracy: 0.8459 - precision_22: 0.8180 - recall_22: 0.8940\n",
      "Epoch 27/50\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.3687 - accuracy: 0.8367 - precision_22: 0.8103 - recall_22: 0.8838\n",
      "Epoch 28/50\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.3660 - accuracy: 0.8423 - precision_22: 0.8183 - recall_22: 0.8842\n",
      "Epoch 29/50\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.3664 - accuracy: 0.8395 - precision_22: 0.8107 - recall_22: 0.8902\n",
      "Epoch 30/50\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.3538 - accuracy: 0.8506 - precision_22: 0.8230 - recall_22: 0.8974\n",
      "Epoch 31/50\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.3532 - accuracy: 0.8442 - precision_22: 0.8194 - recall_22: 0.8872\n",
      "Epoch 32/50\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.3562 - accuracy: 0.8457 - precision_22: 0.8204 - recall_22: 0.8893\n",
      "Epoch 33/50\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.3554 - accuracy: 0.8446 - precision_22: 0.8201 - recall_22: 0.8872\n",
      "Epoch 34/50\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.3534 - accuracy: 0.8448 - precision_22: 0.8172 - recall_22: 0.8927\n",
      "Epoch 35/50\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.3434 - accuracy: 0.8538 - precision_22: 0.8268 - recall_22: 0.8991\n",
      "Epoch 36/50\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.3419 - accuracy: 0.8547 - precision_22: 0.8286 - recall_22: 0.8982\n",
      "Epoch 37/50\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.3454 - accuracy: 0.8489 - precision_22: 0.8255 - recall_22: 0.8889\n",
      "Epoch 38/50\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.3428 - accuracy: 0.8560 - precision_22: 0.8288 - recall_22: 0.9012\n",
      "Epoch 39/50\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.3390 - accuracy: 0.8543 - precision_22: 0.8288 - recall_22: 0.8969\n",
      "Epoch 40/50\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.3456 - accuracy: 0.8489 - precision_22: 0.8245 - recall_22: 0.8906\n",
      "Epoch 41/50\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.3430 - accuracy: 0.8528 - precision_22: 0.8280 - recall_22: 0.8944\n",
      "Epoch 42/50\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.3353 - accuracy: 0.8571 - precision_22: 0.8359 - recall_22: 0.8923\n",
      "Epoch 43/50\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.3322 - accuracy: 0.8553 - precision_22: 0.8276 - recall_22: 0.9016\n",
      "Epoch 44/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3292 - accuracy: 0.8590 - precision_22: 0.8339 - recall_22: 0.9003\n",
      "Epoch 45/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3320 - accuracy: 0.8588 - precision_22: 0.8341 - recall_22: 0.8995\n",
      "Epoch 46/50\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.3398 - accuracy: 0.8508 - precision_22: 0.8272 - recall_22: 0.8910\n",
      "Epoch 47/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3319 - accuracy: 0.8616 - precision_22: 0.8333 - recall_22: 0.9075\n",
      "Epoch 48/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3298 - accuracy: 0.8526 - precision_22: 0.8267 - recall_22: 0.8961\n",
      "Epoch 49/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3301 - accuracy: 0.8553 - precision_22: 0.8288 - recall_22: 0.8995\n",
      "Epoch 50/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3239 - accuracy: 0.8592 - precision_22: 0.8318 - recall_22: 0.9042\n",
      "24/24 [==============================] - 1s 2ms/step - loss: 0.3714 - accuracy: 0.8363 - precision_22: 0.7973 - recall_22: 0.8923\n",
      "[CV 2/3] END .........batch_size=100, epochs=50;, score=0.836 total time=  25.6s\n",
      "Epoch 1/50\n",
      "47/47 [==============================] - 5s 4ms/step - loss: 0.6772 - accuracy: 0.5949 - precision_23: 0.6279 - recall_23: 0.4576\n",
      "Epoch 2/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.6359 - accuracy: 0.7085 - precision_23: 0.7436 - recall_23: 0.6328\n",
      "Epoch 3/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.5907 - accuracy: 0.7578 - precision_23: 0.7703 - recall_23: 0.7318\n",
      "Epoch 4/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.5495 - accuracy: 0.7793 - precision_23: 0.7790 - recall_23: 0.7770\n",
      "Epoch 5/50\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.5193 - accuracy: 0.7831 - precision_23: 0.7786 - recall_23: 0.7886\n",
      "Epoch 6/50\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.4937 - accuracy: 0.7872 - precision_23: 0.7712 - recall_23: 0.8140\n",
      "Epoch 7/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4676 - accuracy: 0.7958 - precision_23: 0.7718 - recall_23: 0.8373\n",
      "Epoch 8/50\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.4524 - accuracy: 0.8011 - precision_23: 0.7690 - recall_23: 0.8584\n",
      "Epoch 9/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4397 - accuracy: 0.8005 - precision_23: 0.7771 - recall_23: 0.8403\n",
      "Epoch 10/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4269 - accuracy: 0.8045 - precision_23: 0.7814 - recall_23: 0.8433\n",
      "Epoch 11/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4204 - accuracy: 0.8080 - precision_23: 0.7773 - recall_23: 0.8610\n",
      "Epoch 12/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4084 - accuracy: 0.8131 - precision_23: 0.7842 - recall_23: 0.8618\n",
      "Epoch 13/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4035 - accuracy: 0.8159 - precision_23: 0.7850 - recall_23: 0.8678\n",
      "Epoch 14/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4051 - accuracy: 0.8153 - precision_23: 0.7811 - recall_23: 0.8739\n",
      "Epoch 15/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3955 - accuracy: 0.8275 - precision_23: 0.7897 - recall_23: 0.8907\n",
      "Epoch 16/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3888 - accuracy: 0.8230 - precision_23: 0.7873 - recall_23: 0.8829\n",
      "Epoch 17/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3773 - accuracy: 0.8275 - precision_23: 0.7919 - recall_23: 0.8864\n",
      "Epoch 18/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3812 - accuracy: 0.8273 - precision_23: 0.7941 - recall_23: 0.8816\n",
      "Epoch 19/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3778 - accuracy: 0.8294 - precision_23: 0.7938 - recall_23: 0.8881\n",
      "Epoch 20/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.3841 - accuracy: 0.8225 - precision_23: 0.7912 - recall_23: 0.8743\n",
      "Epoch 21/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3709 - accuracy: 0.8337 - precision_23: 0.7965 - recall_23: 0.8945\n",
      "Epoch 22/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.3707 - accuracy: 0.8367 - precision_23: 0.7985 - recall_23: 0.8988\n",
      "Epoch 23/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3682 - accuracy: 0.8369 - precision_23: 0.7974 - recall_23: 0.9014\n",
      "Epoch 24/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3655 - accuracy: 0.8343 - precision_23: 0.8039 - recall_23: 0.8825\n",
      "Epoch 25/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.3604 - accuracy: 0.8408 - precision_23: 0.8041 - recall_23: 0.8993\n",
      "Epoch 26/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3637 - accuracy: 0.8395 - precision_23: 0.8011 - recall_23: 0.9014\n",
      "Epoch 27/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3635 - accuracy: 0.8438 - precision_23: 0.8075 - recall_23: 0.9010\n",
      "Epoch 28/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3475 - accuracy: 0.8459 - precision_23: 0.8085 - recall_23: 0.9049\n",
      "Epoch 29/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3532 - accuracy: 0.8423 - precision_23: 0.8108 - recall_23: 0.8911\n",
      "Epoch 30/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3454 - accuracy: 0.8498 - precision_23: 0.8158 - recall_23: 0.9019\n",
      "Epoch 31/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3488 - accuracy: 0.8450 - precision_23: 0.8072 - recall_23: 0.9049\n",
      "Epoch 32/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3425 - accuracy: 0.8519 - precision_23: 0.8188 - recall_23: 0.9023\n",
      "Epoch 33/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3459 - accuracy: 0.8474 - precision_23: 0.8138 - recall_23: 0.8993\n",
      "Epoch 34/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3382 - accuracy: 0.8519 - precision_23: 0.8158 - recall_23: 0.9074\n",
      "Epoch 35/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3380 - accuracy: 0.8519 - precision_23: 0.8170 - recall_23: 0.9053\n",
      "Epoch 36/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3465 - accuracy: 0.8553 - precision_23: 0.8219 - recall_23: 0.9057\n",
      "Epoch 37/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3414 - accuracy: 0.8528 - precision_23: 0.8210 - recall_23: 0.9006\n",
      "Epoch 38/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3367 - accuracy: 0.8526 - precision_23: 0.8197 - recall_23: 0.9023\n",
      "Epoch 39/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3363 - accuracy: 0.8541 - precision_23: 0.8235 - recall_23: 0.8997\n",
      "Epoch 40/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3424 - accuracy: 0.8485 - precision_23: 0.8132 - recall_23: 0.9031\n",
      "Epoch 41/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3290 - accuracy: 0.8577 - precision_23: 0.8221 - recall_23: 0.9113\n",
      "Epoch 42/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3359 - accuracy: 0.8571 - precision_23: 0.8245 - recall_23: 0.9057\n",
      "Epoch 43/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3357 - accuracy: 0.8549 - precision_23: 0.8185 - recall_23: 0.9105\n",
      "Epoch 44/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3299 - accuracy: 0.8577 - precision_23: 0.8234 - recall_23: 0.9092\n",
      "Epoch 45/50\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.3336 - accuracy: 0.8592 - precision_23: 0.8269 - recall_23: 0.9070\n",
      "Epoch 46/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3260 - accuracy: 0.8624 - precision_23: 0.8313 - recall_23: 0.9079\n",
      "Epoch 47/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3244 - accuracy: 0.8620 - precision_23: 0.8250 - recall_23: 0.9173\n",
      "Epoch 48/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3386 - accuracy: 0.8508 - precision_23: 0.8174 - recall_23: 0.9019\n",
      "Epoch 49/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3181 - accuracy: 0.8665 - precision_23: 0.8344 - recall_23: 0.9130\n",
      "Epoch 50/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3281 - accuracy: 0.8611 - precision_23: 0.8270 - recall_23: 0.9118\n",
      "24/24 [==============================] - 1s 2ms/step - loss: 0.3656 - accuracy: 0.8478 - precision_23: 0.8009 - recall_23: 0.9295\n",
      "[CV 3/3] END .........batch_size=100, epochs=50;, score=0.848 total time=  16.0s\n",
      "Epoch 1/100\n",
      "47/47 [==============================] - 7s 4ms/step - loss: 0.6362 - accuracy: 0.6597 - precision_24: 0.6421 - recall_24: 0.7124\n",
      "Epoch 2/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.5450 - accuracy: 0.7355 - precision_24: 0.6979 - recall_24: 0.8249\n",
      "Epoch 3/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.5173 - accuracy: 0.7593 - precision_24: 0.7146 - recall_24: 0.8586\n",
      "Epoch 4/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4988 - accuracy: 0.7673 - precision_24: 0.7239 - recall_24: 0.8594\n",
      "Epoch 5/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4788 - accuracy: 0.7769 - precision_24: 0.7329 - recall_24: 0.8672\n",
      "Epoch 6/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4655 - accuracy: 0.7878 - precision_24: 0.7457 - recall_24: 0.8698\n",
      "Epoch 7/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4645 - accuracy: 0.7844 - precision_24: 0.7469 - recall_24: 0.8564\n",
      "Epoch 8/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4511 - accuracy: 0.7951 - precision_24: 0.7516 - recall_24: 0.8780\n",
      "Epoch 9/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4453 - accuracy: 0.7955 - precision_24: 0.7519 - recall_24: 0.8784\n",
      "Epoch 10/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.8022 - precision_24: 0.7612 - recall_24: 0.8771\n",
      "Epoch 11/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4265 - accuracy: 0.8084 - precision_24: 0.7662 - recall_24: 0.8844\n",
      "Epoch 12/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4164 - accuracy: 0.8114 - precision_24: 0.7756 - recall_24: 0.8732\n",
      "Epoch 13/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4205 - accuracy: 0.8103 - precision_24: 0.7691 - recall_24: 0.8836\n",
      "Epoch 14/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4048 - accuracy: 0.8157 - precision_24: 0.7775 - recall_24: 0.8814\n",
      "Epoch 15/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4027 - accuracy: 0.8161 - precision_24: 0.7743 - recall_24: 0.8892\n",
      "Epoch 16/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4055 - accuracy: 0.8140 - precision_24: 0.7768 - recall_24: 0.8780\n",
      "Epoch 17/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.3903 - accuracy: 0.8249 - precision_24: 0.7813 - recall_24: 0.8995\n",
      "Epoch 18/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3944 - accuracy: 0.8208 - precision_24: 0.7799 - recall_24: 0.8909\n",
      "Epoch 19/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3856 - accuracy: 0.8221 - precision_24: 0.7806 - recall_24: 0.8931\n",
      "Epoch 20/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3866 - accuracy: 0.8245 - precision_24: 0.7822 - recall_24: 0.8965\n",
      "Epoch 21/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3759 - accuracy: 0.8273 - precision_24: 0.7790 - recall_24: 0.9107\n",
      "Epoch 22/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3864 - accuracy: 0.8230 - precision_24: 0.7810 - recall_24: 0.8948\n",
      "Epoch 23/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.3804 - accuracy: 0.8258 - precision_24: 0.7822 - recall_24: 0.9000\n",
      "Epoch 24/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3752 - accuracy: 0.8303 - precision_24: 0.7878 - recall_24: 0.9013\n",
      "Epoch 25/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3738 - accuracy: 0.8283 - precision_24: 0.7893 - recall_24: 0.8931\n",
      "Epoch 26/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3758 - accuracy: 0.8251 - precision_24: 0.7824 - recall_24: 0.8978\n",
      "Epoch 27/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.3735 - accuracy: 0.8268 - precision_24: 0.7861 - recall_24: 0.8952\n",
      "Epoch 28/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.3718 - accuracy: 0.8311 - precision_24: 0.7952 - recall_24: 0.8892\n",
      "Epoch 29/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.3660 - accuracy: 0.8358 - precision_24: 0.7972 - recall_24: 0.8982\n",
      "Epoch 30/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3692 - accuracy: 0.8345 - precision_24: 0.7862 - recall_24: 0.9163\n",
      "Epoch 31/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.3657 - accuracy: 0.8393 - precision_24: 0.7982 - recall_24: 0.9056\n",
      "Epoch 32/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3662 - accuracy: 0.8339 - precision_24: 0.7898 - recall_24: 0.9073\n",
      "Epoch 33/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3634 - accuracy: 0.8328 - precision_24: 0.7892 - recall_24: 0.9056\n",
      "Epoch 34/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.3635 - accuracy: 0.8371 - precision_24: 0.7936 - recall_24: 0.9086\n",
      "Epoch 35/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.3555 - accuracy: 0.8375 - precision_24: 0.7958 - recall_24: 0.9056\n",
      "Epoch 36/100\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.3539 - accuracy: 0.8399 - precision_24: 0.7955 - recall_24: 0.9125\n",
      "Epoch 37/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3518 - accuracy: 0.8399 - precision_24: 0.7977 - recall_24: 0.9082\n",
      "Epoch 38/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3537 - accuracy: 0.8427 - precision_24: 0.7987 - recall_24: 0.9138\n",
      "Epoch 39/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3463 - accuracy: 0.8472 - precision_24: 0.8037 - recall_24: 0.9163\n",
      "Epoch 40/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3462 - accuracy: 0.8444 - precision_24: 0.8020 - recall_24: 0.9120\n",
      "Epoch 41/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.3430 - accuracy: 0.8448 - precision_24: 0.8033 - recall_24: 0.9107\n",
      "Epoch 42/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3441 - accuracy: 0.8515 - precision_24: 0.8084 - recall_24: 0.9189\n",
      "Epoch 43/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3476 - accuracy: 0.8450 - precision_24: 0.8027 - recall_24: 0.9125\n",
      "Epoch 44/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3483 - accuracy: 0.8418 - precision_24: 0.7977 - recall_24: 0.9133\n",
      "Epoch 45/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3428 - accuracy: 0.8502 - precision_24: 0.8113 - recall_24: 0.9103\n",
      "Epoch 46/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3451 - accuracy: 0.8459 - precision_24: 0.8046 - recall_24: 0.9112\n",
      "Epoch 47/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3431 - accuracy: 0.8480 - precision_24: 0.8045 - recall_24: 0.9172\n",
      "Epoch 48/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3370 - accuracy: 0.8528 - precision_24: 0.8126 - recall_24: 0.9146\n",
      "Epoch 49/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3490 - accuracy: 0.8465 - precision_24: 0.8030 - recall_24: 0.9159\n",
      "Epoch 50/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3371 - accuracy: 0.8498 - precision_24: 0.8067 - recall_24: 0.9176\n",
      "Epoch 51/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3377 - accuracy: 0.8508 - precision_24: 0.8144 - recall_24: 0.9064\n",
      "Epoch 52/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3365 - accuracy: 0.8530 - precision_24: 0.8108 - recall_24: 0.9185\n",
      "Epoch 53/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3407 - accuracy: 0.8487 - precision_24: 0.8084 - recall_24: 0.9116\n",
      "Epoch 54/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3210 - accuracy: 0.8603 - precision_24: 0.8187 - recall_24: 0.9232\n",
      "Epoch 55/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3291 - accuracy: 0.8543 - precision_24: 0.8080 - recall_24: 0.9271\n",
      "Epoch 56/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.3302 - accuracy: 0.8658 - precision_24: 0.8203 - recall_24: 0.9349\n",
      "Epoch 57/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.3239 - accuracy: 0.8566 - precision_24: 0.8168 - recall_24: 0.9172\n",
      "Epoch 58/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3224 - accuracy: 0.8598 - precision_24: 0.8169 - recall_24: 0.9254\n",
      "Epoch 59/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.3267 - accuracy: 0.8530 - precision_24: 0.8127 - recall_24: 0.9150\n",
      "Epoch 60/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.3206 - accuracy: 0.8579 - precision_24: 0.8136 - recall_24: 0.9263\n",
      "Epoch 61/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.3310 - accuracy: 0.8573 - precision_24: 0.8190 - recall_24: 0.9150\n",
      "Epoch 62/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.3230 - accuracy: 0.8601 - precision_24: 0.8199 - recall_24: 0.9207\n",
      "Epoch 63/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3307 - accuracy: 0.8558 - precision_24: 0.8168 - recall_24: 0.9150\n",
      "Epoch 64/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3165 - accuracy: 0.8609 - precision_24: 0.8158 - recall_24: 0.9301\n",
      "Epoch 65/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3247 - accuracy: 0.8551 - precision_24: 0.8156 - recall_24: 0.9155\n",
      "Epoch 66/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3297 - accuracy: 0.8568 - precision_24: 0.8154 - recall_24: 0.9202\n",
      "Epoch 67/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3245 - accuracy: 0.8560 - precision_24: 0.8166 - recall_24: 0.9159\n",
      "Epoch 68/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3208 - accuracy: 0.8586 - precision_24: 0.8172 - recall_24: 0.9215\n",
      "Epoch 69/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3196 - accuracy: 0.8613 - precision_24: 0.8215 - recall_24: 0.9211\n",
      "Epoch 70/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3165 - accuracy: 0.8665 - precision_24: 0.8254 - recall_24: 0.9276\n",
      "Epoch 71/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3151 - accuracy: 0.8676 - precision_24: 0.8285 - recall_24: 0.9250\n",
      "Epoch 72/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3121 - accuracy: 0.8641 - precision_24: 0.8227 - recall_24: 0.9263\n",
      "Epoch 73/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3121 - accuracy: 0.8650 - precision_24: 0.8225 - recall_24: 0.9288\n",
      "Epoch 74/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3112 - accuracy: 0.8648 - precision_24: 0.8256 - recall_24: 0.9228\n",
      "Epoch 75/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3211 - accuracy: 0.8598 - precision_24: 0.8208 - recall_24: 0.9185\n",
      "Epoch 76/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.3054 - accuracy: 0.8663 - precision_24: 0.8241 - recall_24: 0.9293\n",
      "Epoch 77/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.3167 - accuracy: 0.8592 - precision_24: 0.8223 - recall_24: 0.9142\n",
      "Epoch 78/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.3193 - accuracy: 0.8590 - precision_24: 0.8157 - recall_24: 0.9254\n",
      "Epoch 79/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3091 - accuracy: 0.8658 - precision_24: 0.8252 - recall_24: 0.9263\n",
      "Epoch 80/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3060 - accuracy: 0.8693 - precision_24: 0.8278 - recall_24: 0.9306\n",
      "Epoch 81/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3134 - accuracy: 0.8598 - precision_24: 0.8198 - recall_24: 0.9202\n",
      "Epoch 82/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3103 - accuracy: 0.8654 - precision_24: 0.8226 - recall_24: 0.9297\n",
      "Epoch 83/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3078 - accuracy: 0.8723 - precision_24: 0.8346 - recall_24: 0.9267\n",
      "Epoch 84/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3171 - accuracy: 0.8616 - precision_24: 0.8221 - recall_24: 0.9207\n",
      "Epoch 85/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3259 - accuracy: 0.8588 - precision_24: 0.8178 - recall_24: 0.9211\n",
      "Epoch 86/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3082 - accuracy: 0.8712 - precision_24: 0.8332 - recall_24: 0.9263\n",
      "Epoch 87/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3142 - accuracy: 0.8652 - precision_24: 0.8255 - recall_24: 0.9241\n",
      "Epoch 88/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3038 - accuracy: 0.8684 - precision_24: 0.8270 - recall_24: 0.9297\n",
      "Epoch 89/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3052 - accuracy: 0.8703 - precision_24: 0.8299 - recall_24: 0.9297\n",
      "Epoch 90/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3066 - accuracy: 0.8682 - precision_24: 0.8300 - recall_24: 0.9241\n",
      "Epoch 91/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3148 - accuracy: 0.8624 - precision_24: 0.8221 - recall_24: 0.9228\n",
      "Epoch 92/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3048 - accuracy: 0.8708 - precision_24: 0.8328 - recall_24: 0.9258\n",
      "Epoch 93/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3106 - accuracy: 0.8667 - precision_24: 0.8287 - recall_24: 0.9224\n",
      "Epoch 94/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3057 - accuracy: 0.8684 - precision_24: 0.8275 - recall_24: 0.9288\n",
      "Epoch 95/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3061 - accuracy: 0.8673 - precision_24: 0.8267 - recall_24: 0.9276\n",
      "Epoch 96/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3098 - accuracy: 0.8667 - precision_24: 0.8267 - recall_24: 0.9258\n",
      "Epoch 97/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3007 - accuracy: 0.8718 - precision_24: 0.8296 - recall_24: 0.9340\n",
      "Epoch 98/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3007 - accuracy: 0.8763 - precision_24: 0.8324 - recall_24: 0.9405\n",
      "Epoch 99/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3077 - accuracy: 0.8652 - precision_24: 0.8260 - recall_24: 0.9232\n",
      "Epoch 100/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3182 - accuracy: 0.8598 - precision_24: 0.8223 - recall_24: 0.9159\n",
      "24/24 [==============================] - 1s 3ms/step - loss: 0.3389 - accuracy: 0.8564 - precision_24: 0.8017 - recall_24: 0.9517\n",
      "[CV 1/3] END ........batch_size=100, epochs=100;, score=0.856 total time=  27.6s\n",
      "Epoch 1/100\n",
      "47/47 [==============================] - 6s 4ms/step - loss: 0.8463 - accuracy: 0.5754 - precision_25: 0.5821 - recall_25: 0.5670\n",
      "Epoch 2/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.6440 - accuracy: 0.6470 - precision_25: 0.6533 - recall_25: 0.6425\n",
      "Epoch 3/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5807 - accuracy: 0.6989 - precision_25: 0.6667 - recall_25: 0.8083\n",
      "Epoch 4/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.5352 - accuracy: 0.7467 - precision_25: 0.6835 - recall_25: 0.9288\n",
      "Epoch 5/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.5078 - accuracy: 0.7572 - precision_25: 0.6918 - recall_25: 0.9368\n",
      "Epoch 6/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4937 - accuracy: 0.7593 - precision_25: 0.6979 - recall_25: 0.9237\n",
      "Epoch 7/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4806 - accuracy: 0.7707 - precision_25: 0.7084 - recall_25: 0.9283\n",
      "Epoch 8/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4730 - accuracy: 0.7754 - precision_25: 0.7114 - recall_25: 0.9347\n",
      "Epoch 9/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4615 - accuracy: 0.7799 - precision_25: 0.7206 - recall_25: 0.9220\n",
      "Epoch 10/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4438 - accuracy: 0.7962 - precision_25: 0.7354 - recall_25: 0.9321\n",
      "Epoch 11/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4436 - accuracy: 0.7943 - precision_25: 0.7360 - recall_25: 0.9245\n",
      "Epoch 12/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4316 - accuracy: 0.7943 - precision_25: 0.7319 - recall_25: 0.9355\n",
      "Epoch 13/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4305 - accuracy: 0.7966 - precision_25: 0.7370 - recall_25: 0.9292\n",
      "Epoch 14/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4190 - accuracy: 0.8071 - precision_25: 0.7473 - recall_25: 0.9343\n",
      "Epoch 15/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4189 - accuracy: 0.8009 - precision_25: 0.7470 - recall_25: 0.9165\n",
      "Epoch 16/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4161 - accuracy: 0.8052 - precision_25: 0.7422 - recall_25: 0.9415\n",
      "Epoch 17/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4139 - accuracy: 0.8093 - precision_25: 0.7500 - recall_25: 0.9338\n",
      "Epoch 18/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4065 - accuracy: 0.8033 - precision_25: 0.7447 - recall_25: 0.9292\n",
      "Epoch 19/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4039 - accuracy: 0.8135 - precision_25: 0.7519 - recall_25: 0.9419\n",
      "Epoch 20/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4067 - accuracy: 0.8058 - precision_25: 0.7453 - recall_25: 0.9355\n",
      "Epoch 21/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4079 - accuracy: 0.8050 - precision_25: 0.7479 - recall_25: 0.9262\n",
      "Epoch 22/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3984 - accuracy: 0.8144 - precision_25: 0.7574 - recall_25: 0.9309\n",
      "Epoch 23/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3954 - accuracy: 0.8110 - precision_25: 0.7545 - recall_25: 0.9279\n",
      "Epoch 24/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.3906 - accuracy: 0.8170 - precision_25: 0.7570 - recall_25: 0.9394\n",
      "Epoch 25/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3920 - accuracy: 0.8187 - precision_25: 0.7609 - recall_25: 0.9351\n",
      "Epoch 26/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3861 - accuracy: 0.8185 - precision_25: 0.7572 - recall_25: 0.9432\n",
      "Epoch 27/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.3859 - accuracy: 0.8174 - precision_25: 0.7626 - recall_25: 0.9275\n",
      "Epoch 28/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.3766 - accuracy: 0.8232 - precision_25: 0.7612 - recall_25: 0.9474\n",
      "Epoch 29/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.3802 - accuracy: 0.8236 - precision_25: 0.7638 - recall_25: 0.9423\n",
      "Epoch 30/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3781 - accuracy: 0.8240 - precision_25: 0.7631 - recall_25: 0.9453\n",
      "Epoch 31/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3745 - accuracy: 0.8228 - precision_25: 0.7646 - recall_25: 0.9381\n",
      "Epoch 32/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3691 - accuracy: 0.8277 - precision_25: 0.7666 - recall_25: 0.9474\n",
      "Epoch 33/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3733 - accuracy: 0.8262 - precision_25: 0.7713 - recall_25: 0.9326\n",
      "Epoch 34/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3707 - accuracy: 0.8268 - precision_25: 0.7678 - recall_25: 0.9423\n",
      "Epoch 35/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3666 - accuracy: 0.8292 - precision_25: 0.7676 - recall_25: 0.9495\n",
      "Epoch 36/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3670 - accuracy: 0.8335 - precision_25: 0.7751 - recall_25: 0.9444\n",
      "Epoch 37/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3608 - accuracy: 0.8352 - precision_25: 0.7828 - recall_25: 0.9326\n",
      "Epoch 38/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3624 - accuracy: 0.8373 - precision_25: 0.7785 - recall_25: 0.9478\n",
      "Epoch 39/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.3651 - accuracy: 0.8298 - precision_25: 0.7729 - recall_25: 0.9394\n",
      "Epoch 40/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3636 - accuracy: 0.8345 - precision_25: 0.7771 - recall_25: 0.9432\n",
      "Epoch 41/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3553 - accuracy: 0.8382 - precision_25: 0.7794 - recall_25: 0.9483\n",
      "Epoch 42/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.3560 - accuracy: 0.8388 - precision_25: 0.7845 - recall_25: 0.9389\n",
      "Epoch 43/100\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.3586 - accuracy: 0.8318 - precision_25: 0.7766 - recall_25: 0.9364\n",
      "Epoch 44/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.3523 - accuracy: 0.8399 - precision_25: 0.7849 - recall_25: 0.9411\n",
      "Epoch 45/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.3497 - accuracy: 0.8420 - precision_25: 0.7847 - recall_25: 0.9474\n",
      "Epoch 46/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.3531 - accuracy: 0.8382 - precision_25: 0.7809 - recall_25: 0.9449\n",
      "Epoch 47/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3531 - accuracy: 0.8365 - precision_25: 0.7829 - recall_25: 0.9360\n",
      "Epoch 48/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3413 - accuracy: 0.8463 - precision_25: 0.7872 - recall_25: 0.9538\n",
      "Epoch 49/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3438 - accuracy: 0.8463 - precision_25: 0.7923 - recall_25: 0.9432\n",
      "Epoch 50/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3423 - accuracy: 0.8420 - precision_25: 0.7869 - recall_25: 0.9427\n",
      "Epoch 51/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3499 - accuracy: 0.8388 - precision_25: 0.7814 - recall_25: 0.9457\n",
      "Epoch 52/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3461 - accuracy: 0.8431 - precision_25: 0.7869 - recall_25: 0.9457\n",
      "Epoch 53/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.3430 - accuracy: 0.8412 - precision_25: 0.7824 - recall_25: 0.9500\n",
      "Epoch 54/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3464 - accuracy: 0.8388 - precision_25: 0.7814 - recall_25: 0.9457\n",
      "Epoch 55/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.3426 - accuracy: 0.8429 - precision_25: 0.7844 - recall_25: 0.9504\n",
      "Epoch 56/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3465 - accuracy: 0.8401 - precision_25: 0.7850 - recall_25: 0.9415\n",
      "Epoch 57/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3415 - accuracy: 0.8431 - precision_25: 0.7847 - recall_25: 0.9504\n",
      "Epoch 58/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3367 - accuracy: 0.8489 - precision_25: 0.7940 - recall_25: 0.9466\n",
      "Epoch 59/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3403 - accuracy: 0.8442 - precision_25: 0.7864 - recall_25: 0.9495\n",
      "Epoch 60/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3382 - accuracy: 0.8463 - precision_25: 0.7911 - recall_25: 0.9457\n",
      "Epoch 61/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3402 - accuracy: 0.8446 - precision_25: 0.7878 - recall_25: 0.9478\n",
      "Epoch 62/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3290 - accuracy: 0.8519 - precision_25: 0.7955 - recall_25: 0.9517\n",
      "Epoch 63/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3452 - accuracy: 0.8420 - precision_25: 0.7919 - recall_25: 0.9326\n",
      "Epoch 64/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3364 - accuracy: 0.8470 - precision_25: 0.7878 - recall_25: 0.9542\n",
      "Epoch 65/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3350 - accuracy: 0.8493 - precision_25: 0.7956 - recall_25: 0.9444\n",
      "Epoch 66/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3267 - accuracy: 0.8532 - precision_25: 0.8008 - recall_25: 0.9444\n",
      "Epoch 67/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3266 - accuracy: 0.8498 - precision_25: 0.7941 - recall_25: 0.9487\n",
      "Epoch 68/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3275 - accuracy: 0.8545 - precision_25: 0.7951 - recall_25: 0.9593\n",
      "Epoch 69/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3403 - accuracy: 0.8431 - precision_25: 0.7859 - recall_25: 0.9478\n",
      "Epoch 70/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3317 - accuracy: 0.8493 - precision_25: 0.7915 - recall_25: 0.9529\n",
      "Epoch 71/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3297 - accuracy: 0.8515 - precision_25: 0.7947 - recall_25: 0.9521\n",
      "Epoch 72/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3338 - accuracy: 0.8444 - precision_25: 0.7904 - recall_25: 0.9419\n",
      "Epoch 73/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.3225 - accuracy: 0.8549 - precision_25: 0.7950 - recall_25: 0.9606\n",
      "Epoch 74/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3292 - accuracy: 0.8485 - precision_25: 0.7904 - recall_25: 0.9529\n",
      "Epoch 75/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.3266 - accuracy: 0.8513 - precision_25: 0.7911 - recall_25: 0.9589\n",
      "Epoch 76/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.3233 - accuracy: 0.8545 - precision_25: 0.7957 - recall_25: 0.9580\n",
      "Epoch 77/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3282 - accuracy: 0.8521 - precision_25: 0.7968 - recall_25: 0.9495\n",
      "Epoch 78/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3192 - accuracy: 0.8560 - precision_25: 0.7983 - recall_25: 0.9567\n",
      "Epoch 79/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.3269 - accuracy: 0.8468 - precision_25: 0.7962 - recall_25: 0.9364\n",
      "Epoch 80/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.3296 - accuracy: 0.8502 - precision_25: 0.7983 - recall_25: 0.9415\n",
      "Epoch 81/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.3296 - accuracy: 0.8485 - precision_25: 0.7887 - recall_25: 0.9563\n",
      "Epoch 82/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.3239 - accuracy: 0.8526 - precision_25: 0.7965 - recall_25: 0.9512\n",
      "Epoch 83/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.3162 - accuracy: 0.8553 - precision_25: 0.8006 - recall_25: 0.9504\n",
      "Epoch 84/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3148 - accuracy: 0.8566 - precision_25: 0.8019 - recall_25: 0.9512\n",
      "Epoch 85/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3188 - accuracy: 0.8519 - precision_25: 0.7948 - recall_25: 0.9529\n",
      "Epoch 86/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3146 - accuracy: 0.8575 - precision_25: 0.7994 - recall_25: 0.9584\n",
      "Epoch 87/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3259 - accuracy: 0.8536 - precision_25: 0.7973 - recall_25: 0.9525\n",
      "Epoch 88/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3097 - accuracy: 0.8571 - precision_25: 0.7984 - recall_25: 0.9593\n",
      "Epoch 89/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3136 - accuracy: 0.8571 - precision_25: 0.7997 - recall_25: 0.9567\n",
      "Epoch 90/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3155 - accuracy: 0.8532 - precision_25: 0.8021 - recall_25: 0.9419\n",
      "Epoch 91/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3155 - accuracy: 0.8562 - precision_25: 0.7973 - recall_25: 0.9593\n",
      "Epoch 92/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3089 - accuracy: 0.8588 - precision_25: 0.8079 - recall_25: 0.9453\n",
      "Epoch 93/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3155 - accuracy: 0.8586 - precision_25: 0.8011 - recall_25: 0.9580\n",
      "Epoch 94/100\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.3185 - accuracy: 0.8508 - precision_25: 0.7972 - recall_25: 0.9453\n",
      "Epoch 95/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.3140 - accuracy: 0.8609 - precision_25: 0.8064 - recall_25: 0.9538\n",
      "Epoch 96/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3118 - accuracy: 0.8607 - precision_25: 0.8013 - recall_25: 0.9631\n",
      "Epoch 97/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3152 - accuracy: 0.8553 - precision_25: 0.7983 - recall_25: 0.9550\n",
      "Epoch 98/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3164 - accuracy: 0.8571 - precision_25: 0.8034 - recall_25: 0.9495\n",
      "Epoch 99/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3137 - accuracy: 0.8598 - precision_25: 0.8026 - recall_25: 0.9584\n",
      "Epoch 100/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3102 - accuracy: 0.8601 - precision_25: 0.8072 - recall_25: 0.9500\n",
      "24/24 [==============================] - 1s 2ms/step - loss: 0.3602 - accuracy: 0.8397 - precision_25: 0.7645 - recall_25: 0.9720\n",
      "[CV 2/3] END ........batch_size=100, epochs=100;, score=0.840 total time=  27.4s\n",
      "Epoch 1/100\n",
      "47/47 [==============================] - 5s 5ms/step - loss: 0.8571 - accuracy: 0.4946 - precision_26: 0.4945 - recall_26: 0.6810\n",
      "Epoch 2/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.6738 - accuracy: 0.6204 - precision_26: 0.5962 - recall_26: 0.7361\n",
      "Epoch 3/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.5847 - accuracy: 0.7085 - precision_26: 0.6863 - recall_26: 0.7637\n",
      "Epoch 4/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.5228 - accuracy: 0.7580 - precision_26: 0.7289 - recall_26: 0.8183\n",
      "Epoch 5/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4894 - accuracy: 0.7805 - precision_26: 0.7522 - recall_26: 0.8338\n",
      "Epoch 6/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4723 - accuracy: 0.7846 - precision_26: 0.7525 - recall_26: 0.8455\n",
      "Epoch 7/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4581 - accuracy: 0.7928 - precision_26: 0.7616 - recall_26: 0.8498\n",
      "Epoch 8/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4470 - accuracy: 0.7981 - precision_26: 0.7657 - recall_26: 0.8567\n",
      "Epoch 9/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4436 - accuracy: 0.7998 - precision_26: 0.7620 - recall_26: 0.8696\n",
      "Epoch 10/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4332 - accuracy: 0.8060 - precision_26: 0.7708 - recall_26: 0.8687\n",
      "Epoch 11/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4230 - accuracy: 0.8125 - precision_26: 0.7732 - recall_26: 0.8820\n",
      "Epoch 12/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4173 - accuracy: 0.8148 - precision_26: 0.7713 - recall_26: 0.8928\n",
      "Epoch 13/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4150 - accuracy: 0.8112 - precision_26: 0.7711 - recall_26: 0.8829\n",
      "Epoch 14/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4115 - accuracy: 0.8198 - precision_26: 0.7817 - recall_26: 0.8851\n",
      "Epoch 15/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4089 - accuracy: 0.8140 - precision_26: 0.7712 - recall_26: 0.8907\n",
      "Epoch 16/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4105 - accuracy: 0.8133 - precision_26: 0.7792 - recall_26: 0.8721\n",
      "Epoch 17/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4023 - accuracy: 0.8217 - precision_26: 0.7842 - recall_26: 0.8855\n",
      "Epoch 18/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3968 - accuracy: 0.8240 - precision_26: 0.7825 - recall_26: 0.8954\n",
      "Epoch 19/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3878 - accuracy: 0.8313 - precision_26: 0.7918 - recall_26: 0.8971\n",
      "Epoch 20/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3967 - accuracy: 0.8240 - precision_26: 0.7838 - recall_26: 0.8928\n",
      "Epoch 21/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3946 - accuracy: 0.8204 - precision_26: 0.7790 - recall_26: 0.8924\n",
      "Epoch 22/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3897 - accuracy: 0.8228 - precision_26: 0.7853 - recall_26: 0.8864\n",
      "Epoch 23/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3815 - accuracy: 0.8326 - precision_26: 0.7959 - recall_26: 0.8928\n",
      "Epoch 24/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.3771 - accuracy: 0.8318 - precision_26: 0.7908 - recall_26: 0.9001\n",
      "Epoch 25/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3735 - accuracy: 0.8354 - precision_26: 0.7953 - recall_26: 0.9014\n",
      "Epoch 26/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3772 - accuracy: 0.8303 - precision_26: 0.7936 - recall_26: 0.8907\n",
      "Epoch 27/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3715 - accuracy: 0.8393 - precision_26: 0.8008 - recall_26: 0.9014\n",
      "Epoch 28/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3650 - accuracy: 0.8395 - precision_26: 0.8057 - recall_26: 0.8928\n",
      "Epoch 29/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.3560 - accuracy: 0.8455 - precision_26: 0.8102 - recall_26: 0.9006\n",
      "Epoch 30/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3635 - accuracy: 0.8393 - precision_26: 0.8031 - recall_26: 0.8971\n",
      "Epoch 31/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3649 - accuracy: 0.8393 - precision_26: 0.8066 - recall_26: 0.8907\n",
      "Epoch 32/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3606 - accuracy: 0.8371 - precision_26: 0.8030 - recall_26: 0.8915\n",
      "Epoch 33/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3513 - accuracy: 0.8457 - precision_26: 0.8072 - recall_26: 0.9066\n",
      "Epoch 34/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3513 - accuracy: 0.8442 - precision_26: 0.8050 - recall_26: 0.9066\n",
      "Epoch 35/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3447 - accuracy: 0.8483 - precision_26: 0.8136 - recall_26: 0.9019\n",
      "Epoch 36/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3564 - accuracy: 0.8431 - precision_26: 0.8080 - recall_26: 0.8984\n",
      "Epoch 37/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3520 - accuracy: 0.8476 - precision_26: 0.8100 - recall_26: 0.9066\n",
      "Epoch 38/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3402 - accuracy: 0.8564 - precision_26: 0.8207 - recall_26: 0.9105\n",
      "Epoch 39/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3375 - accuracy: 0.8586 - precision_26: 0.8265 - recall_26: 0.9062\n",
      "Epoch 40/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3459 - accuracy: 0.8543 - precision_26: 0.8213 - recall_26: 0.9040\n",
      "Epoch 41/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3394 - accuracy: 0.8558 - precision_26: 0.8203 - recall_26: 0.9096\n",
      "Epoch 42/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3401 - accuracy: 0.8534 - precision_26: 0.8218 - recall_26: 0.9010\n",
      "Epoch 43/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3425 - accuracy: 0.8532 - precision_26: 0.8187 - recall_26: 0.9057\n",
      "Epoch 44/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3340 - accuracy: 0.8581 - precision_26: 0.8256 - recall_26: 0.9066\n",
      "Epoch 45/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3354 - accuracy: 0.8588 - precision_26: 0.8260 - recall_26: 0.9074\n",
      "Epoch 46/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3435 - accuracy: 0.8506 - precision_26: 0.8191 - recall_26: 0.8984\n",
      "Epoch 47/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3271 - accuracy: 0.8609 - precision_26: 0.8270 - recall_26: 0.9113\n",
      "Epoch 48/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3270 - accuracy: 0.8626 - precision_26: 0.8288 - recall_26: 0.9126\n",
      "Epoch 49/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3203 - accuracy: 0.8643 - precision_26: 0.8335 - recall_26: 0.9092\n",
      "Epoch 50/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.8553 - precision_26: 0.8214 - recall_26: 0.9066\n",
      "Epoch 51/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.3247 - accuracy: 0.8628 - precision_26: 0.8327 - recall_26: 0.9066\n",
      "Epoch 52/100\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.3296 - accuracy: 0.8616 - precision_26: 0.8284 - recall_26: 0.9105\n",
      "Epoch 53/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3289 - accuracy: 0.8616 - precision_26: 0.8282 - recall_26: 0.9109\n",
      "Epoch 54/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3271 - accuracy: 0.8603 - precision_26: 0.8275 - recall_26: 0.9087\n",
      "Epoch 55/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3235 - accuracy: 0.8654 - precision_26: 0.8281 - recall_26: 0.9208\n",
      "Epoch 56/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3210 - accuracy: 0.8652 - precision_26: 0.8322 - recall_26: 0.9135\n",
      "Epoch 57/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3187 - accuracy: 0.8680 - precision_26: 0.8346 - recall_26: 0.9165\n",
      "Epoch 58/100\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.3196 - accuracy: 0.8671 - precision_26: 0.8327 - recall_26: 0.9173\n",
      "Epoch 59/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3157 - accuracy: 0.8710 - precision_26: 0.8329 - recall_26: 0.9268\n",
      "Epoch 60/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3200 - accuracy: 0.8712 - precision_26: 0.8355 - recall_26: 0.9229\n",
      "Epoch 61/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3194 - accuracy: 0.8671 - precision_26: 0.8364 - recall_26: 0.9113\n",
      "Epoch 62/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3222 - accuracy: 0.8661 - precision_26: 0.8311 - recall_26: 0.9173\n",
      "Epoch 63/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3206 - accuracy: 0.8637 - precision_26: 0.8283 - recall_26: 0.9161\n",
      "Epoch 64/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3168 - accuracy: 0.8706 - precision_26: 0.8302 - recall_26: 0.9303\n",
      "Epoch 65/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3254 - accuracy: 0.8588 - precision_26: 0.8276 - recall_26: 0.9049\n",
      "Epoch 66/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3191 - accuracy: 0.8676 - precision_26: 0.8308 - recall_26: 0.9217\n",
      "Epoch 67/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3126 - accuracy: 0.8703 - precision_26: 0.8371 - recall_26: 0.9182\n",
      "Epoch 68/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3168 - accuracy: 0.8663 - precision_26: 0.8338 - recall_26: 0.9135\n",
      "Epoch 69/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3202 - accuracy: 0.8658 - precision_26: 0.8350 - recall_26: 0.9105\n",
      "Epoch 70/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3129 - accuracy: 0.8718 - precision_26: 0.8313 - recall_26: 0.9316\n",
      "Epoch 71/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3146 - accuracy: 0.8714 - precision_26: 0.8388 - recall_26: 0.9182\n",
      "Epoch 72/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3065 - accuracy: 0.8708 - precision_26: 0.8383 - recall_26: 0.9173\n",
      "Epoch 73/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3149 - accuracy: 0.8658 - precision_26: 0.8363 - recall_26: 0.9083\n",
      "Epoch 74/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3031 - accuracy: 0.8766 - precision_26: 0.8435 - recall_26: 0.9234\n",
      "Epoch 75/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3154 - accuracy: 0.8710 - precision_26: 0.8378 - recall_26: 0.9186\n",
      "Epoch 76/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3134 - accuracy: 0.8633 - precision_26: 0.8300 - recall_26: 0.9122\n",
      "Epoch 77/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3160 - accuracy: 0.8667 - precision_26: 0.8342 - recall_26: 0.9139\n",
      "Epoch 78/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3005 - accuracy: 0.8804 - precision_26: 0.8441 - recall_26: 0.9320\n",
      "Epoch 79/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3138 - accuracy: 0.8725 - precision_26: 0.8396 - recall_26: 0.9195\n",
      "Epoch 80/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3046 - accuracy: 0.8766 - precision_26: 0.8400 - recall_26: 0.9290\n",
      "Epoch 81/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3052 - accuracy: 0.8753 - precision_26: 0.8434 - recall_26: 0.9204\n",
      "Epoch 82/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.2948 - accuracy: 0.8811 - precision_26: 0.8480 - recall_26: 0.9272\n",
      "Epoch 83/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3048 - accuracy: 0.8763 - precision_26: 0.8373 - recall_26: 0.9328\n",
      "Epoch 84/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3040 - accuracy: 0.8742 - precision_26: 0.8442 - recall_26: 0.9165\n",
      "Epoch 85/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3108 - accuracy: 0.8716 - precision_26: 0.8380 - recall_26: 0.9199\n",
      "Epoch 86/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3036 - accuracy: 0.8791 - precision_26: 0.8459 - recall_26: 0.9260\n",
      "Epoch 87/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.2984 - accuracy: 0.8774 - precision_26: 0.8437 - recall_26: 0.9251\n",
      "Epoch 88/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.2973 - accuracy: 0.8800 - precision_26: 0.8486 - recall_26: 0.9238\n",
      "Epoch 89/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3002 - accuracy: 0.8785 - precision_26: 0.8492 - recall_26: 0.9191\n",
      "Epoch 90/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3148 - accuracy: 0.8718 - precision_26: 0.8421 - recall_26: 0.9139\n",
      "Epoch 91/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3006 - accuracy: 0.8763 - precision_26: 0.8410 - recall_26: 0.9268\n",
      "Epoch 92/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3000 - accuracy: 0.8751 - precision_26: 0.8385 - recall_26: 0.9277\n",
      "Epoch 93/100\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.2959 - accuracy: 0.8813 - precision_26: 0.8467 - recall_26: 0.9298\n",
      "Epoch 94/100\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.2926 - accuracy: 0.8815 - precision_26: 0.8460 - recall_26: 0.9316\n",
      "Epoch 95/100\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.2960 - accuracy: 0.8808 - precision_26: 0.8466 - recall_26: 0.9290\n",
      "Epoch 96/100\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.2953 - accuracy: 0.8808 - precision_26: 0.8499 - recall_26: 0.9238\n",
      "Epoch 97/100\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.3040 - accuracy: 0.8763 - precision_26: 0.8437 - recall_26: 0.9225\n",
      "Epoch 98/100\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.2946 - accuracy: 0.8819 - precision_26: 0.8464 - recall_26: 0.9320\n",
      "Epoch 99/100\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.2995 - accuracy: 0.8774 - precision_26: 0.8445 - recall_26: 0.9238\n",
      "Epoch 100/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.2918 - accuracy: 0.8821 - precision_26: 0.8472 - recall_26: 0.9311\n",
      "24/24 [==============================] - 1s 5ms/step - loss: 0.3260 - accuracy: 0.8697 - precision_26: 0.8236 - recall_26: 0.9439\n",
      "[CV 3/3] END ........batch_size=100, epochs=100;, score=0.870 total time=  26.3s\n",
      "Epoch 1/100\n",
      "140/140 [==============================] - 7s 4ms/step - loss: 0.6498 - accuracy: 0.6737 - precision_27: 0.6805 - recall_27: 0.6549\n",
      "Epoch 2/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.4933 - accuracy: 0.7730 - precision_27: 0.7427 - recall_27: 0.8354\n",
      "Epoch 3/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.4633 - accuracy: 0.7894 - precision_27: 0.7507 - recall_27: 0.8666\n",
      "Epoch 4/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.4517 - accuracy: 0.7927 - precision_27: 0.7497 - recall_27: 0.8789\n",
      "Epoch 5/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.4387 - accuracy: 0.7960 - precision_27: 0.7545 - recall_27: 0.8774\n",
      "Epoch 6/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.4387 - accuracy: 0.7943 - precision_27: 0.7529 - recall_27: 0.8760\n",
      "Epoch 7/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.4338 - accuracy: 0.8011 - precision_27: 0.7583 - recall_27: 0.8840\n",
      "Epoch 8/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.4334 - accuracy: 0.7995 - precision_27: 0.7636 - recall_27: 0.8677\n",
      "Epoch 9/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.4233 - accuracy: 0.8035 - precision_27: 0.7646 - recall_27: 0.8771\n",
      "Epoch 10/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.4249 - accuracy: 0.8014 - precision_27: 0.7609 - recall_27: 0.8791\n",
      "Epoch 11/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.4211 - accuracy: 0.8067 - precision_27: 0.7693 - recall_27: 0.8763\n",
      "Epoch 12/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.4133 - accuracy: 0.8095 - precision_27: 0.7709 - recall_27: 0.8809\n",
      "Epoch 13/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.4091 - accuracy: 0.8127 - precision_27: 0.7698 - recall_27: 0.8923\n",
      "Epoch 14/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.4122 - accuracy: 0.8087 - precision_27: 0.7692 - recall_27: 0.8820\n",
      "Epoch 15/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.4053 - accuracy: 0.8137 - precision_27: 0.7726 - recall_27: 0.8891\n",
      "Epoch 16/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.4055 - accuracy: 0.8095 - precision_27: 0.7711 - recall_27: 0.8806\n",
      "Epoch 17/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.3979 - accuracy: 0.8183 - precision_27: 0.7782 - recall_27: 0.8903\n",
      "Epoch 18/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.3972 - accuracy: 0.8191 - precision_27: 0.7849 - recall_27: 0.8791\n",
      "Epoch 19/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.3967 - accuracy: 0.8158 - precision_27: 0.7835 - recall_27: 0.8729\n",
      "Epoch 20/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.3979 - accuracy: 0.8095 - precision_27: 0.7745 - recall_27: 0.8734\n",
      "Epoch 21/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.3907 - accuracy: 0.8227 - precision_27: 0.7912 - recall_27: 0.8769\n",
      "Epoch 22/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.3930 - accuracy: 0.8168 - precision_27: 0.7806 - recall_27: 0.8814\n",
      "Epoch 23/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.3852 - accuracy: 0.8228 - precision_27: 0.7930 - recall_27: 0.8737\n",
      "Epoch 24/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.3817 - accuracy: 0.8223 - precision_27: 0.7873 - recall_27: 0.8831\n",
      "Epoch 25/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.3838 - accuracy: 0.8240 - precision_27: 0.7899 - recall_27: 0.8829\n",
      "Epoch 26/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.3864 - accuracy: 0.8234 - precision_27: 0.7866 - recall_27: 0.8877\n",
      "Epoch 27/100\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.3805 - accuracy: 0.8271 - precision_27: 0.7933 - recall_27: 0.8849\n",
      "Epoch 28/100\n",
      "140/140 [==============================] - 1s 9ms/step - loss: 0.3797 - accuracy: 0.8240 - precision_27: 0.7877 - recall_27: 0.8871\n",
      "Epoch 29/100\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.3783 - accuracy: 0.8300 - precision_27: 0.7984 - recall_27: 0.8829\n",
      "Epoch 30/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.3796 - accuracy: 0.8223 - precision_27: 0.7895 - recall_27: 0.8789\n",
      "Epoch 31/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.3754 - accuracy: 0.8235 - precision_27: 0.7896 - recall_27: 0.8823\n",
      "Epoch 32/100\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.3737 - accuracy: 0.8295 - precision_27: 0.7925 - recall_27: 0.8929\n",
      "Epoch 33/100\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.3756 - accuracy: 0.8247 - precision_27: 0.7918 - recall_27: 0.8811\n",
      "Epoch 34/100\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.3710 - accuracy: 0.8255 - precision_27: 0.7881 - recall_27: 0.8906\n",
      "Epoch 35/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.3709 - accuracy: 0.8261 - precision_27: 0.7916 - recall_27: 0.8854\n",
      "Epoch 36/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.3640 - accuracy: 0.8323 - precision_27: 0.8005 - recall_27: 0.8851\n",
      "Epoch 37/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.3744 - accuracy: 0.8291 - precision_27: 0.7930 - recall_27: 0.8909\n",
      "Epoch 38/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.3685 - accuracy: 0.8303 - precision_27: 0.7946 - recall_27: 0.8909\n",
      "Epoch 39/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.3607 - accuracy: 0.8380 - precision_27: 0.8016 - recall_27: 0.8983\n",
      "Epoch 40/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.3664 - accuracy: 0.8310 - precision_27: 0.7974 - recall_27: 0.8874\n",
      "Epoch 41/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.3657 - accuracy: 0.8324 - precision_27: 0.7984 - recall_27: 0.8894\n",
      "Epoch 42/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.3641 - accuracy: 0.8283 - precision_27: 0.7915 - recall_27: 0.8914\n",
      "Epoch 43/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.3603 - accuracy: 0.8393 - precision_27: 0.8007 - recall_27: 0.9034\n",
      "Epoch 44/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.3595 - accuracy: 0.8345 - precision_27: 0.7989 - recall_27: 0.8943\n",
      "Epoch 45/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.3548 - accuracy: 0.8348 - precision_27: 0.7946 - recall_27: 0.9031\n",
      "Epoch 46/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.3577 - accuracy: 0.8353 - precision_27: 0.8002 - recall_27: 0.8937\n",
      "Epoch 47/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.3515 - accuracy: 0.8428 - precision_27: 0.8029 - recall_27: 0.9089\n",
      "Epoch 48/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.3511 - accuracy: 0.8378 - precision_27: 0.8008 - recall_27: 0.8994\n",
      "Epoch 49/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.3549 - accuracy: 0.8385 - precision_27: 0.8034 - recall_27: 0.8966\n",
      "Epoch 50/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.3554 - accuracy: 0.8384 - precision_27: 0.7995 - recall_27: 0.9034\n",
      "Epoch 51/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.3531 - accuracy: 0.8361 - precision_27: 0.7990 - recall_27: 0.8983\n",
      "Epoch 52/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.3558 - accuracy: 0.8383 - precision_27: 0.8008 - recall_27: 0.9006\n",
      "Epoch 53/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.3478 - accuracy: 0.8383 - precision_27: 0.7966 - recall_27: 0.9086\n",
      "Epoch 54/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.3558 - accuracy: 0.8357 - precision_27: 0.7951 - recall_27: 0.9046\n",
      "Epoch 55/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.3527 - accuracy: 0.8387 - precision_27: 0.8011 - recall_27: 0.9011\n",
      "Epoch 56/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.3448 - accuracy: 0.8400 - precision_27: 0.8017 - recall_27: 0.9034\n",
      "Epoch 57/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.3588 - accuracy: 0.8370 - precision_27: 0.7970 - recall_27: 0.9043\n",
      "Epoch 58/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.3520 - accuracy: 0.8380 - precision_27: 0.8049 - recall_27: 0.8923\n",
      "Epoch 59/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.3412 - accuracy: 0.8445 - precision_27: 0.8041 - recall_27: 0.9111\n",
      "Epoch 60/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.3468 - accuracy: 0.8398 - precision_27: 0.8040 - recall_27: 0.8989\n",
      "Epoch 61/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.3537 - accuracy: 0.8378 - precision_27: 0.8001 - recall_27: 0.9009\n",
      "Epoch 62/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.3360 - accuracy: 0.8461 - precision_27: 0.8082 - recall_27: 0.9077\n",
      "Epoch 63/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.3401 - accuracy: 0.8415 - precision_27: 0.8046 - recall_27: 0.9023\n",
      "Epoch 64/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.3476 - accuracy: 0.8425 - precision_27: 0.8029 - recall_27: 0.9080\n",
      "Epoch 65/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.3359 - accuracy: 0.8468 - precision_27: 0.8134 - recall_27: 0.9003\n",
      "Epoch 66/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.3349 - accuracy: 0.8467 - precision_27: 0.8092 - recall_27: 0.9074\n",
      "Epoch 67/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.3342 - accuracy: 0.8514 - precision_27: 0.8141 - recall_27: 0.9109\n",
      "Epoch 68/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.3459 - accuracy: 0.8443 - precision_27: 0.8076 - recall_27: 0.9040\n",
      "Epoch 69/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.3354 - accuracy: 0.8501 - precision_27: 0.8069 - recall_27: 0.9206\n",
      "Epoch 70/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.3359 - accuracy: 0.8467 - precision_27: 0.8070 - recall_27: 0.9114\n",
      "Epoch 71/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.3351 - accuracy: 0.8467 - precision_27: 0.8056 - recall_27: 0.9140\n",
      "Epoch 72/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.3374 - accuracy: 0.8450 - precision_27: 0.8065 - recall_27: 0.9077\n",
      "Epoch 73/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.3405 - accuracy: 0.8458 - precision_27: 0.8121 - recall_27: 0.9000\n",
      "Epoch 74/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.3490 - accuracy: 0.8437 - precision_27: 0.8027 - recall_27: 0.9114\n",
      "Epoch 75/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.3342 - accuracy: 0.8468 - precision_27: 0.8070 - recall_27: 0.9117\n",
      "Epoch 76/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.3405 - accuracy: 0.8448 - precision_27: 0.8048 - recall_27: 0.9106\n",
      "Epoch 77/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.3296 - accuracy: 0.8528 - precision_27: 0.8154 - recall_27: 0.9123\n",
      "Epoch 78/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.3308 - accuracy: 0.8500 - precision_27: 0.8112 - recall_27: 0.9123\n",
      "Epoch 79/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.3302 - accuracy: 0.8530 - precision_27: 0.8125 - recall_27: 0.9177\n",
      "Epoch 80/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.3261 - accuracy: 0.8538 - precision_27: 0.8138 - recall_27: 0.9177\n",
      "Epoch 81/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.3285 - accuracy: 0.8537 - precision_27: 0.8160 - recall_27: 0.9134\n",
      "Epoch 82/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.3279 - accuracy: 0.8518 - precision_27: 0.8111 - recall_27: 0.9174\n",
      "Epoch 83/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.3278 - accuracy: 0.8547 - precision_27: 0.8141 - recall_27: 0.9194\n",
      "Epoch 84/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.3305 - accuracy: 0.8527 - precision_27: 0.8140 - recall_27: 0.9143\n",
      "Epoch 85/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.3242 - accuracy: 0.8550 - precision_27: 0.8185 - recall_27: 0.9123\n",
      "Epoch 86/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.3266 - accuracy: 0.8581 - precision_27: 0.8187 - recall_27: 0.9200\n",
      "Epoch 87/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.3281 - accuracy: 0.8514 - precision_27: 0.8128 - recall_27: 0.9131\n",
      "Epoch 88/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.3254 - accuracy: 0.8567 - precision_27: 0.8150 - recall_27: 0.9229\n",
      "Epoch 89/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.3254 - accuracy: 0.8556 - precision_27: 0.8139 - recall_27: 0.9220\n",
      "Epoch 90/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.3170 - accuracy: 0.8590 - precision_27: 0.8180 - recall_27: 0.9234\n",
      "Epoch 91/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.3230 - accuracy: 0.8554 - precision_27: 0.8118 - recall_27: 0.9254\n",
      "Epoch 92/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.3376 - accuracy: 0.8506 - precision_27: 0.8105 - recall_27: 0.9151\n",
      "Epoch 93/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.3281 - accuracy: 0.8601 - precision_27: 0.8163 - recall_27: 0.9294\n",
      "Epoch 94/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.3207 - accuracy: 0.8560 - precision_27: 0.8143 - recall_27: 0.9223\n",
      "Epoch 95/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.3290 - accuracy: 0.8516 - precision_27: 0.8069 - recall_27: 0.9243\n",
      "Epoch 96/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.3151 - accuracy: 0.8608 - precision_27: 0.8177 - recall_27: 0.9289\n",
      "Epoch 97/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.3214 - accuracy: 0.8557 - precision_27: 0.8086 - recall_27: 0.9320\n",
      "Epoch 98/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.3232 - accuracy: 0.8568 - precision_27: 0.8132 - recall_27: 0.9266\n",
      "Epoch 99/100\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.3179 - accuracy: 0.8591 - precision_27: 0.8163 - recall_27: 0.9269\n",
      "Epoch 100/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.3180 - accuracy: 0.8593 - precision_27: 0.8159 - recall_27: 0.9280\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {'batch_size': [50, 100],\n",
    "          'epochs': [50, 100]}\n",
    "\n",
    "grid = GridSearchCV(estimator=model_wrapper, param_grid=params, cv=3, verbose=3)\n",
    "grid_result = grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T08:19:19.981775Z",
     "start_time": "2023-11-09T08:19:17.366898Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 50, 'epochs': 100}\n",
      "0.8658379713694254\n"
     ]
    }
   ],
   "source": [
    "best_parameters = grid.best_params_\n",
    "print(best_parameters)\n",
    "best_score = grid.best_score_\n",
    "print(best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T08:21:48.530996Z",
     "start_time": "2023-11-09T08:19:17.368178Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.3637 - accuracy: 0.8397 - precision: 0.8122 - recall: 0.8837 - val_loss: 0.3574 - val_accuracy: 0.8463 - val_precision: 0.7971 - val_recall: 0.9291\n",
      "Epoch 2/150\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.3562 - accuracy: 0.8443 - precision: 0.8164 - recall: 0.8883 - val_loss: 0.3479 - val_accuracy: 0.8497 - val_precision: 0.8312 - val_recall: 0.8777\n",
      "Epoch 3/150\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.3555 - accuracy: 0.8431 - precision: 0.8108 - recall: 0.8951 - val_loss: 0.3421 - val_accuracy: 0.8583 - val_precision: 0.8157 - val_recall: 0.9257\n",
      "Epoch 4/150\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.3545 - accuracy: 0.8435 - precision: 0.8162 - recall: 0.8869 - val_loss: 0.3378 - val_accuracy: 0.8623 - val_precision: 0.8183 - val_recall: 0.9314\n",
      "Epoch 5/150\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.3545 - accuracy: 0.8447 - precision: 0.8122 - recall: 0.8969 - val_loss: 0.3323 - val_accuracy: 0.8577 - val_precision: 0.8181 - val_recall: 0.9200\n",
      "Epoch 6/150\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.3526 - accuracy: 0.8447 - precision: 0.8164 - recall: 0.8894 - val_loss: 0.3345 - val_accuracy: 0.8674 - val_precision: 0.8402 - val_recall: 0.9074\n",
      "Epoch 7/150\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.3512 - accuracy: 0.8464 - precision: 0.8173 - recall: 0.8923 - val_loss: 0.3327 - val_accuracy: 0.8634 - val_precision: 0.8272 - val_recall: 0.9189\n",
      "Epoch 8/150\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.3467 - accuracy: 0.8485 - precision: 0.8222 - recall: 0.8894 - val_loss: 0.3301 - val_accuracy: 0.8674 - val_precision: 0.8325 - val_recall: 0.9200\n",
      "Epoch 9/150\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.3481 - accuracy: 0.8531 - precision: 0.8277 - recall: 0.8920 - val_loss: 0.3271 - val_accuracy: 0.8600 - val_precision: 0.8175 - val_recall: 0.9269\n",
      "Epoch 10/150\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.3413 - accuracy: 0.8556 - precision: 0.8288 - recall: 0.8963 - val_loss: 0.3291 - val_accuracy: 0.8674 - val_precision: 0.8251 - val_recall: 0.9326\n",
      "Epoch 11/150\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.3436 - accuracy: 0.8514 - precision: 0.8240 - recall: 0.8937 - val_loss: 0.3283 - val_accuracy: 0.8663 - val_precision: 0.8287 - val_recall: 0.9234\n",
      "Epoch 12/150\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.3454 - accuracy: 0.8513 - precision: 0.8226 - recall: 0.8957 - val_loss: 0.3208 - val_accuracy: 0.8697 - val_precision: 0.8258 - val_recall: 0.9371\n",
      "Epoch 13/150\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.3368 - accuracy: 0.8564 - precision: 0.8326 - recall: 0.8923 - val_loss: 0.3198 - val_accuracy: 0.8749 - val_precision: 0.8361 - val_recall: 0.9326\n",
      "Epoch 14/150\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.3352 - accuracy: 0.8578 - precision: 0.8300 - recall: 0.9000 - val_loss: 0.3178 - val_accuracy: 0.8703 - val_precision: 0.8499 - val_recall: 0.8994\n",
      "Epoch 15/150\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.3338 - accuracy: 0.8590 - precision: 0.8350 - recall: 0.8949 - val_loss: 0.3294 - val_accuracy: 0.8617 - val_precision: 0.8131 - val_recall: 0.9394\n",
      "Epoch 16/150\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.3383 - accuracy: 0.8553 - precision: 0.8296 - recall: 0.8943 - val_loss: 0.3239 - val_accuracy: 0.8703 - val_precision: 0.8221 - val_recall: 0.9451\n",
      "Epoch 17/150\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.3299 - accuracy: 0.8596 - precision: 0.8323 - recall: 0.9006 - val_loss: 0.3221 - val_accuracy: 0.8686 - val_precision: 0.8370 - val_recall: 0.9154\n",
      "Epoch 18/150\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.3334 - accuracy: 0.8543 - precision: 0.8303 - recall: 0.8906 - val_loss: 0.3152 - val_accuracy: 0.8720 - val_precision: 0.8437 - val_recall: 0.9131\n",
      "Epoch 19/150\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.3329 - accuracy: 0.8537 - precision: 0.8305 - recall: 0.8889 - val_loss: 0.3188 - val_accuracy: 0.8731 - val_precision: 0.8369 - val_recall: 0.9269\n",
      "Epoch 20/150\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.3345 - accuracy: 0.8568 - precision: 0.8282 - recall: 0.9006 - val_loss: 0.3399 - val_accuracy: 0.8663 - val_precision: 0.8103 - val_recall: 0.9566\n",
      "Epoch 21/150\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.3313 - accuracy: 0.8561 - precision: 0.8309 - recall: 0.8943 - val_loss: 0.3156 - val_accuracy: 0.8686 - val_precision: 0.8449 - val_recall: 0.9029\n",
      "Epoch 22/150\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.3298 - accuracy: 0.8588 - precision: 0.8310 - recall: 0.9009 - val_loss: 0.3183 - val_accuracy: 0.8640 - val_precision: 0.8273 - val_recall: 0.9200\n",
      "Epoch 23/150\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.3273 - accuracy: 0.8570 - precision: 0.8320 - recall: 0.8946 - val_loss: 0.3091 - val_accuracy: 0.8749 - val_precision: 0.8327 - val_recall: 0.9383\n",
      "Epoch 24/150\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.3260 - accuracy: 0.8616 - precision: 0.8333 - recall: 0.9040 - val_loss: 0.3232 - val_accuracy: 0.8669 - val_precision: 0.8344 - val_recall: 0.9154\n",
      "Epoch 25/150\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.3205 - accuracy: 0.8636 - precision: 0.8344 - recall: 0.9071 - val_loss: 0.3244 - val_accuracy: 0.8754 - val_precision: 0.8308 - val_recall: 0.9429\n",
      "Epoch 26/150\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.3320 - accuracy: 0.8578 - precision: 0.8343 - recall: 0.8931 - val_loss: 0.3095 - val_accuracy: 0.8726 - val_precision: 0.8403 - val_recall: 0.9200\n",
      "Epoch 27/150\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.3229 - accuracy: 0.8598 - precision: 0.8345 - recall: 0.8977 - val_loss: 0.3213 - val_accuracy: 0.8680 - val_precision: 0.8145 - val_recall: 0.9531\n",
      "Epoch 28/150\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.3281 - accuracy: 0.8591 - precision: 0.8343 - recall: 0.8963 - val_loss: 0.3123 - val_accuracy: 0.8783 - val_precision: 0.8251 - val_recall: 0.9600\n",
      "Epoch 29/150\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.3187 - accuracy: 0.8674 - precision: 0.8391 - recall: 0.9091 - val_loss: 0.3116 - val_accuracy: 0.8720 - val_precision: 0.8519 - val_recall: 0.9006\n",
      "Epoch 30/150\n",
      "140/140 [==============================] - 1s 9ms/step - loss: 0.3187 - accuracy: 0.8680 - precision: 0.8402 - recall: 0.9089 - val_loss: 0.3170 - val_accuracy: 0.8646 - val_precision: 0.8430 - val_recall: 0.8960\n",
      "Epoch 31/150\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.3230 - accuracy: 0.8653 - precision: 0.8436 - recall: 0.8969 - val_loss: 0.3194 - val_accuracy: 0.8726 - val_precision: 0.8215 - val_recall: 0.9520\n",
      "Epoch 32/150\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.3183 - accuracy: 0.8653 - precision: 0.8378 - recall: 0.9060 - val_loss: 0.3455 - val_accuracy: 0.8497 - val_precision: 0.8454 - val_recall: 0.8560\n",
      "Epoch 33/150\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.3180 - accuracy: 0.8681 - precision: 0.8431 - recall: 0.9046 - val_loss: 0.3071 - val_accuracy: 0.8823 - val_precision: 0.8410 - val_recall: 0.9429\n",
      "Epoch 34/150\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.3144 - accuracy: 0.8713 - precision: 0.8439 - recall: 0.9111 - val_loss: 0.2977 - val_accuracy: 0.8823 - val_precision: 0.8608 - val_recall: 0.9120\n",
      "Epoch 35/150\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.3149 - accuracy: 0.8667 - precision: 0.8447 - recall: 0.8986 - val_loss: 0.3111 - val_accuracy: 0.8726 - val_precision: 0.8389 - val_recall: 0.9223\n",
      "Epoch 36/150\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.3082 - accuracy: 0.8741 - precision: 0.8489 - recall: 0.9103 - val_loss: 0.3023 - val_accuracy: 0.8829 - val_precision: 0.8363 - val_recall: 0.9520\n",
      "Epoch 37/150\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.3216 - accuracy: 0.8646 - precision: 0.8360 - recall: 0.9071 - val_loss: 0.3105 - val_accuracy: 0.8726 - val_precision: 0.8424 - val_recall: 0.9166\n",
      "Epoch 38/150\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.3150 - accuracy: 0.8690 - precision: 0.8445 - recall: 0.9046 - val_loss: 0.3148 - val_accuracy: 0.8760 - val_precision: 0.8323 - val_recall: 0.9417\n",
      "Epoch 39/150\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.3171 - accuracy: 0.8648 - precision: 0.8394 - recall: 0.9023 - val_loss: 0.3211 - val_accuracy: 0.8720 - val_precision: 0.8188 - val_recall: 0.9554\n",
      "Epoch 40/150\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.3171 - accuracy: 0.8678 - precision: 0.8421 - recall: 0.9054 - val_loss: 0.3124 - val_accuracy: 0.8857 - val_precision: 0.8306 - val_recall: 0.9691\n",
      "Epoch 41/150\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.3120 - accuracy: 0.8696 - precision: 0.8454 - recall: 0.9046 - val_loss: 0.3077 - val_accuracy: 0.8777 - val_precision: 0.8411 - val_recall: 0.9314\n",
      "Epoch 42/150\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.3210 - accuracy: 0.8673 - precision: 0.8425 - recall: 0.9034 - val_loss: 0.3097 - val_accuracy: 0.8737 - val_precision: 0.8337 - val_recall: 0.9337\n",
      "Epoch 43/150\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.3096 - accuracy: 0.8707 - precision: 0.8437 - recall: 0.9100 - val_loss: 0.3076 - val_accuracy: 0.8783 - val_precision: 0.8441 - val_recall: 0.9280\n",
      "Epoch 44/150\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.3127 - accuracy: 0.8706 - precision: 0.8410 - recall: 0.9140 - val_loss: 0.3185 - val_accuracy: 0.8840 - val_precision: 0.8333 - val_recall: 0.9600\n",
      "Epoch 45/150\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.3154 - accuracy: 0.8651 - precision: 0.8415 - recall: 0.8997 - val_loss: 0.2946 - val_accuracy: 0.8851 - val_precision: 0.8481 - val_recall: 0.9383\n",
      "Epoch 46/150\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.3099 - accuracy: 0.8697 - precision: 0.8434 - recall: 0.9080 - val_loss: 0.2935 - val_accuracy: 0.8891 - val_precision: 0.8536 - val_recall: 0.9394\n",
      "Epoch 47/150\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.3113 - accuracy: 0.8650 - precision: 0.8384 - recall: 0.9043 - val_loss: 0.2941 - val_accuracy: 0.8857 - val_precision: 0.8617 - val_recall: 0.9189\n",
      "Epoch 48/150\n",
      "140/140 [==============================] - 1s 11ms/step - loss: 0.3079 - accuracy: 0.8740 - precision: 0.8474 - recall: 0.9123 - val_loss: 0.3148 - val_accuracy: 0.8771 - val_precision: 0.8395 - val_recall: 0.9326\n",
      "Epoch 49/150\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.3067 - accuracy: 0.8731 - precision: 0.8483 - recall: 0.9089 - val_loss: 0.3091 - val_accuracy: 0.8771 - val_precision: 0.8320 - val_recall: 0.9451\n",
      "Epoch 50/150\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.3156 - accuracy: 0.8674 - precision: 0.8437 - recall: 0.9020 - val_loss: 0.3137 - val_accuracy: 0.8663 - val_precision: 0.8549 - val_recall: 0.8823\n",
      "Epoch 51/150\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.3029 - accuracy: 0.8730 - precision: 0.8486 - recall: 0.9080 - val_loss: 0.2966 - val_accuracy: 0.8851 - val_precision: 0.8600 - val_recall: 0.9200\n",
      "Epoch 52/150\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.3074 - accuracy: 0.8713 - precision: 0.8483 - recall: 0.9043 - val_loss: 0.3321 - val_accuracy: 0.8634 - val_precision: 0.8149 - val_recall: 0.9406\n",
      "Epoch 53/150\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.3102 - accuracy: 0.8678 - precision: 0.8432 - recall: 0.9037 - val_loss: 0.2963 - val_accuracy: 0.8874 - val_precision: 0.8495 - val_recall: 0.9417\n",
      "Epoch 54/150\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.3094 - accuracy: 0.8703 - precision: 0.8441 - recall: 0.9083 - val_loss: 0.3298 - val_accuracy: 0.8663 - val_precision: 0.8406 - val_recall: 0.9040\n",
      "Epoch 55/150\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.3018 - accuracy: 0.8763 - precision: 0.8492 - recall: 0.9151 - val_loss: 0.3040 - val_accuracy: 0.8829 - val_precision: 0.8350 - val_recall: 0.9543\n",
      "Epoch 56/150\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.3074 - accuracy: 0.8681 - precision: 0.8431 - recall: 0.9046 - val_loss: 0.3167 - val_accuracy: 0.8697 - val_precision: 0.8298 - val_recall: 0.9303\n",
      "Epoch 57/150\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.3018 - accuracy: 0.8764 - precision: 0.8463 - recall: 0.9200 - val_loss: 0.2959 - val_accuracy: 0.8789 - val_precision: 0.8312 - val_recall: 0.9509\n",
      "Epoch 58/150\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.3065 - accuracy: 0.8720 - precision: 0.8515 - recall: 0.9011 - val_loss: 0.3262 - val_accuracy: 0.8777 - val_precision: 0.8163 - val_recall: 0.9749\n",
      "Epoch 59/150\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.3131 - accuracy: 0.8664 - precision: 0.8415 - recall: 0.9029 - val_loss: 0.3143 - val_accuracy: 0.8720 - val_precision: 0.8318 - val_recall: 0.9326\n",
      "Epoch 60/150\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.3125 - accuracy: 0.8746 - precision: 0.8472 - recall: 0.9140 - val_loss: 0.3014 - val_accuracy: 0.8823 - val_precision: 0.8403 - val_recall: 0.9440\n",
      "Epoch 61/150\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.3143 - accuracy: 0.8697 - precision: 0.8443 - recall: 0.9066 - val_loss: 0.2970 - val_accuracy: 0.8846 - val_precision: 0.8473 - val_recall: 0.9383\n",
      "Epoch 62/150\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.3068 - accuracy: 0.8720 - precision: 0.8455 - recall: 0.9103 - val_loss: 0.2902 - val_accuracy: 0.8954 - val_precision: 0.8545 - val_recall: 0.9531\n",
      "Epoch 63/150\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.3045 - accuracy: 0.8748 - precision: 0.8469 - recall: 0.9151 - val_loss: 0.2939 - val_accuracy: 0.8863 - val_precision: 0.8463 - val_recall: 0.9440\n",
      "Epoch 64/150\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.3057 - accuracy: 0.8740 - precision: 0.8489 - recall: 0.9100 - val_loss: 0.2929 - val_accuracy: 0.8897 - val_precision: 0.8451 - val_recall: 0.9543\n",
      "Epoch 65/150\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.3067 - accuracy: 0.8668 - precision: 0.8465 - recall: 0.8963 - val_loss: 0.2934 - val_accuracy: 0.8909 - val_precision: 0.8462 - val_recall: 0.9554\n",
      "Epoch 66/150\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.2980 - accuracy: 0.8801 - precision: 0.8510 - recall: 0.9217 - val_loss: 0.3076 - val_accuracy: 0.8720 - val_precision: 0.8613 - val_recall: 0.8869\n",
      "Epoch 67/150\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.3094 - accuracy: 0.8700 - precision: 0.8463 - recall: 0.9043 - val_loss: 0.2914 - val_accuracy: 0.8903 - val_precision: 0.8583 - val_recall: 0.9349\n",
      "Epoch 68/150\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.3022 - accuracy: 0.8754 - precision: 0.8474 - recall: 0.9157 - val_loss: 0.2983 - val_accuracy: 0.8806 - val_precision: 0.8384 - val_recall: 0.9429\n",
      "Epoch 69/150\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.3014 - accuracy: 0.8787 - precision: 0.8508 - recall: 0.9186 - val_loss: 0.2893 - val_accuracy: 0.8846 - val_precision: 0.8662 - val_recall: 0.9097\n",
      "Epoch 70/150\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.2968 - accuracy: 0.8754 - precision: 0.8500 - recall: 0.9117 - val_loss: 0.2916 - val_accuracy: 0.8880 - val_precision: 0.8461 - val_recall: 0.9486\n",
      "Epoch 71/150\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.3065 - accuracy: 0.8717 - precision: 0.8475 - recall: 0.9066 - val_loss: 0.2935 - val_accuracy: 0.8851 - val_precision: 0.8481 - val_recall: 0.9383\n",
      "Epoch 72/150\n",
      "140/140 [==============================] - 1s 9ms/step - loss: 0.2972 - accuracy: 0.8798 - precision: 0.8546 - recall: 0.9154 - val_loss: 0.2958 - val_accuracy: 0.8800 - val_precision: 0.8322 - val_recall: 0.9520\n",
      "Epoch 73/150\n",
      "140/140 [==============================] - 1s 9ms/step - loss: 0.2991 - accuracy: 0.8743 - precision: 0.8473 - recall: 0.9131 - val_loss: 0.3099 - val_accuracy: 0.8663 - val_precision: 0.8541 - val_recall: 0.8834\n",
      "Epoch 74/150\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.2992 - accuracy: 0.8751 - precision: 0.8474 - recall: 0.9151 - val_loss: 0.2908 - val_accuracy: 0.8874 - val_precision: 0.8509 - val_recall: 0.9394\n",
      "Epoch 75/150\n",
      "140/140 [==============================] - 1s 9ms/step - loss: 0.2931 - accuracy: 0.8811 - precision: 0.8525 - recall: 0.9217 - val_loss: 0.2944 - val_accuracy: 0.8846 - val_precision: 0.8561 - val_recall: 0.9246\n",
      "Epoch 76/150\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.2965 - accuracy: 0.8768 - precision: 0.8551 - recall: 0.9074 - val_loss: 0.3129 - val_accuracy: 0.8800 - val_precision: 0.8194 - val_recall: 0.9749\n",
      "Epoch 77/150\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.2937 - accuracy: 0.8786 - precision: 0.8528 - recall: 0.9151 - val_loss: 0.2993 - val_accuracy: 0.8806 - val_precision: 0.8384 - val_recall: 0.9429\n",
      "Epoch 78/150\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.3009 - accuracy: 0.8780 - precision: 0.8528 - recall: 0.9137 - val_loss: 0.2891 - val_accuracy: 0.8886 - val_precision: 0.8688 - val_recall: 0.9154\n",
      "Epoch 79/150\n",
      "140/140 [==============================] - 1s 9ms/step - loss: 0.3032 - accuracy: 0.8741 - precision: 0.8517 - recall: 0.9060 - val_loss: 0.3040 - val_accuracy: 0.8869 - val_precision: 0.8444 - val_recall: 0.9486\n",
      "Epoch 80/150\n",
      "140/140 [==============================] - 1s 9ms/step - loss: 0.3009 - accuracy: 0.8768 - precision: 0.8482 - recall: 0.9180 - val_loss: 0.2857 - val_accuracy: 0.8857 - val_precision: 0.8625 - val_recall: 0.9177\n",
      "Epoch 81/150\n",
      "140/140 [==============================] - 1s 9ms/step - loss: 0.2985 - accuracy: 0.8783 - precision: 0.8548 - recall: 0.9114 - val_loss: 0.3085 - val_accuracy: 0.8783 - val_precision: 0.8277 - val_recall: 0.9554\n",
      "Epoch 82/150\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.2925 - accuracy: 0.8804 - precision: 0.8565 - recall: 0.9140 - val_loss: 0.2953 - val_accuracy: 0.8691 - val_precision: 0.8629 - val_recall: 0.8777\n",
      "Epoch 83/150\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.2996 - accuracy: 0.8776 - precision: 0.8512 - recall: 0.9151 - val_loss: 0.3346 - val_accuracy: 0.8657 - val_precision: 0.8156 - val_recall: 0.9451\n",
      "Epoch 84/150\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.2916 - accuracy: 0.8774 - precision: 0.8521 - recall: 0.9134 - val_loss: 0.2844 - val_accuracy: 0.8926 - val_precision: 0.8502 - val_recall: 0.9531\n",
      "Epoch 85/150\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.2979 - accuracy: 0.8773 - precision: 0.8513 - recall: 0.9143 - val_loss: 0.3006 - val_accuracy: 0.8817 - val_precision: 0.8262 - val_recall: 0.9669\n",
      "Epoch 86/150\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.2954 - accuracy: 0.8761 - precision: 0.8482 - recall: 0.9163 - val_loss: 0.2906 - val_accuracy: 0.8886 - val_precision: 0.8448 - val_recall: 0.9520\n",
      "Epoch 87/150\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.2929 - accuracy: 0.8760 - precision: 0.8541 - recall: 0.9069 - val_loss: 0.2960 - val_accuracy: 0.8811 - val_precision: 0.8428 - val_recall: 0.9371\n",
      "Epoch 88/150\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.2952 - accuracy: 0.8828 - precision: 0.8596 - recall: 0.9151 - val_loss: 0.2855 - val_accuracy: 0.8891 - val_precision: 0.8443 - val_recall: 0.9543\n",
      "Epoch 89/150\n",
      "140/140 [==============================] - 1s 9ms/step - loss: 0.2886 - accuracy: 0.8820 - precision: 0.8509 - recall: 0.9263 - val_loss: 0.2979 - val_accuracy: 0.8766 - val_precision: 0.8325 - val_recall: 0.9429\n",
      "Epoch 90/150\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.2959 - accuracy: 0.8770 - precision: 0.8512 - recall: 0.9137 - val_loss: 0.2922 - val_accuracy: 0.8886 - val_precision: 0.8462 - val_recall: 0.9497\n",
      "Epoch 91/150\n",
      "140/140 [==============================] - 1s 9ms/step - loss: 0.2897 - accuracy: 0.8850 - precision: 0.8594 - recall: 0.9206 - val_loss: 0.2837 - val_accuracy: 0.8931 - val_precision: 0.8554 - val_recall: 0.9463\n",
      "Epoch 92/150\n",
      "140/140 [==============================] - 1s 9ms/step - loss: 0.2866 - accuracy: 0.8831 - precision: 0.8584 - recall: 0.9177 - val_loss: 0.2860 - val_accuracy: 0.8937 - val_precision: 0.8563 - val_recall: 0.9463\n",
      "Epoch 93/150\n",
      "140/140 [==============================] - 1s 10ms/step - loss: 0.2933 - accuracy: 0.8791 - precision: 0.8516 - recall: 0.9183 - val_loss: 0.2875 - val_accuracy: 0.8909 - val_precision: 0.8462 - val_recall: 0.9554\n",
      "Epoch 94/150\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.3013 - accuracy: 0.8734 - precision: 0.8480 - recall: 0.9100 - val_loss: 0.2863 - val_accuracy: 0.8857 - val_precision: 0.8372 - val_recall: 0.9577\n",
      "Epoch 95/150\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.2900 - accuracy: 0.8797 - precision: 0.8529 - recall: 0.9177 - val_loss: 0.2745 - val_accuracy: 0.8926 - val_precision: 0.8560 - val_recall: 0.9440\n",
      "Epoch 96/150\n",
      "140/140 [==============================] - 1s 9ms/step - loss: 0.2919 - accuracy: 0.8783 - precision: 0.8492 - recall: 0.9200 - val_loss: 0.2896 - val_accuracy: 0.8857 - val_precision: 0.8664 - val_recall: 0.9120\n",
      "Epoch 97/150\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.2910 - accuracy: 0.8810 - precision: 0.8555 - recall: 0.9169 - val_loss: 0.2836 - val_accuracy: 0.8851 - val_precision: 0.8481 - val_recall: 0.9383\n",
      "Epoch 98/150\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.2847 - accuracy: 0.8824 - precision: 0.8586 - recall: 0.9157 - val_loss: 0.2906 - val_accuracy: 0.8891 - val_precision: 0.8618 - val_recall: 0.9269\n",
      "Epoch 99/150\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.2912 - accuracy: 0.8793 - precision: 0.8537 - recall: 0.9154 - val_loss: 0.2830 - val_accuracy: 0.8874 - val_precision: 0.8517 - val_recall: 0.9383\n",
      "Epoch 100/150\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.2926 - accuracy: 0.8796 - precision: 0.8547 - recall: 0.9146 - val_loss: 0.2906 - val_accuracy: 0.8851 - val_precision: 0.8744 - val_recall: 0.8994\n",
      "Epoch 101/150\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.2913 - accuracy: 0.8831 - precision: 0.8566 - recall: 0.9203 - val_loss: 0.2840 - val_accuracy: 0.8909 - val_precision: 0.8406 - val_recall: 0.9646\n",
      "Epoch 102/150\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.2915 - accuracy: 0.8787 - precision: 0.8524 - recall: 0.9160 - val_loss: 0.3106 - val_accuracy: 0.8657 - val_precision: 0.8471 - val_recall: 0.8926\n",
      "Epoch 103/150\n",
      "140/140 [==============================] - 1s 9ms/step - loss: 0.2928 - accuracy: 0.8763 - precision: 0.8523 - recall: 0.9103 - val_loss: 0.2872 - val_accuracy: 0.8886 - val_precision: 0.8414 - val_recall: 0.9577\n",
      "Epoch 104/150\n",
      "140/140 [==============================] - 1s 10ms/step - loss: 0.2920 - accuracy: 0.8806 - precision: 0.8543 - recall: 0.9177 - val_loss: 0.2885 - val_accuracy: 0.8960 - val_precision: 0.8482 - val_recall: 0.9646\n",
      "Epoch 105/150\n",
      "140/140 [==============================] - 1s 9ms/step - loss: 0.2835 - accuracy: 0.8834 - precision: 0.8596 - recall: 0.9166 - val_loss: 0.2810 - val_accuracy: 0.8886 - val_precision: 0.8549 - val_recall: 0.9360\n",
      "Epoch 106/150\n",
      "140/140 [==============================] - 1s 9ms/step - loss: 0.2810 - accuracy: 0.8867 - precision: 0.8589 - recall: 0.9254 - val_loss: 0.2699 - val_accuracy: 0.8971 - val_precision: 0.8624 - val_recall: 0.9451\n",
      "Epoch 107/150\n",
      "140/140 [==============================] - 1s 9ms/step - loss: 0.2862 - accuracy: 0.8830 - precision: 0.8587 - recall: 0.9169 - val_loss: 0.2837 - val_accuracy: 0.8920 - val_precision: 0.8507 - val_recall: 0.9509\n",
      "Epoch 108/150\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.2880 - accuracy: 0.8817 - precision: 0.8570 - recall: 0.9163 - val_loss: 0.2925 - val_accuracy: 0.8783 - val_precision: 0.8271 - val_recall: 0.9566\n",
      "Epoch 109/150\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.2884 - accuracy: 0.8840 - precision: 0.8580 - recall: 0.9203 - val_loss: 0.2863 - val_accuracy: 0.8920 - val_precision: 0.8479 - val_recall: 0.9554\n",
      "Epoch 110/150\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.2847 - accuracy: 0.8841 - precision: 0.8581 - recall: 0.9206 - val_loss: 0.2869 - val_accuracy: 0.8834 - val_precision: 0.8365 - val_recall: 0.9531\n",
      "Epoch 111/150\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.2924 - accuracy: 0.8828 - precision: 0.8575 - recall: 0.9183 - val_loss: 0.2869 - val_accuracy: 0.8829 - val_precision: 0.8526 - val_recall: 0.9257\n",
      "Epoch 112/150\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.2905 - accuracy: 0.8813 - precision: 0.8548 - recall: 0.9186 - val_loss: 0.2776 - val_accuracy: 0.8937 - val_precision: 0.8548 - val_recall: 0.9486\n",
      "Epoch 113/150\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.2850 - accuracy: 0.8823 - precision: 0.8579 - recall: 0.9163 - val_loss: 0.2818 - val_accuracy: 0.8909 - val_precision: 0.8654 - val_recall: 0.9257\n",
      "Epoch 114/150\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.2842 - accuracy: 0.8816 - precision: 0.8572 - recall: 0.9157 - val_loss: 0.2913 - val_accuracy: 0.8880 - val_precision: 0.8319 - val_recall: 0.9726\n",
      "Epoch 115/150\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.2826 - accuracy: 0.8850 - precision: 0.8598 - recall: 0.9200 - val_loss: 0.2772 - val_accuracy: 0.8903 - val_precision: 0.8439 - val_recall: 0.9577\n",
      "Epoch 116/150\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.2825 - accuracy: 0.8864 - precision: 0.8602 - recall: 0.9229 - val_loss: 0.2996 - val_accuracy: 0.8817 - val_precision: 0.8249 - val_recall: 0.9691\n",
      "Epoch 117/150\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.2865 - accuracy: 0.8786 - precision: 0.8531 - recall: 0.9146 - val_loss: 0.2630 - val_accuracy: 0.8971 - val_precision: 0.8542 - val_recall: 0.9577\n",
      "Epoch 118/150\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.2799 - accuracy: 0.8856 - precision: 0.8617 - recall: 0.9186 - val_loss: 0.2918 - val_accuracy: 0.8846 - val_precision: 0.8232 - val_recall: 0.9794\n",
      "Epoch 119/150\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.2878 - accuracy: 0.8848 - precision: 0.8579 - recall: 0.9226 - val_loss: 0.2764 - val_accuracy: 0.8897 - val_precision: 0.8444 - val_recall: 0.9554\n",
      "Epoch 120/150\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.2912 - accuracy: 0.8771 - precision: 0.8537 - recall: 0.9103 - val_loss: 0.2855 - val_accuracy: 0.8834 - val_precision: 0.8358 - val_recall: 0.9543\n",
      "Epoch 121/150\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.2897 - accuracy: 0.8818 - precision: 0.8563 - recall: 0.9177 - val_loss: 0.2765 - val_accuracy: 0.8920 - val_precision: 0.8618 - val_recall: 0.9337\n",
      "Epoch 122/150\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.2758 - accuracy: 0.8863 - precision: 0.8632 - recall: 0.9180 - val_loss: 0.2765 - val_accuracy: 0.8966 - val_precision: 0.8463 - val_recall: 0.9691\n",
      "Epoch 123/150\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.2810 - accuracy: 0.8853 - precision: 0.8584 - recall: 0.9229 - val_loss: 0.2733 - val_accuracy: 0.8937 - val_precision: 0.8469 - val_recall: 0.9611\n",
      "Epoch 124/150\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.2841 - accuracy: 0.8800 - precision: 0.8541 - recall: 0.9166 - val_loss: 0.2877 - val_accuracy: 0.8829 - val_precision: 0.8468 - val_recall: 0.9349\n",
      "Epoch 125/150\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.2815 - accuracy: 0.8866 - precision: 0.8620 - recall: 0.9206 - val_loss: 0.2786 - val_accuracy: 0.8914 - val_precision: 0.8422 - val_recall: 0.9634\n",
      "Epoch 126/150\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.2827 - accuracy: 0.8833 - precision: 0.8576 - recall: 0.9191 - val_loss: 0.2873 - val_accuracy: 0.8920 - val_precision: 0.8410 - val_recall: 0.9669\n",
      "Epoch 127/150\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.2850 - accuracy: 0.8828 - precision: 0.8558 - recall: 0.9209 - val_loss: 0.2964 - val_accuracy: 0.8863 - val_precision: 0.8263 - val_recall: 0.9783\n",
      "Epoch 128/150\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.2828 - accuracy: 0.8856 - precision: 0.8603 - recall: 0.9206 - val_loss: 0.2716 - val_accuracy: 0.8989 - val_precision: 0.8490 - val_recall: 0.9703\n",
      "Epoch 129/150\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.2847 - accuracy: 0.8874 - precision: 0.8624 - recall: 0.9220 - val_loss: 0.2707 - val_accuracy: 0.8943 - val_precision: 0.8549 - val_recall: 0.9497\n",
      "Epoch 130/150\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.2760 - accuracy: 0.8841 - precision: 0.8611 - recall: 0.9160 - val_loss: 0.2598 - val_accuracy: 0.9029 - val_precision: 0.8615 - val_recall: 0.9600\n",
      "Epoch 131/150\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.2802 - accuracy: 0.8816 - precision: 0.8572 - recall: 0.9157 - val_loss: 0.2783 - val_accuracy: 0.8949 - val_precision: 0.8479 - val_recall: 0.9623\n",
      "Epoch 132/150\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.2808 - accuracy: 0.8854 - precision: 0.8611 - recall: 0.9191 - val_loss: 0.2849 - val_accuracy: 0.8869 - val_precision: 0.8652 - val_recall: 0.9166\n",
      "Epoch 133/150\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.2894 - accuracy: 0.8818 - precision: 0.8567 - recall: 0.9171 - val_loss: 0.2710 - val_accuracy: 0.9006 - val_precision: 0.8537 - val_recall: 0.9669\n",
      "Epoch 134/150\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.2825 - accuracy: 0.8871 - precision: 0.8619 - recall: 0.9220 - val_loss: 0.2814 - val_accuracy: 0.8903 - val_precision: 0.8391 - val_recall: 0.9657\n",
      "Epoch 135/150\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.2957 - accuracy: 0.8764 - precision: 0.8501 - recall: 0.9140 - val_loss: 0.2883 - val_accuracy: 0.8857 - val_precision: 0.8571 - val_recall: 0.9257\n",
      "Epoch 136/150\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.2817 - accuracy: 0.8838 - precision: 0.8586 - recall: 0.9191 - val_loss: 0.2819 - val_accuracy: 0.8834 - val_precision: 0.8513 - val_recall: 0.9291\n",
      "Epoch 137/150\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.2841 - accuracy: 0.8818 - precision: 0.8563 - recall: 0.9177 - val_loss: 0.2865 - val_accuracy: 0.8926 - val_precision: 0.8425 - val_recall: 0.9657\n",
      "Epoch 138/150\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.2768 - accuracy: 0.8841 - precision: 0.8588 - recall: 0.9194 - val_loss: 0.2784 - val_accuracy: 0.8851 - val_precision: 0.8720 - val_recall: 0.9029\n",
      "Epoch 139/150\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.2863 - accuracy: 0.8811 - precision: 0.8594 - recall: 0.9114 - val_loss: 0.2892 - val_accuracy: 0.8806 - val_precision: 0.8370 - val_recall: 0.9451\n",
      "Epoch 140/150\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.2791 - accuracy: 0.8864 - precision: 0.8635 - recall: 0.9180 - val_loss: 0.2817 - val_accuracy: 0.8949 - val_precision: 0.8417 - val_recall: 0.9726\n",
      "Epoch 141/150\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.2796 - accuracy: 0.8840 - precision: 0.8588 - recall: 0.9191 - val_loss: 0.2877 - val_accuracy: 0.8926 - val_precision: 0.8459 - val_recall: 0.9600\n",
      "Epoch 142/150\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.2778 - accuracy: 0.8880 - precision: 0.8604 - recall: 0.9263 - val_loss: 0.2813 - val_accuracy: 0.8903 - val_precision: 0.8446 - val_recall: 0.9566\n",
      "Epoch 143/150\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.2696 - accuracy: 0.8901 - precision: 0.8656 - recall: 0.9237 - val_loss: 0.2997 - val_accuracy: 0.8834 - val_precision: 0.8332 - val_recall: 0.9589\n",
      "Epoch 144/150\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.2871 - accuracy: 0.8824 - precision: 0.8561 - recall: 0.9194 - val_loss: 0.2816 - val_accuracy: 0.8937 - val_precision: 0.8408 - val_recall: 0.9714\n",
      "Epoch 145/150\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.2682 - accuracy: 0.8934 - precision: 0.8668 - recall: 0.9297 - val_loss: 0.2669 - val_accuracy: 0.9011 - val_precision: 0.8531 - val_recall: 0.9691\n",
      "Epoch 146/150\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.2845 - accuracy: 0.8834 - precision: 0.8556 - recall: 0.9226 - val_loss: 0.2791 - val_accuracy: 0.8811 - val_precision: 0.8485 - val_recall: 0.9280\n",
      "Epoch 147/150\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.2790 - accuracy: 0.8866 - precision: 0.8637 - recall: 0.9180 - val_loss: 0.2835 - val_accuracy: 0.8863 - val_precision: 0.8499 - val_recall: 0.9383\n",
      "Epoch 148/150\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.2852 - accuracy: 0.8804 - precision: 0.8574 - recall: 0.9126 - val_loss: 0.3095 - val_accuracy: 0.8754 - val_precision: 0.8120 - val_recall: 0.9771\n",
      "Epoch 149/150\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.2837 - accuracy: 0.8881 - precision: 0.8612 - recall: 0.9254 - val_loss: 0.2690 - val_accuracy: 0.8943 - val_precision: 0.8594 - val_recall: 0.9429\n",
      "Epoch 150/150\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.2853 - accuracy: 0.8840 - precision: 0.8576 - recall: 0.9209 - val_loss: 0.2761 - val_accuracy: 0.8994 - val_precision: 0.8520 - val_recall: 0.9669\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13a6a7250>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs = 150, batch_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "90% accuracy on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "d1GOfAgt4M-Q",
    "KICuY0lg5nUD",
    "AD57fE2n7QP4",
    "U5zevRH57X8v",
    "IImSYWQGBSz6",
    "ngJVLbRKG7U_",
    "mXf6cpO_KWTs"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "8c3d4d9970fc5c09c50d9318a9c7fbf4d0159e4b28833276f5678ee22bded273"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
